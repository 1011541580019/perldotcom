<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" id="sixapart-standard">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="generator" content="Movable Type Pro 5.13-en" />
<link rel="stylesheet" href="/pub/styles.css" type="text/css" />
<link rel="start" href="/pub/" title="Home" />
<link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/pub/atom.xml" />
<script type="text/javascript" src="/pub/mt.js"></script>
<!--
<rdf:RDF xmlns="http://web.resource.org/cc/"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<Work rdf:about="/pub/">
<dc:title>Perl.com</dc:title>
<dc:description>news and views of the Perl programming language</dc:description>
<license rdf:resource="http://creativecommons.org/licenses/by-nc-nd/3.0/" />
</Work>
<License rdf:about="http://creativecommons.org/licenses/by-nc-nd/3.0/">
</License>
</rdf:RDF>
-->

<script type="text/javascript">

 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-50555-22']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type =
   'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
   'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0];
   s.parentNode.insertBefore(ga, s);
 })();

</script>
<script type='text/javascript' src='http://partner.googleadservices.com/gampad/google_service.js'></script>
<script type='text/javascript'>
GS_googleAddAdSenseService("ca-pub-4136420132070439");
GS_googleEnableAllServices();
</script>
<script type='text/javascript'>
GA_googleAddSlot("ca-pub-4136420132070439", "Perl_728x90");
</script>
<script type='text/javascript'>GA_googleFetchAds();</script>
    <title>Perl.com: October 2012 Archives</title>


    <link rel="prev" href="/pub/2012/08/" title="August 2012" />
    <link rel="next" href="/pub/2012/11/" title="November 2012" />

</head>
<body id="perl-com" class="mt-archive-listing mt-datebased-monthly-archive layout-wt">
    <div id="container">
        <div id="container-inner">


            <div id="header">
    <div id="header-inner">
        <div id="header-content">
        <span id="top_advert"> 
<!-- Put any landscape advert in here -->
<!-- Perl_728x90 -->
<script type='text/javascript'>
GA_googleFillSlot("Perl_728x90");
</script>
        </span> 



            <div id="header-name"><a href="/pub/" accesskey="1">Perl.com</a></div>
            <div id="header-description">news and views of the Perl programming language</div>




        </div>
    </div>
</div>



            <div id="content">
                <div id="content-inner">


                    <div id="alpha">
                        <div id="alpha-inner">


                            <h1 id="page-title" class="archive-title">October 2012 Archives</h1>





                            
                            <div id="entry-2076" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2012/10/newcomer-experience-in-the-perl-community-survey.html" rel="bookmark">Newcomer Experience in the Perl Community Survey</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author"><a class="fn url" href="http://kevincarillo.org/">Kevin Carillo</a></span> on <abbr class="published" title="2012-10-15T06:00:01-08:00">October 15, 2012  6:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            <p>I am currently running <a
href="https://limesurvey.sim.vuw.ac.nz/index.php?sid=89971&amp;lang=en">a
survey looking at the Perl community</a> specifically and I am looking for
people who joined the Perl community within the last two years. I am equally
interested in hearing from people having had either positive or negative
experiences as newcomers.</p>

<h2>Perl subcultures and newcomer experience in Perl</h2>

<p>The Perl community has been a growing and evolving multi-faceted entity that
is now comprised of a large number of social groups (for example, 262 Perl
Mongers groups as of 10/10/12) and various sub-projects that all have their own
history and subculture.</p>

<p>Some projects are very newcomer conscious while others are not. Projects may
rely on different strategies and means when trying to integrate new recruits.
Younger projects like <a href="http://mojolicio.us/">Mojo</a> or <a
href="http://perldancer.org/">Dancer</a> may do things differently compared to
older projects such as <a href="http://catalystframework.org/">Catalyst</a> or
<a href="http://moose.perl.org/">Moose</a>. Depending on a project's
subculture, there may be more or fewer resources dedicated to helping
newcomers, people may be more or less supportive, or people may or may not
voluntarily mentor newcomers. We could also debate about the differences
between Perl 5 and Perl 6 when dealing with newcomers.</p>

<p>There is then a lot of variation in the way newcomers of the overall Perl
community are handled making each person's newcomer experience pretty
unique.</p>

<p>Among all these different types of experience, some of them will lead one to
become a valued sustainable contributor (from the Perl community perspective)
while others may simply end up in people slowly giving up or even running
away.</p>

<p>This study tries to identify the important aspects of one's newcomer
experience in Perl that have a positive influence in generating "good"
contributors&mdash;"good" in terms of being good citizens for the Perl
community.</p>

<h2>How is it going to help Perl?</h2>

<p>The data will help gain insights about the experience of newcomers within
the Perl community. In addition, it will allow to understand how to design
effective newcomer initiatives to ensure that Perl will remain a successful and
healthy community.</p>

<h2>Where is the project going after that?</h2>

<p>This survey is the first step of the research project as a refined survey
will be later administered to other FOSS communities at the same time. This
will allow to generate cross-community results that will be to some extent
generalizable. This research project overall aims at helping FOSS communities
to design newcomer initiatives in line with their well-being and
sustainability.</p>

<h2>About the survey</h2>

<p>This survey is anonymous, and no information that would identify you is
being collected. I expect the survey to take around 20 minutes of your
time.</p>

<p>The survey is available at <a
href="https://limesurvey.sim.vuw.ac.nz/index.php?sid=89971&amp;lang=en">https://limesurvey.sim.vuw.ac.nz/index.php?sid=89971&amp;lang=en</a>.
It will be available until Monday, 22 October, 2012.</p>

<p>If you know members of the Perl community who you think would be interested
in completing it, please let them know about the survey.</p>

<p>I will post news about my progress with this research, and the results on my
blog at <a href="http://kevincarillo.org/">kevincarillo.org</a>. Don't hesitate
to contact me at <a
href="mailto:kevin.carillo@vuw.ac.nz">kevin.carillo@vuw.ac.nz</a>.</p>
        </div>



    </div>
    <div class="asset-footer"></div>
</div>


                            
                            <div id="entry-2074" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2012/10/an-overview-of-lexing-and-parsing.html" rel="bookmark">An Overview of Lexing and Parsing</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author"><a class="fn url" href="http://savage.net.au/index.html">Ron Savage</a></span> on <abbr class="published" title="2012-10-01T06:00:01-08:00">October  1, 2012  6:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            <p>Perl programmers spend a lot of time munging data: reading it in,
transforming it, and writing out the results. Perl's great at this ad hoc text
transformation, with all sorts of string manipulation tools, including regular
expressions.</p>

<p>Regular expressions will only get you so far: witness the repeated advice
that you cannot parse HTML or XML with regular expressions themselves. When
Perl's builtin text processing tools aren't enough, you have to turn to
something more powerful.</p>

<p>That something is <em>parsing</em>.</p>

<h1>An Overview of Lexing and Parsing</h1>

<p>For a more formal discussion of what exactly lexing and parsing are, start
with Wikipedia's definitions: <a
    href="http://en.wikipedia.org/wiki/Lexing">Lexing</a> and <a
    href="http://en.wikipedia.org/wiki/Parsing">Parsing</a>.</p>

<p>Unfortunately, when people use the word parsing, they sometimes include the
idea of lexing. Other times they don't. This can cause confusion, but I'll
try to keep them clear. Such situations arise with other words, and our minds
usually resolve the specific meaning intended by analysing the context in which
the word is used. So, keep your mind in mind.</p>

<p>The lex phase and the parse phase can be combined into a single process, but
I advocate always keeping them separate. Trust me for a moment; I'll explain
shortly. If you're having trouble keeping the ideas separate, note that the
phases very conveniently run in alphabetical order: first we lex, and then we
parse.</p>

<h1>A History Lesson - In Absentia</a></h1>

<p>At this point, an article such as this would normally provide a summary of
historical developments in this field, to explain how the world ended up where
it is.  I won't do that, especially as I first encountered parsing many years
ago, when the only tools (lex, bison, yacc) were so complex to operate I took
the pledge to abstain.  Nevertheless, it's good to know such tools are still
available, so here are a few references:</p>

<p><a href="http://directory.fsf.org/wiki/Flex">Flex</a> is a successor to <a
    href="http://en.wikipedia.org/wiki/Lex_programming_tool">lex</a>, and <a
    href="http://www.gnu.org/software/bison/">Bison</a> is a successor to <a
    href="http://en.wikipedia.org/wiki/Yacc">yacc</a>. These are
well-established (old) tools to keep you from having to build a lexer or parser
by hand. This article explains why I (still) don't use any of these.</p>

<h1>But Why Study Lexing and Parsing?</h1>

<p>There are many situations where the only path to a solution requires a lexer
and a parser:</p>

<ol>
    <li><p><em>Running a program</em></p>

<p>This is trivial to understand, but not to implement.  In order to run a
program we need to set up a range of pre-conditions:</p>

<ul>
<li>Define the language, perhaps called Perl</li>
<li>Write a compiler (combined lexer and parser) for that language's grammar</li>
<li>Write a program in that language</li>
<li><p><em>Lex and parse</em> the source code</p>

<p>After all, it must be syntactically correct before we run it.  If not, we
display syntax errors. The real point of this step is to determine the
programmer's <em>intention</em>, that is, the reason for writing the code. We
don't <em>run</em> the code in this step, but we do get output. How do we do
that?</p></li>

<li><p>Run the code</p>

<p>Then we can gaze at the output which, hopefully, is correct.  Otherwise,
perhaps, we must find and fix logic errors.</p></li>

</ul></li>

<li><p><em>Rendering a web page of HTML + content</em>

<p>The steps are identical to those of the first example, with HTML replacing
Perl, although I can't bring myself to call writing HTML writing a program.</p>

<p>This time, we're asking: What is the web page designer's <em>intention</em>.
What would they like to render and how?  Of course, syntax checking is far
looser that with a programming language, but must still be undertaken.  For
instance, here's an example of clearly-corrupt HTML which can be parsed by <a
    href="http://www.jeffreykegler.com/marpa">Marpa</a>:</p>

<pre><code>        &#60;title&#62;Short&#60;/title&#62;&#60;p&#62;Text&#60;/head&#62;&#60;head&#62;</code></pre>

<p>See <a href="http://metacpan.org/module/Marpa::HTML">Marpa::HTML</a> for
more details. So far, I have used <a
    href="http://metacpan.org/module/Marpa::R2">Marpa::R2</a> in all my work,
which does not involve HTML.</p></li>

<li><p>Rendering an image, perhaps in SVG</p>

<p>Consider this file, written in the <a
    href="http://www.graphviz.org/content/dot-language">DOT</a> language, as
used by the <a href="http://www.graphviz.org/">Graphviz</a> graph visualizer
(<em>teamwork.dot</em>):</p>

<pre><code>        digraph Perl
        {
        graph [ rankdir=&#34;LR&#34; ]
        node  [ fontsize=&#34;12pt&#34; shape=&#34;rectangle&#34; style=&#34;filled, solid&#34; ]
        edge  [ color=&#34;grey&#34; ]
        &#34;Teamwork&#34; [ fillcolor=&#34;yellow&#34; ]
        &#34;Victory&#34;  [ fillcolor=&#34;red&#34; ]
        &#34;Teamwork&#34; -&#62; &#34;Victory&#34; [ label=&#34;is the key to&#34; ]
        }</code></pre>

<p>Given this "program", a renderer give effects to the author's
<em>intention</em> by rendering an image:</p>

<img src="teamwork.svg" />

<p>What's required to do that? As above, <em>lex</em>, <em>parse</em>,
<em>render</em>. Using Graphviz's <code>dot</code> command to carry out these
tasks, we would run:</p>

<pre><code>        shell&#62; dot -Tsvg teamwork.dot &#62; teamwork.svg</code></pre>

<p>Note: Files used in these examples can be downloaded from <a href="http://savage.net.au/Ron/html/graphviz2.marpa/teamwork.tgz">http://savage.net.au/Ron/html/graphviz2.marpa/teamwork.tgz</a>.</p>

<p>The link to the DOT language points to a definition of DOT's syntax, written
in a somewhat casual version of BNF: <a
    href="http://en.wikipedia.org/wiki/Backus%E2%80%93Naur_Form">Backus-Naur
    Form</a>. This is significant, as it's usually straight-forward to
translate a BNF description of a language into code within a lexer and
parser.</p></li>

<li><p>Rendering that same image, using a different language in the input file</p>

<p>Suppose that you decide that the Graphviz language is too complex, and hence
you write a wrapper around it, so end users can code in a simplified version of
that language. This actually happened, with the original effort available in
the now-obsolete Perl module <a
    href="http://metacpan.org/module/Graph::Easy">Graph::Easy</a>. Tels, the
author, devised his own very clever <a
    href="http://en.wikipedia.org/wiki/Little_languages">little language</a>,
which he called <a
    href="http://bloodgate.com/perl/graph/manual/"><code>Graph::Easy</code></a>.</p>

<p>When I took over maintenance of <a
    href="http://metacpan.org/module/Graph::Easy">Graph::Easy</a>, I found the
code too complex to read, let alone work on, so I wrote another implementation
of the lexer and parser, released as <a
    href="http://metacpan.org/module/Graph::Easy::Marpa">Graph::Easy::Marpa</a>.
I'll have much more to say about that in another article. For now, let's
discuss the previous graph rewritten in <code>Graph::Easy</code>
(<em>teamwork.easy</em>):</p>

<pre><code>        graph {rankdir: LR}
        node {fontsize: 12pt; shape: rectangle; style: filled, solid}
        edge {color: grey}
        [Teamwork]{fillcolor: yellow}
        -&#62; {label: is the key to}
        [Victory]{fillcolor: red}</code></pre>

<p>That's simpler for sure, but how does <a href="http://metacpan.org/module/Graph::Easy::Marpa">Graph::Easy::Marpa</a> work? Easy: <em>lex</em>, <em>parse</em>, render. More samples of <a href="http://metacpan.org/module/Graph::Easy::Marpa">Graph::Easy::Marpa</a>'s work are <a href="http://savage.net.au/Perl-modules/html/graph.easy.marpa/index.html">my Graph::Easy::Marpa examples</a>.</p></li>

</ol>

<p>It should be clear by now that lexing and parsing are in fact widespread,
although they often operate out of sight, with only their rendered output
visible to the average programmer, user, or web surfer.</p>

<p>All of these problems have in common a complex but well-structured source
text format, with a bit of hand-waving over the tacky details available to
authors of documents in HTML. In each case, it is the responsibility of the
programmer writing the lexer and parser to honour the intention of the original
text's author. We can only do that by recognizing each token in the input as a
discrete unit of meaning (where a word such as <code>print</code>
<em>means</em> to output something of the author's choosing), and by bringing
that meaning to fruition (for <code>print</code>, to make the output visible on
a device).</p>

<p>With all that I can safely claim that the ubiquity and success of lexing and
parsing justify their recognition as vital constituents in the world of
software engineering. Why study them indeed!</p>

<h1>Good Solutions and Home-grown Solutions</h1>

<p>There's another&mdash;more significant&mdash; reason to discuss lexing and
parsing: to train programmers, without expertise in such matters, to resist the
understandable urge to opt for using tools they are already familiar with, with
regexps being the obvious choice.</p>

<p>Sure, regexps suit many simple cases, and the old standbys of flex and bison
are always available, but now there's a new kid on the block: <a
    href="http://www.jeffreykegler.com/marpa">Marpa</a>. Marpa draws heavily
from theoretical work done over many decades, and comes in various forms:</p>

<dl>
<dt>libmarpa</dt>

<dd><p>Hand-crafted in C.</p></dd>

<dt><code>Marpa::XS</code></dt>

<dd><p>The Perl and C-based interface to the previous version of libmarpa.</p></dd>

<dt><code>Marpa::R2</code></dt>

<dd><p>The Perl and C-based interface to the most recent version of libmarpa.
This is the version I use.</p></dd>

<dt><code>Marpa::R2::Advanced::Thin</code></dt>

<dd><p>The newest and thinnest interface to libmarpa, which documents how to
make Marpa accessible to non-Perl languages.</p></dd>

</dl>

<p>The problem, of course, is whether or not any of these are a good, or even
excellent, choice. Good news! Marpa's advantages are huge.  It's well tested,
which alone is of great significance.  It has a Perl interface, so that I can
specify my task in Perl and let Marpa handle the details. It has its own <a
    href="http://groups.google.com/group/marpa-parser?hl=en">Marpa Google
    Group</a>. It's already used by various modules on the CPAN (see <a
    href="https://metacpan.org/search?q=Marpa">a search for Marpa on the
    CPAN</a>); Open Source says you can see exactly how other people use
it.</p>

<p>Even better, Marpa has a very simple syntax, once you get used to it, of
course! If you're having trouble, just post on the Google Group. (If you've
ever worked with flex and bison, you'll be astonished at how simple it is to
drive Marpa.) Marpa is also very fast, with libmarpa written in C. Its speed is
a bit surprising, because new technology usually needs some time to surpass
established technology while delivering the all-important stability.</p>

<p>Finally, Marpa is being improved all the time.  For instance, recently the
author eliminated the dependency on Glib, to improve portability. His work
continues, so that users can expect a series of incremental improvements for
some time to come.</p>

<p>I myself use Marpa in <a
    href="http://metacpan.org/module/Graph::Easy::Marpa">Graph::Easy::Marpa</a>
and <a href="http://metacpan.org/module/GraphViz2::Marpa">GraphViz2::Marpa</a>,
but this is not an article on Marpa in specific.</p>

<h1>The Lexer's Job Description</h1>

<p>As I mentioned earlier, the stages conveniently, run in English alphabetical
order. First you lex. Then you parse.</p>

<p>Here, I use <em>lexing </em> to mean the comparatively simple (compared to
parsing) process of tokenising a stream of text, which means chopping that
input stream into discrete tokens and identifying the type of each. The output
is a new stream, this time of stand-alone tokens. (Lexing is comparatively
simpler than parsing.)</p>

<p>Lexing does nothing more than identify tokens. Questions about the meanings
of those tokens or their acceptable order or anything else are matters for the
parser. The lexer will say: I have found another token and have identified it
as being of some type T. Hence, for each recognized token, the lexer will
produce two items:</p>

<ul>
<li>The type of the token</li>
<li>The value of the token</li>
</ul>

<p>Because the lexing process happens repeatedly, the lexer will produce an
output of an array of token elements, with each element needing at least these
two components: type and value.</p>

<p>In practice, I prefer to represent these elements as a hashref:</p>

<pre><code>        {
                count =&#62; $integer, # 1 .. N.
                name  =&#62; '',       # Unused.
                type  =&#62; $string,  # The type of the token.
                value =&#62; $value,   # The value from the input stream.
        }</code></pre>

<p>... with the array managed by an object of type <a
    href="http://metacpan.org/module/Set::Tiny">Set::Tiny</a>. The latter
module has many nice methods, making it very suitable for such work. Up until
recently I used <a href="http://metacpan.org/module/Set::Array">Set::Array</a>,
which I did not write but which I do now maintain. However, insights from a
recent report of mine, <a
    href="http://savage.net.au/Perl-modules/html/setops.report.html">Set-handling
    modules</a>, comparing a range of similar modules, has convinced me to
switch to <a href="http://metacpan.org/module/Set::Tiny">Set::Tiny</a>. For an
application which might best store its output in a tree, the Perl module <a
    href="http://metacpan.org/module/Tree::DAG_Node">Tree::DAG_Node</a> is
superb.</p>

<p>The <code>count</code> field, apparently redundant, is sometimes useful in
the clean-up phase of the lexer, which may need to combine tokens unnecessarily
split by the regexps used in lexing. Also, it is available to the parser if
needed, so I always include it in the hashref.</p>

<p>The <code>name</code> field really is unused, but gives people who fork or
sub-class my code a place to work with their own requirements, without worrying
that their edits will affect the fundamental code.</p>

<h1>The Parser's Job Description</h1>

<p>The parser concerns itself with the context in which each token appears,
which is a way of saying it cares about whether or not the sequence and
combination of tokens actually detected fits the expected grammar.</p>

<p>Ideally, the grammar is provided in BNF Form. This makes it easy to
translate into the form acceptable to Marpa. If you have a grammar in another
form, your work will probably be more difficult, simply because someone else
has <em>not</em> done the hard work of formalizing the grammar.</p>

<p>That's a parser. What's a grammar?</p>

<h1>Grammars and Sub-grammars</h1>

<p>I showed an example grammar earlier, for the <a
    href="http://www.graphviz.org/content/dot-language">DOT</a> format. How
does a normal person understand a block of text written in BNF? Training helps.
Besides that, I've gleaned a few things from practical experience.  To us
beginners eventually comes the realization that grammars, no matter how
formally defined, contain within them two sub-grammars:</p>

<h2>Sub-grammar #1</h2>

<p>One sub-grammar specifies what a token looks like, meaning the range of
forms it can assume in the input stream. If the lexer detects an
incomprehensible candidate, the lexer can generate an error, or it can activate
a strategy called <a
    href="http://blogs.perl.org/users/jeffrey_kegler/2011/11/marpa-and-the-ruby-slippers.html">Ruby
    Slippers</a> (no relation to the Ruby programming language). This technique
was named by Jeffrey Kegler, the author of Marpa.</p>

<p>In simple terms, the Ruby Slippers strategy fiddles the current token (or an
even larger section of the input stream) in a way that satisfies the grammar
and restarts processing at the new synthesized token. Marpa is arguably unique
in being able to do this.</p>

<h2>Sub-grammar #2</h2>

<p>The other sub-grammar specifies the allowable ways in which these tokens may
combine, meaning if they don't conform to the grammar, the code generates a
syntax error of some sort.</p>

<p>Easy enough?</p>

<p>I split the grammar into two sub-grammars because it helps me express my
Golden Rule of Lexing and Parsing: <em>encode the first sub-grammar into the
    lexer and the second into the parser</em>.</p>

<p>If you know what tokens look like, you can tokenize the input stream by
splitting it into separate tokens using a lexer. Then you give those tokens to
the parser for (more) syntax checking, and for interpretation of what the user
presumably intended with that specific input stream (combination of
tokens).</p>

<p>That separation between lexing and parsing gives a clear plan-of-attack for
any new project.</p>

<p>In case you think this is going to be complex, truly it only <em>sounds</em>
complicated. Yes, I've introduced a few new concepts (and will introduce a few
more), but don't despair. It's not really that difficult.</p>

<p>For any given grammar, you must somehow and somewhere manage the complexity
of the question "Is this a valid document?" Recognizing a token with a regex is
easy. (That's probably why so many people stop at the point of using regexes to
pick at documents instead of moving to parsing.) Keeping track of the context
in which that token appeared, and the context in which a grammar allows that
token, is hard.</p>

<p>The complexity of setting up and managing a formal grammar and its
implementation seems like a lot of work, but it's a specified and well
understood mechanism you don't have to reinvent every time. The lexer and
parser approach limits the code you have to write to two things: a set of rules
for how to construct tokens within a grammar and a set of rules for what
happens when we construct a valid combination of tokens. This limit allows you
to focus on the important part of the application&mdash;determining what a
document which conforms to the grammar means (the author's
<em>intention</em>)&mdash;and less on the mechanics of verifying that a
document matches the grammar.</p>

<p>In other words, you can focus on <em>what</em> you want to do with a
document more than <em>how</em> to do something with it.</p>

<h1>Coding the Lexer</h1>

<p>The lexer's job is to recognise tokens. Sub-grammar #1 specifies what those
tokens look like. Any lexer will have to examine the input stream, possibly one
character at a time, to see if the current input, appended to the immediately
preceding input, fits the definition of a token.</p>

<p>A programmer can write a lexer in many ways. I do so by combining regexps
with a DFA (<a
    href="http://en.wikipedia.org/wiki/Deterministic_finite_automaton">Discrete
    Finite Automaton</a>) module. The blog entry <a
    href="http://blogs.perl.org/users/andrew_rodland/2012/01/more-marpa-madness.html">More
    Marpa Madness</a> discusses using Marpa in the lexer (as well as in the
parser, which is where I use it).</p>

<p>What is a DFA? Abusing any reasonable definition, let me describe them
thusly. The <em>Deterministic</em> part means that given the same input at the
same stage, you'll always get the same result. The <em>Finite</em> part means
the input stream only contains a limited number of different tokens, which
simplifies the code. The <em>Automata</em> is, essentially, a software
machine&mdash;a program. DFAs are also often called STTs (State Transition
Tables).</p>

<p>How do you make this all work in Perl? <a
    href="https://metacpan.org/">MetaCPAN</a> is your friend! In particular, I
like to use <a
    href="http://metacpan.org/module/Set::FA::Element">Set::FA::Element</a> to
drive the process. For candidate alternatives I assembled a list of Perl
modules with relevance in the area, while cleaning up the docs for
<code>Set::FA</code>. See <a
    href="https://metacpan.org/module/Set::FA#See-Also">Alternatives to
    Set::FA</a>.  I did not write <a
    href="http://metacpan.org/module/Set::FA">Set::FA</a>, nor <a
    href="http://metacpan.org/module/Set::FA::Element">Set::FA::Element</a>,
but I now maintain them.</p>

<p>Transforming a grammar from BNF (or whatever form you use) into a DFA
provides:</p>

<ul>
    <li><p><em>Insight into the problem</em></p>

    <p>To cast BNF into regexps means you must understand exactly what the
    grammar definition is saying.</p></li>

    <li><p><em>Clarity of formulation</em></p>

    <p>You end up with a spreadsheet which simply and clearly encodes your
    understanding of tokens.</p>

    <p>Spreadsheet? Yes, I store the derived regexps, along with other
    information, in a spreadsheet. I even incorporate this spreadsheet into the
    source code.</p></li>

</ul>

<h1>Back to the Finite Automaton</h1>

<p>In practice, building a lexer is a process of reading and rereading, many
times, the definition of the BNF (here the <a
    href="http://www.graphviz.org/content/dot-language">DOT</a> language) to
build up the corresponding set of regexps to handle each case. This is
laborious work, no doubt about it.</p>

<p>For example, by using a regexp like <code>/[a-zA-Z_][a-zA-Z_0-9]*/</code>,
you can get Perl's regexp engine to intelligently gobble up characters as long
as they fit the definition. In plain English, this regexp says: start with a
letter, upper- or lower-case, or an underline, followed by 0 or more letters,
digits or underlines. Look familiar? It's very close to the Perl definition of
<code>\w</code>, but it disallows leading digits. Actually, <a
    href="http://www.graphviz.org/content/dot-language">DOT</a> disallows them
(in certain circumstances), but DOT does allow pure numbers in certain
circumstances.</p>

<p>What is the result of all of these hand-crafted regexps? They're
<em>data</em> fed into the DFA, along with the input stream. The output of the
DFA is a flag that signifies Yes or No, the input stream matches/doesn't match
the token definitions specified by the given regexps. Along the way, the DFA
calls a callback functions each time it recognizes a token, stockpiling them.
At the end of the run, you can output them as a stream of tokens, each with its
identifying type, as per The Lexer's Job Description I described earlier.</p>

<p>A note about callbacks: Sometimes it's easier to design a regexp to capture
more than seems appropriate, and to use code in the callback to chop up what's
been captured, outputting several token elements as a consequence.</p>

<p>Because developing the state transition table is such an iterative process,
I recommend creating various test files with all sorts of example programs, as
well as scripts with very short names to run the tests (short names because
you're going to be running these scripts an unbelievable number of
times...).</p>

<h1>States</h1>

<p>What are states and why do you care about them?</p>

<p>At any moment, the STT (automation, software machine) is in precisely
<em>on)</em> state. Perhaps it has not yet received even one token (so that
it's in the start state), or perhaps it has just finished processing the
previous one. Whatever the case, the code maintains information so as to know
exactly what state it is in, and this leads to knowing exactly what set of
tokens is now acceptable. That is, it has a set of tokens, any of which will be
legal in its current state.</p>

<p>The implication is this: you must associate each regexp with a specific
state and visa versa. Furthermore, the machine will remain in its current state
as long as each new input character matches a regexp belonging to the current
state. It will jump (make a transition) to a new state when that character does
not match.</p>

<h1>Sample Lexer Code</h1>

<p>Consider this simplistic code from the synopsis of <a
    href="http://metacpan.org/module/Set::FA::Element">Set::FA::Element</a>:</p>

<pre><code>        my($dfa) = Set::FA::Element -&#62; new
        (
                accepting   =&#62; ['baz'],
                start       =&#62; 'foo',
                transitions =&#62;
                [
                        ['foo', 'b', 'bar'],
                        ['foo', '.', 'foo'],
                        ['bar', 'a', 'foo'],
                        ['bar', 'b', 'bar'],
                        ['bar', 'c', 'baz'],
                        ['baz', '.', 'baz'],
                ],
        );</code></pre>

<p>In the <em>transitions</em> parameter the first line says: "foo" is a
state's name, and "b" is a regexp. Jump to state "bar" if the next input char
matches that regexp. Other lines are similar.</p>

<p>To use <a
    href="http://metacpan.org/module/Set::FA::Element">Set::FA::Element</a>,
you must prepare that transitions parameter matching this format. Now you see
the need for states and regexps.</p>

<p>This is code I've used, taken directly from <a
    href="http://metacpan.org/module/GraphViz2::Marpa::Lexer::DFA">GraphViz2::Marpa::Lexer::DFA</a>:</p>

<pre><code>        Set::FA::Element -&#62; new
        (
                accepting   =&#62; \@accept,
                actions     =&#62; \%actions,
                die_on_loop =&#62; 1,
                logger      =&#62; $self -&#62; logger,
                start       =&#62; $self -&#62; start,
                transitions =&#62; \@transitions,
                verbose     =&#62; $self -&#62; verbose,
        );</code></pre>

<p>Let's discuss these parameters.</p>

<dl>
<dt>accepting</dt>

<dd><p>This is an arrayref of state names. After processing the entire input
stream, if the machine ends up in one of these states, it has accepted that
input stream. All that means is that every input token matched an appropriate
regexp, where "appropriate" means every char matched the regexp belonging to
the current state, whatever the state was at the instant that char was
input.</p></dd>

<dt>actions</dt>

<dd>
<p>This is a hashref of function names so that the machine can call a function,
optionally, upon entering or leaving any state. That's how the stockpile for
recognized tokens works.</p>

<p>Because I wrote these functions myself and wrote the rules to attach each to
a particular combination of state and regexp, I encoded into each function the
knowledge of what type of token the DFA has matched. That's how the stockpile
ends up with (token, type) pairs to output at the end of the run.</p></dd>

<dt>die_on_loop</dt>

<dd>
<p>This flag, if true, tells the DFA to stop if none of the regexps belonging to the current state match the current input char.  Rather than looping forever, stop. Throw an exception.</p>

<p>You might wonder what stopping automatically is not the default, or even
mandatory. The default behavior allows you to try to recover from this bad
state, or at least give a reasonable error message, before dying.</p></dd>

<dt>logger</dt>

<dd><p>This is an (optional) logger object.</p></dd>

<dt>start</dt>

<dd><p>This is the name of the state in which the STT starts, so the code knows
which regexp(s) to try upon receiving the very first character of
input.</p></dd>

<dt>transitions</dt>

<dd><p>This is a potentially large arrayref which lists separately for all
states all the regexps which may possibly match the current input
char.</p></dd>

<dt>verbose</dt>

<dd>
<p>Specifies how much to report if the logger object is not defined.</p></dd>

</dl>

<p>With all of that configured, the next problem is how to prepare the grammar
in such a way as to fit into this parameter list.</p>

<h1>Coding the Lexer - Revisited</h1>

<p>The coder thus needs to develop regexps etc which can be fed directly into
the chosen DFA, here <a
    href="http://metacpan.org/module/Set::FA::Element">Set::FA::Element</a>, or
which can be transformed somehow into a format acceptable to that module. So
far I haven't actually said how I do that, but now it's time to be
explicit.</p>

<p>I use a spreadsheet with nine columns:</p>

<dl>
<dt>Start</dt>

<dd><p>This contains one word, "Yes", against the name of the state which is
the start state.</p></dd>

<dt>Accept</dt>

<dd><p>This contains the word "Yes" against the name of any state which will be
an accepting state (the machine has matched an input stream).</p></dd>

<dt>State</dt>

<dd><p>This is the name of the state.</p></dd>

<dt>Event</dt>

<dd><p>This is a regexp. The event will fire the current input char matches this
regexp.</p>

<p>Because the regexp belongs to a given state, we know the DFA will only
process regexps associated with the current state, of which there will be
usually one or or at most a few.</p>

<p>When there are multiple regexps per state, I leave all other columns
empty.</p></dd>

<dt>Next</dt>

<dd><p>The name of the "next" state to which the STT will jump if the current
char matches the regexp given on the same line of the spreadsheet (in the
current state of course).</p></dd>

<dt>Entry</dt>

<dd><p>The optional name of the function the DFA is to call upon (just before)
entry to the (new) state.</p></dd>

<dt>Exit</dt>

<dd><p>The optional name of the function the DFA is to call upon exiting from
the current state.</p></dd>

<dt>Regexp</dt>

<dd><p>This is a working column, in which I put formulas so that I can refer to
them in various places in the Event column. It is not passed to the DFA in the
transitions parameter.</p></dd>

<dt>Interpretation</dt>

<dd><p>Comments to myself.</p></dd>

</dl>

<p>I've put the STT for <a
    href="http://savage.net.au/Perl-modules/html/graphviz2.marpa/default.stt.html">STT
    for GraphViz2::Marpa</a> online.</p>

<p>This spreadsheet has various advantages:</p>

<p><em>Legibility.</em> It is very easy to read and to work with. Don't forget,
to start with you'll be basically switching back and forth between the grammar
definition document (hopefully in BNF) and this spreadsheet. I don't do much
(any) coding at this stage.</p>

<p><em>Exportability.</em> Because I have no code yet, there are several
possibilities. I could read the spreadsheet directly. The two problems with
this approach are the complexity of the code (in the external module which does
the reading of course), and the slowness of loading and running this code.</p>

<p>Because I use <a href="http://www.libreoffice.org/">LibreOffice</a> I can
either force end-users to install <a
    href="http://metacpan.org/module/OpenOffice::OODoc">OpenOffice::OODoc</a>,
or export the spreadsheet as an Excel file, in order to avail themselves of
this option. I have chosen to not support reading the<em>.ods </em>file
directly in the modules (<a
    href="http://metacpan.org/module/Graph::Easy::Marpa">Graph::Easy::Marpa</a>
and <a href="http://metacpan.org/module/GraphViz2::Marpa">GraphViz2::Marpa</a>)
I ship.</p>

<dt>I could alternately export the spreadsheet to a CSV file first. This way,
we can read a CSV file into the DFA fairly quickly, without loading the module
which reads spreadsheets.</p>

<p>Be careful here with LibreOffice, because it forces you to use Unicode for
the spreadsheet but exports odd character sequences, such as double-quotes as
the three byte sequence 0xe2, 0x80, 0x9c. When used in a regexp, this sequence
will never match a <em>real</em> double-quote in your input stream. Sigh. Do No
Evil. If only.</p>

<p>I could also incorporate the spreadsheet directly into my code. This is my
favorite approach. I do this in two stages. I export my data to a CSV file,
then append that file to the end of the source code of the module, after the
<code>__DATA__</code> token.</p>

<p>Such in-line data can be accessed effortlessly by the very neat and very
fast module <a
    href="http://metacpan.org/module/Data::Section::Simple">Data::Section::Simple</a>.
Because Perl has already loaded the module&mdash;and is executing
it&mdash;there is essentially no overhead whatsoever in reading data from
within it. Don't you just love Perl! And MetaCPAN of course. And a community
which contributes such wondrous code.</p>

<p>An advantage of this alternative is that it allows end users to edit the
shipped <em>.csv </em>or <em>.ods </em>files, after which they can use a
command line option on scripts to read their own file, overriding the built-in
STT.</p>

<p>After all this, it's just a matter of code to read and validate the
structure of the STT's data, then to reformat it into what <a
    href="http://metacpan.org/module/Set::FA::Element">Set::FA::Element</a>
demands.</p>

<h1>Coding the Parser</h1>

<p>At this point, you know how to incorporate the first sub-grammar into the
design and code of the lexer. You also know that the second sub-grammar must be
encoded into the parser, for that's how the parser performs syntax
checking.</p>

<p>How you do this depends intimately on which pre-existing module, if any, you
choose to use to aid the development of the parser. Because I choose Marpa
(currently <a href="http://metacpan.org/module/Marpa::R2">Marpa::R2</a>), I am
orienting this article to that module. However, only in the next article will I
deal in depth with Marpa.</p>

<p>Whichever tool you choose, think of the parsing process like this: Your
input stream is a set of pre-defined tokens (probably but necessarily output
from the lexer). You must now specify all possible legal combinations of those
tokens. This is the <em>syntax</em> of the language (or, more accurately, the
<em>remainder</em> of the syntax, because the first sub-grammar has already
handled all of the definitions of legal tokens).  At this point, assume all
incoming tokens are legal. In other words, the parser will not try to parse and
run a program containing token-based syntax errors, although it may contain
logic errors (even if written in Perl :-).</p>

<p>A combination of tokens which does not match any of the given legal
combinations can be immediately rejected as a syntax error. Keep in mind that
the friendliest compilers find as many syntax errors as possible per parse.</p>

<p>Because this check takes place on a token-by-token basis, you (ought to)
know precisely which token triggered the error, which means that you can emit a
nice error message, identifying the culprit and its context.</p>

<h1>Sample Parser Code</h1>

<p>Here's a sample of a <code>Marpa::R2</code> grammar (adapted from its
synopsis):</p>

<pre><code>        my($grammar) = Marpa::R2::Grammar -&#62; new
        ({
                actions =&#62; 'My_Actions',
                start   =&#62; 'Expression',
                rules   =&#62;
                [
                        { lhs =&#62; 'Expression', rhs =&#62; [qw/Term/] },
                        { lhs =&#62; 'Term',       rhs =&#62; [qw/Factor/] },
                        { lhs =&#62; 'Factor',     rhs =&#62; [qw/Number/] },
                        { lhs =&#62; 'Term',       rhs =&#62; [qw/Term Add Term/],
                                action =&#62; 'do_add'
                        },
                        { lhs =&#62; 'Factor',     rhs =&#62; [qw/Factor Multiply Factor/],
                                action =&#62; 'do_multiply'
                        },
                ],
                default_action =&#62; 'do_something',
        });</code></pre>

<p>Despite the differences between this and the calls to <code>Set::FA::Element
    -&#62; new()</code> in the lexer example, these two snippets are basically
the same:</p>

<dl>
<dt>actions</dt>

<dd><p>This is the name of a Perl package in which Marpa will look for actions
such as <code>do_add()</code> and <code>do_multiply()</code>. (Okay, the lexer
has no such option, as it defaults to the current package.)</p></dd>

<dt>start</dt>

<dd><p>This is the <em>lhs</em> name of the rule to start with, as with the
lexer.</p></dd>

<dt>rules</dt>

<dd><p>This is an arrayref of <em>rule descriptors</em> defining the syntax of
the grammar. This is the lexer's <em>transitions</em> parameter.</p></dd>

<dt>default_action</dt>

<dd><p>Use this (optional) callback as the action for any rule element which does not explicitly specify its own action.</p></dd>

</dl>

<p>The real problem is recasting the syntax from BNF, or whatever, into a set
of <em>rule descriptors</em>. How do you think about this problem? I suggest
contrast-and-compare real code with what the grammar says it must be.</p>

<p>Here's the <em>teamwork.dot</em> file I explained earlier.</p>

<pre><code>        digraph Perl
        {
        graph [ rankdir=&#34;LR&#34; ]
        node  [ fontsize=&#34;12pt&#34; shape=&#34;rectangle&#34; style=&#34;filled, solid&#34; ]
        edge  [ color=&#34;grey&#34; ]
        &#34;Teamwork&#34; [ fillcolor=&#34;yellow&#34; ]
        &#34;Victory&#34;  [ fillcolor=&#34;red&#34; ]
        &#34;Teamwork&#34; -&#62; &#34;Victory&#34; [ label=&#34;is the key to&#34; ]
        }</code></pre>

<p>In general, a valid <a href="http://www.graphviz.org/">Graphviz</a> (DOT)
graph must start with one of:</p>

<pre><code>        strict digraph $id {...} # Case 1. $id is a variable.
        strict digraph     {...}
        strict   graph $id {...} # Case 3
        strict   graph     {...}
               digraph $id {...} # Case 5
               digraph     {...}
                 graph $id {...} # Case 7
                 graph     {...}</code></pre>

<p>... as indeed this real code does. The graph's id is <em>Perl</em>, which is
case 5. If you've ever noticed that you can write a BNF as a tree (right?), you
can guess what comes next. I like to write my <em>rule descriptors</em> from
the root down.</p>

<p>Drawing this as a tree gives:</p>

<pre><code>             DOT's Grammar
                  |
                  V
        ---------------------
        |                   |
     strict                 |
        |                   |
        ---------------------
                  |
                  V
        ---------------------
        |                   |
     digraph     or       graph
        |                   |
        ---------------------
                  |
                  V
        ---------------------
        |                   |
       $id                  |
        |                   |
        ---------------------
                  |
                  V
                {...}</code></pre>

<h1>Connecting the Parser back to the Lexer</h1>

<p>Wait, what's this? Didn't I say that <em>strict</em> is optional. It's not
optional, not in the parser. It is optional in the DOT language, but I designed
the lexer, and I therein ensured it would necessarily output <em>strict =&#62;
    no</em> when the author of the graph omitted the <em>strict</em>.</p>

<p>By the time the parser runs, <em>strict</em> is no longer optional.  I did
this to make the life easier for consumers of the lexer's output stream, such
as authors of parsers. (Making the parser work less is often good.) </p>

<p>Likewise, for <em>digraph</em> 'v' <em>graph</em>, I designed the lexer to
output <em>digraph =&#62; 'yes'</em> in one case and <em>digraph =&#62;
    'no'</em> in the other. What does that mean? For <em>teamwork.dot</em>, the
lexer will output (in some convenient format) the equivalent of:</p>

<pre><code>        strict   =&#62; no
        digraph  =&#62; yes
        graph_id =&#62; Perl
        ...</code></pre>

<p>I chose <em>graph_id</em> because the DOT language allows other types of
ids, such as for nodes, edges, ports, and compass points.</p>

<p>All of this produces the first six Marpa-friendly rules:</p>

<pre><code>        [
        {   # Root-level stuff.
                lhs =&#62; 'graph_grammar',
                rhs =&#62; [qw/prolog_and_graph/],
        },
        {
                lhs =&#62; 'prolog_and_graph',
                rhs =&#62; [qw/prolog_definition graph_sequence_definition/],
        },
        {   # Prolog stuff.
                lhs =&#62; 'prolog_definition',
                rhs =&#62; [qw/strict_definition digraph_definition graph_id_definition/],
        },
        {
                lhs    =&#62; 'strict_definition',
                rhs    =&#62; [qw/strict/],
                action =&#62; 'strict', # &#60;== Callback.
        },
        {
                lhs    =&#62; 'digraph_definition',
                rhs    =&#62; [qw/digraph/],
                action =&#62; 'digraph', # &#60;== Callback.
        },
        {
                lhs    =&#62; 'graph_id_definition',
                rhs    =&#62; [qw/graph_id/],
                action =&#62; 'graph_id', # &#60;== Callback.
        },
        ...
        ]</code></pre>

<p>In English, all of this asserts that the graph as a whole consists of a
prolog thingy, then a graph sequence thingy. (Remember, I made up the names
<code>prolog_and_graph</code>, etc.</p>

<p>Next, a prolog consists of a strict thingy, which is now not optional, and
then.  a digraph thingy, which will turn out to match the lexer input of
<code>/^(di|)graph$/</code>, and the lexer output of <code>digraph =&#62;
    /^(yes|no)$/</code>, and then a graph_id, which is optional, and then some
other stuff which will be the precise definition of real live graphs,
represented by <code>{...}</code> in the list of the eight possible formats for
the prolog.</p>

<p>Whew.</p>

<h1>Something Fascinating about Rule Descriptors</h1>

<p>Take another look at those rule descriptors. They say <em>nothing</em> about
the values of the tokens! For instance, in <em>graph_id =&#62; Perl</em> what
happens to ids such as <em>Perl</em>. Nothing. They are ignored. That's just
how these grammars work.</p>

<p>Recall: it's the job of the <em>lexer</em> to identify valid graph ids based
on the first sub-grammar. By the time the data hits the parser, we know we have
a valid graph id, and as long as it plugs in to the <em>structure</em> of the
grammar in the right place, we are prepared to accept <em>any valid</em> graph
id. Hence <a href="http://metacpan.org/module/Marpa::R2">Marpa::R2</a> does not
even look at the graph id, which is a way of saying this one grammar works with
<em>every</em> valid graph id.</p>

<p>This point also raises the tricky discussion of whether a specific
implementation of lexer/parser code can or must keep the two phases separate,
or whether in fact you can roll them into one without falling into the
premature optimisation trap. I'll just draw a veil over that discussion, as
I've already declared my stance: my implementation uses two separate
modules.</p>

<h1>Chains and Trees</h1>

<p>If these rules have to be chained into a tree, how do you handle the root?
Consider this call to <a
    href="http://metacpan.org/module/Marpa::R2">Marpa::R2</a>'s
<code>new()</code> method:</p>

<pre><code>        my($grammar) = Marpa::R2::Grammar -&#62; new(... start =&#62; 'graph_grammar', ...);</code></pre>

<p><em>graph_grammar</em> is precisely the <em>lhs</em> in the first rule
descriptor.</p>

<p>After that, every rule's <em>rhs</em>, including the root's, must be defined
later in the list of rule descriptors. These definitions form the links in the
chain. If you draw this, you'll see the end result is a tree.</p>

<p>Here's the full <a href="http://metacpan.org/module/Marpa::R2">Marpa::R2</a>
grammar for DOT (as used in the <a
    href="http://metacpan.org/module/GraphViz2::Marpa">GraphViz2::Marpa</a>
module) as an image: <a
    href="http://savage.net.au/Ron/html/graphviz2.marpa/Marpa.Grammar.svg">http://savage.net.au/Ron/html/graphviz2.marpa/Marpa.Grammar.svg</a>.
I created this image with (you guessed it!) <a
    href="http://www.graphviz.org/">Graphviz</a> via <a
    href="http://metacpan.org/module/GraphViz2">GraphViz2</a>. I've added
numbers to node names in the tree, otherwise Graphviz would regard any two
identical numberless names as one and the same node.</p>

<h1>Less Coding, More Design</h1>

<p>Here I'll stop building the tree of the grammar (see the next article), and
turn to some design issues.</p>

<h1>My Rules-of-Thumb for Writing Lexers/Parsers</h1>

<p>The remainder of this document is to help beginners orient their thinking
when tackling a problem they don't yet have much experience in. Of course, if
you're an expert in lexing and parsing, feel free to ignore everything I say,
and if you think I've misused lexing/parsing terminology here, please let me
know.</p>

<h2>Eschew Premature Optimisation</h2>

<p>Yep, this old one again. It has various connotations:</p>

<ul>

    <li><p><em>The lexer and the parser</em></p>

    <p>Don't aim to combine the lexer and parser, even though that might
    eventually happen. Do wait until the design of each is clear and finalized,
    before trying to jam them into a single module (or program).</p></li>

    <li><p><em>The lexer and the tokens</em></p>

    <p>Do make the lexer identify the existence of tokens, but not identify
    their ultimate role or meaning.</p></li>

    <li><p><em>The lexer and context</em></p>

    <p>Don't make the lexer do context analysis. Do make the parser
    disambiguate tokens with multiple meanings, by using the context. Let the
    lexer do the hard work of identifying tokens.</p>

    <p>And <a href="http://en.wikipedia.org/wiki/Context_analysis">context
        analysis for businesses</a>, for example, is probably not what you want
    either.</p></li>

    <li><p><em>The lexer and syntax</em></p>

    <p>Don't make the lexer do syntax checking. This is effectively the same as
    the last point.</p></li>

    <li><p><em>The lexer and its output</em></p>

    <p>Don't minimize the lexer's output stream. For instance, don't force the
    code which reads the lexer's output to guess whether or not a
    variable-length set of tokens has ended. Output a specific token as a set
    terminator. The point of this token is to tell the parser exactly what's
    going on. Without such a token, the next token has to do double-duty:
    Firstly it tells the parser the variable-length part has finished and
    secondly, it represents itself. Such overloading is unnecessary.</p></li>

    <li><p><em>The State Transition Table</em></p>

    <p>In the STT, don't try to minimize the number of states, at least not
    until the code has stabilized (that is, it's no longer under [rapid]
    development).</p>

    <p>I develop my STTs in a spreadsheet program, which means a formula
    (regexp) stored in one cell can be referred to by any number of other
    cells. This is <em>very</em> convenient.</p></li>

</ul>

<h2>Divide and Conquer</h2>

<p>Hmmm, another ancient <a
    href="http://en.wikipedia.org/wiki/Aphorism">aphorism</a>. Naturally, these
persist precisely because they're telling us something important. Here, it
means study the problem carefully, and deal with each part (lexer, parser) of
it separately. Enough said.</p>

<h2>Don't Reinvent the Wheel</h2>

<p>Yes, I know <em>you'd</em> never do that.</p>

<p>The CPAN has plenty of Perl modules to help with things like the STT, such
as <a href="http://metacpan.org/module/Set::FA::Element">Set::FA::Element</a>.
Check its See Also (in <a
    href="http://metacpan.org/module/Set::FA">Set::FA</a>, actually) for other
STT helpers.</p>

<h2>Be Patient with the STT</h2>

<p>Developing the STT takes many iterations:</p>

<ul>
    <li><p>The test cases</p>

    <p>For each iteration, prepare a separate test case.</p></li>

    <li><p>The tiny script</p>

    <p>Have a tiny script which runs a single test. Giving it a
    short&mdash;perhaps temporary&mdash;name, makes each test just that little
    bit easier to run. You can give it a meaningful name later, when including
    it in the distro.</p></li>

    <li><p>The wrapper script</p>

    <p>Have a script which runs all tests.</p>

    <p>I keep the test data files in the data/ dir, and the scripts in the scripts/ dir. Then, creating tests in the t/ dir can perhaps use these two sets of helpers.</p>

    <p>Because I've only used <a
        href="http://metacpan.org/module/Marpa::R2">Marpa::R2</a> for graphical
    work, the output of the wrapper is a web page, which makes viewing the
    results simple. I like to include (short) input or output text files on
    such a page, beside the SVG images. That way I can see at a glance what the
    input was and hence I can tell what the output should be without switching
    to the editor's window.</p>

    <p>There's a little bit of effort initially, but after that it's
    <em>so</em> easy to check the output of the latest test.</p></li>

</ul>

<p>I've made available sample output from my wrapper scripts:</p>

<p><a href="http://savage.net.au/Perl-modules/html/graphviz2/">GraphViz2
    (non-Marpa)</a></p>

<p><a
    href="http://savage.net.au/Perl-modules/html/graphviz2.marpa/">GraphViz2::Marpa</a></p>

<p><a
    href="http://savage.net.au/Perl-modules/html/graph.easy.marpa/">Graph::Easy::Marpa</a></p>

<h2>Be Patient with the Grammar</h2>

<p>As with the STT, creating a grammar is at least for me very much a
trial-and-error process. I offer a few tips:</p>

<p>Tips:</p>

<ul>

    <li><p>Paper, not code</p>

    <p>A good idea is not to start by coding with your editor, but to draw the
    grammar as a tree, on paper.</p></li>

    <li><p>Watch out for alternatives</p>

    <p>This refers to when one of several tokens can appear in the input
    stream. Learn exactly how to draw that without trying to minimize the
    number of branches in the tree.</p>

    <p>Of course, you will still need to learn how to code such a construct.
    Here's a bit of code from <a
        href="http://metacpan.org/module/Graph::Easy::Marpa">Graph::Easy::Marpa</a>
    which deals with this (note: we're back to the <code>Graph::Easy</code>
    language from here on!):</p>

<pre><code>        {   # Graph stuff.
                lhs =&#62; 'graph_definition',
                rhs =&#62; [qw/graph_statement/],
        },
        {
                lhs =&#62; 'graph_statement', # 1 of 3.
                rhs =&#62; [qw/group_definition/],
        },
        {
                lhs =&#62; 'graph_statement', # 2 of 3.
                rhs =&#62; [qw/node_definition/],
        },
        {
                lhs =&#62; 'graph_statement', # 3 of 3.
                rhs =&#62; [qw/edge_definition/],
        },</code></pre>

<p>This is telling you that a graph thingy can be any one of a group, node, or
edge. It's <a href="http://metacpan.org/module/Marpa::R2">Marpa::R2</a>'s job
to try these alternatives in order to see which (if any) matches the input
stream. This ruleset represents a point in the input stream where one of
several <em>alternatives</em> can appear.</p>

<p>The tree looks like:</p>

<pre><code>                        graph_definition
                               |
                               V
                        graph_statement
                               |
                               V
            ---------------------------------------
            |                  |                  |
            V                  V                  V
     group_definition   node_definition    edge_definition</code></pre>

    <p>My comment <code>3 of 3</code> says an edge can stand alone.</p></li>

    <li><p>Watch out for sequences</p>

    <p>... but consider the <em>node_definition</em>:</p>

<pre><code>        {   # Node stuff.
                lhs =&#62; 'node_definition',
                rhs =&#62; [qw/node_sequence/],
                min =&#62; 0,
        },
        {
                lhs =&#62; 'node_sequence', # 1 of 4.
                rhs =&#62; [qw/node_statement/],
        },
        {
                lhs =&#62; 'node_sequence', # 2 of 4.
                rhs =&#62; [qw/node_statement daisy_chain_node/],
        },
        {
                lhs =&#62; 'node_sequence', # 3 of 4.
                rhs =&#62; [qw/node_statement edge_definition/],
        },
        {
                lhs =&#62; 'node_sequence', # 4 of 4.
                rhs =&#62; [qw/node_statement group_definition/],
        },</code></pre>

    <p>Here <code>3 of 4</code> tells you that nodes can be followed by
    edges.</p>

    <p>A realistic sample is: <code>[node_1] -&#62; [node_2]</code>, where
    <code>[x]</code> is a node and <code>-&#62;</code> is an edge, because an
    edge can be followed by a node (applying <code>3 of 4</code>).</p>

    <p>This full example represents a point in the input stream where one of
    several specific <em>sequences</em> of tokens are allowed/expected. Here's
    the <em>edge_definition</em>:</p>

<pre><code>        {   # Edge stuff.
                lhs =&#62; 'edge_definition',
                rhs =&#62; [qw/edge_sequence/],
                min =&#62; 0,
        },
        {
                lhs =&#62; 'edge_sequence', # 1 of 4.
                rhs =&#62; [qw/edge_statement/],
        },
        {
                lhs =&#62; 'edge_sequence', # 2 of 4.
                rhs =&#62; [qw/edge_statement daisy_chain_edge/],
        },
        {
                lhs =&#62; 'edge_sequence', # 3 of 4.
                rhs =&#62; [qw/edge_statement node_definition/],
        },
        {
                lhs =&#62; 'edge_sequence', # 4 of 4.
                rhs =&#62; [qw/edge_statement group_definition/],
        },
        {
                lhs =&#62; 'edge_statement',
                rhs =&#62; [qw/edge_name attribute_definition/],
        },
        {
                lhs    =&#62; 'edge_name',
                rhs    =&#62; [qw/edge_id/],
                action =&#62; 'edge_id',
        },</code></pre></li>
</ul>

<p>But, I have to stop somewhere, so...</p>

<h1>Wrapping Up and Winding Down</h1>

<p>I hope I've clarified what can be a complex and daunting part of
programming, and I also hope I've convinced you that working in Perl, with the
help of a spreadsheet, is the modern (or "only") path to lexer and parser
bliss.</p>

<p><em><a href="http://savage.net.au/index.html">Ron Savage</a></em> is a
longtime Perl programmer and prolific CPAN contributor.</p>
        </div>



    </div>
    <div class="asset-footer"></div>
</div>




                            <div class="content-nav">
                                <a href="/pub/2012/08/">&laquo; August 2012</a> |
                                <a href="/pub/">Main Index</a> |
                                <a href="/pub/archives.html">Archives</a>
                                | <a href="/pub/2012/11/">November 2012 &raquo;</a>
                            </div>


                        </div>
                    </div>


                    <div id="beta">
    <div id="beta-inner">


    
    <div class="widget-what-is-perl widget">
    <div class="widget-content widget-content-what-is-perl">
       Visit the home of the  Perl programming language: <a href="http://www.perl.org/">Perl.org</a
    </div>
</div>
<div class="widget-find-out-more widget-archives widget">
    <div class="widget-content">
        <ul>
            <li><a href="http://www.perl.org/get.html">Download</a></li>
            <li><a href="http://perldoc.perl.org/">Documentation</a></li>
            <li><a href="http://blogs.perl.org/">Perl Bloggers</a></li>
            <li><a href="http://news.perlfoundation.org/">Foundation News</a></li>
        </ul>
    </div>
</div><div class="widget-tcpc widget">
<h3 class="widget-header">Sponsored by</h3>
    <div class="widget-content">
        <a href="http://training.perl.com/" alt="Perl Training" target="_blank"><img src="/i/tcpc.png" width="150" height="50"></a>
    </div>
</div>

<div class="widget-syndication widget">
    <div class="widget-content">
        <ul>
            <li><img src="/mt-static/images/status_icons/feed.gif" alt="Subscribe to feed" width="9" height="9" /> <a href="/pub/atom.xml">Subscribe to this website's feed</a></li>

        </ul>
    </div>
</div>
<div class="widget-archive-monthly widget-archive widget">
    <h3 class="widget-header">Monthly <a href="/pub/archives.html">Archives</a></h3>
    <div class="widget-content">
        <ul>
        
            <li><a href="/pub/2014/02/">February 2014 (1)</a></li>
        
    
        
            <li><a href="/pub/2014/01/">January 2014 (1)</a></li>
        
    
        
            <li><a href="/pub/2013/10/">October 2013 (1)</a></li>
        
    
        
            <li><a href="/pub/2013/01/">January 2013 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/12/">December 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/11/">November 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/10/">October 2012 (2)</a></li>
        
    
        
            <li><a href="/pub/2012/08/">August 2012 (2)</a></li>
        
    
        
            <li><a href="/pub/2012/06/">June 2012 (11)</a></li>
        
    
        
            <li><a href="/pub/2012/05/">May 2012 (18)</a></li>
        
    
        
            <li><a href="/pub/2012/04/">April 2012 (17)</a></li>
        
    
        
            <li><a href="/pub/2012/02/">February 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/12/">December 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/09/">September 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/08/">August 2011 (2)</a></li>
        
    
        
            <li><a href="/pub/2011/06/">June 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/05/">May 2011 (3)</a></li>
        
    
        
            <li><a href="/pub/2011/04/">April 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/03/">March 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/02/">February 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/01/">January 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/11/">November 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/10/">October 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/09/">September 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/08/">August 2010 (3)</a></li>
        
    
        
            <li><a href="/pub/2010/07/">July 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/04/">April 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/03/">March 2010 (4)</a></li>
        
    
        
            <li><a href="/pub/2008/05/">May 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/04/">April 2008 (2)</a></li>
        
    
        
            <li><a href="/pub/2008/03/">March 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/02/">February 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/01/">January 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/12/">December 2007 (2)</a></li>
        
    
        
            <li><a href="/pub/2007/09/">September 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/08/">August 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/07/">July 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/06/">June 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/05/">May 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/04/">April 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/03/">March 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/02/">February 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/01/">January 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/12/">December 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/11/">November 2006 (2)</a></li>
        
    
        
            <li><a href="/pub/2006/10/">October 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/09/">September 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/08/">August 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/07/">July 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/06/">June 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/05/">May 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/04/">April 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/03/">March 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/02/">February 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2006/01/">January 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/12/">December 2005 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/11/">November 2005 (3)</a></li>
        
    
        
            <li><a href="/pub/2005/10/">October 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/09/">September 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/08/">August 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/07/">July 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/06/">June 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/05/">May 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/04/">April 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/03/">March 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2005/02/">February 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/01/">January 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/12/">December 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/11/">November 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/10/">October 2004 (5)</a></li>
        
    
        
            <li><a href="/pub/2004/09/">September 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/08/">August 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/07/">July 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/06/">June 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/05/">May 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2004/04/">April 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/03/">March 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/02/">February 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/01/">January 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/12/">December 2003 (4)</a></li>
        
    
        
            <li><a href="/pub/2003/11/">November 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/10/">October 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/09/">September 2003 (6)</a></li>
        
    
        
            <li><a href="/pub/2003/08/">August 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/07/">July 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/06/">June 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/05/">May 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/04/">April 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/03/">March 2003 (10)</a></li>
        
    
        
            <li><a href="/pub/2003/02/">February 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/01/">January 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/12/">December 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/11/">November 2002 (9)</a></li>
        
    
        
            <li><a href="/pub/2002/10/">October 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/09/">September 2002 (11)</a></li>
        
    
        
            <li><a href="/pub/2002/08/">August 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/07/">July 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/06/">June 2002 (4)</a></li>
        
    
        
            <li><a href="/pub/2002/05/">May 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/04/">April 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/03/">March 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/02/">February 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/01/">January 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/12/">December 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/11/">November 2001 (5)</a></li>
        
    
        
            <li><a href="/pub/2001/10/">October 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/09/">September 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/08/">August 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/07/">July 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/06/">June 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/05/">May 2001 (11)</a></li>
        
    
        
            <li><a href="/pub/2001/04/">April 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/03/">March 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/02/">February 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/01/">January 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2000/12/">December 2000 (6)</a></li>
        
    
        
            <li><a href="/pub/2000/11/">November 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/10/">October 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/09/">September 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/08/">August 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/07/">July 2000 (5)</a></li>
        
    
        
            <li><a href="/pub/2000/06/">June 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/05/">May 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/04/">April 2000 (3)</a></li>
        
    
        
            <li><a href="/pub/2000/03/">March 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/02/">February 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/01/">January 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/12/">December 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/11/">November 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/10/">October 1999 (5)</a></li>
        
    
        
            <li><a href="/pub/1999/09/">September 1999 (4)</a></li>
        
    
        
            <li><a href="/pub/1999/08/">August 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/07/">July 1999 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/06/">June 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/04/">April 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/03/">March 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/01/">January 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/12/">December 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/11/">November 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/07/">July 1998 (2)</a></li>
        
    
        
            <li><a href="/pub/1998/06/">June 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/03/">March 1998 (1)</a></li>
        
        </ul>
    </div>
</div>
        
    

<div class="widget-powered widget">
    <div class="widget-content">
        <a href="http://www.movabletype.com/"><img src="/mt-static/images/bug-pbmt-white.png" alt="Powered by Movable Type 5.13-en" width="120" height="75" /></a>
    </div>
</div>



    </div>
</div>






                </div>
            </div>


            <div id="footer">
    <div id="footer-inner">
        <div id="footer-content">
            <div class="widget-powered widget">
                <div class="widget-content">
                    Powered by <a href="http://www.movabletype.com/" rel="generator">Movable Type Pro</a>
                </div>
            </div>

            <div class="widget-creative-commons widget">
                <div class="widget-content">
                    This blog is licensed under a <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/">Creative Commons License</a>.
                </div>
            </div>

        </div>
    </div>
</div>



        </div>
    </div>
</body>
</html>
