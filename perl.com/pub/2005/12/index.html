<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" id="sixapart-standard">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="generator" content="Movable Type Pro 5.13-en" />
<link rel="stylesheet" href="/pub/styles.css" type="text/css" />
<link rel="start" href="/pub/" title="Home" />
<link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/pub/atom.xml" />
<script type="text/javascript" src="/pub/mt.js"></script>
<!--
<rdf:RDF xmlns="http://web.resource.org/cc/"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<Work rdf:about="/pub/">
<dc:title>Perl.com</dc:title>
<dc:description>news and views of the Perl programming language</dc:description>
<license rdf:resource="http://creativecommons.org/licenses/by-nc-nd/3.0/" />
</Work>
<License rdf:about="http://creativecommons.org/licenses/by-nc-nd/3.0/">
</License>
</rdf:RDF>
-->

<script type="text/javascript">

 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-50555-22']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type =
   'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
   'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0];
   s.parentNode.insertBefore(ga, s);
 })();

</script>
<script type='text/javascript' src='http://partner.googleadservices.com/gampad/google_service.js'></script>
<script type='text/javascript'>
GS_googleAddAdSenseService("ca-pub-4136420132070439");
GS_googleEnableAllServices();
</script>
<script type='text/javascript'>
GA_googleAddSlot("ca-pub-4136420132070439", "Perl_728x90");
</script>
<script type='text/javascript'>GA_googleFetchAds();</script>
    <title>Perl.com: December 2005 Archives</title>


    <link rel="prev" href="/pub/2005/11/" title="November 2005" />
    <link rel="next" href="/pub/2006/01/" title="January 2006" />

</head>
<body id="perl-com" class="mt-archive-listing mt-datebased-monthly-archive layout-wt">
    <div id="container">
        <div id="container-inner">


            <div id="header">
    <div id="header-inner">
        <div id="header-content">
        <span id="top_advert"> 
<!-- Put any landscape advert in here -->
<!-- Perl_728x90 -->
<script type='text/javascript'>
GA_googleFillSlot("Perl_728x90");
</script>
        </span> 



            <div id="header-name"><a href="/pub/" accesskey="1">Perl.com</a></div>
            <div id="header-description">news and views of the Perl programming language</div>




        </div>
    </div>
</div>



            <div id="content">
                <div id="content-inner">


                    <div id="alpha">
                        <div id="alpha-inner">


                            <h1 id="page-title" class="archive-title">December 2005 Archives</h1>





                            
                            <div id="entry-856" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2005/12/21/a_timely_start.html" rel="bookmark">A Timely Start</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author">Jean-Louis Leroy</span> on <abbr class="published" title="2005-12-21T00:00:00-08:00">December 21, 2005 12:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            
<!-- sidebar begins -->
<!-- don't move sidebars-->
<!-- sidebar ends -->
<p>This article is a follow-up to the lightning talk I delivered at the recent YAPC::Europe 2005 that took place in Braga, Portugal: "Perl Vs. Korn Shell: 1-1." I presented two case studies taken from my experience as Perl expert at the Agency (they have asked me to remain discreet about their real name, but rest reassured, it's not the CIA, it's a European agency).</p>

<p>In the first case, I explained how I had rewritten a heavily used Korn shell script in Perl, in the process bringing its execution time from a half-hour down to ten seconds. The audience laughed and applauded loudly at that point of my talk.</p>

<p>Then I proceeded to the second case, where the situation was not so rosy for Perl. One of my colleagues had rewritten a simple <code>ksh</code> script that did a few computations then transferred a file over FTP. The rewrite in Perl ran ten times slower.</p>

<h3>Slower?</h3>

<p>My job was to investigate. I found a couple of obvious ways of speeding up the Perl script. First I removed hidden calls to subprocesses:</p>

<pre><code>use Shell qw( date which );
# ...
$now   = date();
$where = which 'some_command';</code></pre>

<p>Then I replaced a few <code>use</code> directives with calls to <code>require</code>. If you're going to use the features contained in a module only conditionally, <code>require</code> may be preferable, because <code>perl</code> always executes <code>use</code> directives at compile time.</p>

<p>Take this code:</p>

<pre><code>use Pod::Usage;

# $help set from command-line option
if ($help) {
    pod2usage(-exitstatus =&gt; 0);
}</code></pre>

<p>This loads <a href="http://search.cpan.org/perldoc?Pod::Usage">Pod::Usage</a>, even if <code>$help</code> is false. The following change won't help, though:</p>

<pre><code># $help set from command-line option
if ($help) {
    use Pod::Usage;
    pod2usage(-exitstatus =&gt; 0);
}</code></pre>

<p>This just gives the illusion that the program loads <code>Pod::Usage</code> only when necessary. The right answer is:</p>

<pre><code># $help set from command-line option
if ($help) {
    require Pod::Usage;
    Pod::Usage::pod2usage(-exitstatus =&gt; 0);
}</code></pre>

<p>After these changes the situation had improved: the Perl version was only five times slower now. I pulled out the profiler. Sadly, most of the time still went to loading modules, especially <a href="http://search.cpan.org/perldoc?Net::FTP">Net::FTP</a>. Of course, we <em>always</em> needed that.</p>

<p>If you dig in, you realize that <code>Net::FTP</code> is not the only culprit. It loads other modules that in turn load other modules, and so on. Here is the complete list:</p>

<pre><code>/.../libnet.cfg
Carp.pm
Config.pm
Errno.pm
Exporter.pm
Exporter/Heavy.pm
IO.pm
IO/Handle.pm
IO/Socket.pm
IO/Socket/INET.pm
IO/Socket/UNIX.pm
Net/Cmd.pm
Net/Config.pm
Net/FTP.pm
SelectSaver.pm
Socket.pm
Symbol.pm
Time/Local.pm
XSLoader.pm
strict.pm
vars.pm
warnings.pm
warnings/register.pm</code></pre>

<p>This is not by itself a bad thing: modules are there to promote code reuse, after all, so in theory, the more modules a module uses, the better. It usually shows that it's not reinventing wheels. Modules are good and account for much of Perl's success. You can solve so many problems in ten lines: use this, use that, use this too, grab this from CPAN, write three lines yourself--bang! problem solved.</p>

<csperl file="grab" domain="on" record="b/1795" template="b/article_sidebar2.view">













<h3>Why Was Perl Slower?</h3>

<p>In my case, though, the sad truth was that the Perl version of the FTP script spent 95 percent of its time getting started; the meat of the script, the code written by my colleague, accounted for only five percent of the execution time. The <code>ksh</code> version, on the other hand, started to work on the job nearly immediately.</p>

<p>My lightning talk ended with the conclusion that Perl needs a compiler--badly. In the final slides I addressed some popular objections against this statement, the more important one being that "it won't make your code run faster." I know: I want it to <em>start</em> faster.</p>


<p>Several hackers came for a discussion after my talk. Some of their objections were interesting but missed the point. ("The total execution time is good enough." Me: "It's not up to me to decide, there are specs; and the FTP version <em>is</em> five times faster. That's what I'm talking about.")</p>

<p>However, other remarks suggested that some stones remained unturned. One of the attendants timed <code>perl -MNet::FTP -e 0</code> under my eyes and indeed it loaded quite fast on his laptop. It loaded faster than on the Agency's multi-CPU, 25000-euro computers. How come?</p>

<p>The answer turned out to be the length of <code>PERL5LIB</code>. The Agency has collections of systems that build upon one another. Each system may contain one or several directories hosting Perl modules. The build system produces a value for <code>PERL5LIB</code> that includes the Perl module directories for the system, followed by the module directories of all of the systems it builds upon, recursively.</p>

<p>I wrote a small module, <code>Devel::Dependencies</code>, which uses <code>BEGIN</code> and <code>CHECK</code> blocks to find all of the modules that a Perl program loads. Optionally, it lists the path to each module, the position of that path within <code>@INC</code>, and the sum of all of the positions at the end. This gives a good idea of the number of directory searches Perl has to perform when loading modules.</p>

<p>I used it on a one-line script that just says <code>use Net::FTP</code>. Here's the result:</p>

<pre><code>$ <strong>echo $PERL5LIB</strong>
XxB:
/build/MAP/CONFIG!11.213/idl/stubs:
/build/MAP/CONFIG!11.213/perl/lib:
/build/MAP/CONFIG!11.213/pm:
/build/LIB/UTILS!11.151/ftpstuff:
/build/LIB/UTILS!11.151/alien/PA-RISC2.0:
/build/LIB/UTILS!11.151/alien:
/build/LIB/UTILS!11.151/perl/lib:
/build/LIB/UTILS!11.151/pm:
/build/MAP/MAP_SERVER!11.197/pm:
/build/CONTROL/KLIBS!11.132/idl/stubs:
/build/CONTROL/KLIBS!11.132/perl/lib:
/build/CONTROL/KLIBS!11.132/pm:
/build/CONTROL/ACME!11.177/idl/stubs:
/build/CONTROL/ACME!11.177/pm:
/build/CONTROL/ADAPTER!11.189/pm:
/build/MAP/HMI!1.12.165/idl/stubs:
/build/CONTROL/KERNEL_INIT!11.130/pm:
/build/CONTROL/BUSINESS!11.176/pm:
/build/CONTROL/KERNEL!11.130/pm:
/build/BASIC/SSC!11.78/pm:
/build/BASIC/LOG!11.78/perl/lib:
/build/BASIC/LOG!11.78/pm:
/build/BASIC/BSC!11.77/pm:
/build/BASIC/POLYORB!11.39/idl/stubs:
/build/BASIC/TEST!11.58/perl/lib/ldap/interface:
/build/BASIC/TEST!11.58/perl/lib/ldap:
/build/BASIC/TEST!11.58/perl/lib:
/build/BASIC/TEST!11.58/pm:
/build/BASIC/TANGRAM!11.53/perl/lib:
/build/BASIC/TANGRAM!11.53/pm:
/build/LIB/PERL!5.6.1.1.39/lib/site_perl:
/build/LIB/PERL!5.6.1.1.39/lib:
/build/LIB/PERL!5.6.1.1.39/alien:
/build/LIB/PERL!5.6.1.1.39/pm:
/build/LIB/GNU!11.30/pm:
/build/CM/LIB!2.1.221/perl/lib/wle/interface:
/build/CM/LIB!2.1.221/perl/lib:
/build/CM/LIB!2.1.221/alien:
/build/CM/LIB!2.1.221/pm:
/build/CM/CM_LIB!2.1.96/perl/lib/MakeCfg:
/build/CM/CM_LIB!2.1.96/perl/lib:
/build/CM/CM_LIB!2.1.96/pm:
/build/CM/EXT_LIBS!2.1.6/perl/lib:
/build/CM/EXT_LIBS!2.1.6/alien:
/build/CM/EXT_LIBS!2.1.6/pm:
XxE

$ <strong>perl -c -MDevel::Dependencies=origin ftp.pl</strong>
Devel::Dependencies 23 dependencies:
  /build/LIB/UTILS!11.151/ftpstuff/Net/libnet.cfg /build/LIB/UTILS!11.151/ftpstuff/Net/libnet.cfg (6)
  Carp.pm /build/LIB/PERL!5.6.1.1.39/lib/Carp.pm (38)
  Config.pm /build/LIB/PERL!5.6.1.1.39/lib/PA-RISC2.0/Config.pm (37)
  Errno.pm /build/LIB/PERL!5.6.1.1.39/lib/PA-RISC2.0/Errno.pm (37)
  Exporter.pm /build/LIB/PERL!5.6.1.1.39/lib/Exporter.pm (38)
  Exporter/Heavy.pm /build/LIB/PERL!5.6.1.1.39/lib/Exporter/Heavy.pm (38)
  IO.pm /build/LIB/PERL!5.6.1.1.39/lib/PA-RISC2.0/IO.pm (37)
  IO/Handle.pm /build/LIB/PERL!5.6.1.1.39/lib/PA-RISC2.0/IO/Handle.pm (37)
  IO/Socket.pm /build/LIB/PERL!5.6.1.1.39/lib/PA-RISC2.0/IO/Socket.pm (37)
  IO/Socket/INET.pm /build/LIB/PERL!5.6.1.1.39/lib/IO/Socket/INET.pm (38)
  IO/Socket/UNIX.pm /build/LIB/PERL!5.6.1.1.39/lib/IO/Socket/UNIX.pm (38)
  Net/Cmd.pm /build/LIB/UTILS!11.151/ftpstuff/Net/Cmd.pm (6)
  Net/Config.pm /build/LIB/UTILS!11.151/ftpstuff/Net/Config.pm (6)
  Net/FTP.pm /build/LIB/UTILS!11.151/ftpstuff/Net/FTP.pm (6)
  SelectSaver.pm /build/LIB/PERL!5.6.1.1.39/lib/SelectSaver.pm (38)
  Socket.pm /build/LIB/PERL!5.6.1.1.39/lib/PA-RISC2.0/Socket.pm (37)
  Symbol.pm /build/LIB/PERL!5.6.1.1.39/lib/Symbol.pm (38)
  Time/Local.pm /build/LIB/PERL!5.6.1.1.39/lib/Time/Local.pm (38)
  XSLoader.pm /build/LIB/PERL!5.6.1.1.39/lib/PA-RISC2.0/XSLoader.pm (37)
  strict.pm /build/LIB/PERL!5.6.1.1.39/lib/strict.pm (38)
  vars.pm /build/LIB/PERL!5.6.1.1.39/lib/vars.pm (38)
  warnings.pm /build/LIB/PERL!5.6.1.1.39/lib/warnings.pm (38)
  warnings/register.pm /build/LIB/PERL!5.6.1.1.39/lib/warnings/register.pm (38)
Total directory searches: 739
ftp.pl syntax OK</code></pre>

<p>Now it looked like I had found the wasted time.</p>













<h3>Making Perl Faster</h3>

<p>Still pushing, I wrote a script that consolidates <code>@INC</code>. It creates a directory tree containing the union of all of the directory trees found in <code>@INC</code> and then populates them with symlinks to the .pm files. I could replace the lengthy <code>PERL5LIB</code> with one that contained just one directory. Here's the resulting dependency listing:</p>

<pre><code>ler@cougar: <strong>cm_perl -I lib/MAP/CONFIG -c -MDevel::Dependencies=origin ftp.pl</strong>
  Devel::Dependencies 23 dependencies:
  Carp.pm lib/MAP/CONFIG/Carp.pm (2)
  Config.pm lib/MAP/CONFIG/PA-RISC2.0/Config.pm (1)
  Errno.pm lib/MAP/CONFIG/PA-RISC2.0/Errno.pm (1)
  Exporter.pm lib/MAP/CONFIG/Exporter.pm (2)
  Exporter/Heavy.pm lib/MAP/CONFIG/Exporter/Heavy.pm (2)
  IO.pm lib/MAP/CONFIG/PA-RISC2.0/IO.pm (1)
  IO/Handle.pm lib/MAP/CONFIG/PA-RISC2.0/IO/Handle.pm (1)
  IO/Socket.pm lib/MAP/CONFIG/PA-RISC2.0/IO/Socket.pm (1)
  IO/Socket/INET.pm lib/MAP/CONFIG/IO/Socket/INET.pm (2)
  IO/Socket/UNIX.pm lib/MAP/CONFIG/IO/Socket/UNIX.pm (2)
  Net/Cmd.pm lib/MAP/CONFIG/Net/Cmd.pm (2)
  Net/Config.pm lib/MAP/CONFIG/Net/Config.pm (2)
  Net/FTP.pm lib/MAP/CONFIG/Net/FTP.pm (2)
  SelectSaver.pm lib/MAP/CONFIG/SelectSaver.pm (2)
  Socket.pm lib/MAP/CONFIG/PA-RISC2.0/Socket.pm (1)
  Symbol.pm lib/MAP/CONFIG/Symbol.pm (2)
  Time/Local.pm lib/MAP/CONFIG/Time/Local.pm (2)
  XSLoader.pm lib/MAP/CONFIG/PA-RISC2.0/XSLoader.pm (1)
  lib/MAP/CONFIG/Net/libnet.cfg lib/MAP/CONFIG/Net/libnet.cfg (2)
  strict.pm lib/MAP/CONFIG/strict.pm (2)
  vars.pm lib/MAP/CONFIG/vars.pm (2)
  warnings.pm lib/MAP/CONFIG/warnings.pm (2)
  warnings/register.pm lib/MAP/CONFIG/warnings/register.pm (2)
Total directory searches: 39
ftp.pl syntax OK</code></pre>

<p>Why does Perl find <em>Carp.pm</em> in the <em>second</em> directory, considering Perl should search the directory passed via <code>-I</code> first? <code>perl -V</code> gives the answer:</p>

<pre><code>    (extract)
  @INC:
    lib/MAP/CONFIG/PA-RISC2.0
    lib/MAP/CONFIG
    XxB
    /build/LIB/UTILS!11.162/ftpstuff/PA-RISC2.0
    /build/LIB/UTILS!11.162/ftpstuff
    /build/LIB/UTILS!11.162/alien/PA-RISC2.0</code></pre>

<p>Under some circumstances, Perl adds architecture-specific paths to <code>@INC</code>; for more information on this, see the description of <code>PER5LIB</code> in the <code>perlrun</code> manpage.</p>

<p>Finally I timed the <em>ftp.pl</em> program twice: with the normal <code>PERL5LIB</code> and with the consolidated <code>PERL5LIB</code>. Here are the results (<code>u</code> stands for "user time," <code>s</code> for "system time," and <code>u+s</code> is the sum; times are in seconds):</p>

<pre><code>Running ft_ftp.pl..
47-element PERL5LIB  : u: 0.07 s: 0.20 u+s: 0.27
Consolidated PERL5LIB: u: 0.05 s: 0.04 u+s: 0.09</code></pre>

<p>Therefore, I recommended incorporating the consolidation script as part of the process that builds the various systems.</p>

<h3>Conclusion</h3>

<p>It may seem silly to have a <code>PERL5LIB</code> that contains 47 directories. On the other hand, that kind of situation naturally arises once you try to use Perl in complex developments such as the Agency's. After all, Perl "is a real programming language," we like to say, so why can't it do what C++ or Ada can do?</p>

<p>I still think that we need a Perl compiler. The problem is not the length of <code>PERL5LIB</code>, it's the fact that Perl processes it each time it runs the script. My workaround, in effect, amounts to "compiling" a fast Perl lib.</p>

        </div>



    </div>
    <div class="asset-footer"></div>
</div>


                            
                            <div id="entry-854" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2005/12/15/perl_prolog.html" rel="bookmark">Logic Programming with Perl and Prolog</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author">Robert Pratte</span> on <abbr class="published" title="2005-12-15T00:00:00-08:00">December 15, 2005 12:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            
<!-- sidebar begins -->
<!-- don't move sidebars-->
<!-- sidebar ends -->
<p>Computing languages can be addictive; developers sometimes blame themselves for perceived inadequacies, making apologies for them. That is the case, at least, when one defends his or her language of choice against the criticism of another language's devotee. Regardless, many programmers prefer one language, and typically ground that preference in a respect for that language's strengths.</p>

<p>Perl has many strengths, but two most often cited are its adaptability and propensity to work as a "glue" between applications and/or data. However, Perl isn't the only advantageous language: programmers have used C or even assembly to gain speed for years, and intelligent use of SQL allows the keen coder to offload difficult data manipulations onto a database, for example. Prolog is an often overlooked gem that, when combined with the flexibility of Perl, affords the coder powerful ways to address logical relationships and rules. In this article, I hope to provide a glimpse of the benefits that embedded Prolog offers to Perl programmers. Moreover, I hope that my example implementation demonstrates the ease with which one can address complex logical relationships.</p>

<h4>A Bit About Prolog</h4>

<p>For the sake of demonstration, I would like to frame a simple problem and solution that illustrate the individual strengths of Perl and Prolog, respectively. However, while I anticipate that the average reader will be familiar with the former, he or she may not be as familiar with the latter. <a href="http://en.wikipedia.org/wiki/Prolog">Prolog</a> is a logic programming language often used in AI work, based upon predicate calculus and first developed in 1972. There are several excellent, free versions of Prolog available today, including <a href="http://gnu-prolog.inria.fr">GNU Prolog</a> and the popular <a href="http://www.swi-prolog.org">SWI Prolog</a>. For the Prolog initiate, I recommend checking out some of the free Prolog tutorials, either those linked from Wikipedia or from <a href="http://oopweb.com/Prolog/Files/Prolog.html">OOPWeb</a>.</p>

<p>Prolog and Perl aren't exactly strangers, however. There are several excellent Perl modules available to allow the coder to access the power of Prolog quite easily, including the <a href="http://search.cpan.org/perldoc?Language::Prolog::SWI">SWI</a> module developed by Robert Barta, the <a href="http://search.cpan.org/perldoc?Language::Prolog::Interpreter">Interpreter</a> module by Lee Goddard, the <a href="http://search.cpan.org/perldoc?Language::Prolog::Yaswi">Yaswi</a> modules developed by Salvador Fandino Garcia, and the <a href="http://search.cpan.org/perldoc?AI::Prolog">AI::Prolog</a> module written by Curtis "Ovid" Poe. Poe has also recently provided a rather nice <a href="http://users.easystreet.com/ovid/presentations/logic">introduction to Prolog-in-Perl</a> in an online-accessible format.</p>

<h4>The Problem</h4>

<p>There are many advantages to using Prolog within Perl. In the general sense, each language has its own advantages, and can thus complement the other. Suppose that I am building a testing harness or a logic-based query engine for a web application, where neither language easily provides all of the features I need. In cases such as these, I could use Prolog to provide the logic "muscle," and Perl to "glue" things together with its flexibility and varied, readily available modules on CPAN.</p>

<p>In my simple demonstration, I am going to posit the requirement that I take genealogical information built by another application and test relationships based upon a set of rules. In this case, the rules are defined in a Prolog file (an interesting intersection here is that both Perl and Prolog typically use the suffix <em>.pl</em>), while the genealogical information is contained in a <a href="http://www.graphviz.org/Documentation.php">Dot</a> file readable by Graphviz. As such, I am going to make certain assumptions about the format of the data. Next, I am going to assume that I will have a query (web-based, or from yet another application) that will allow users to identify relationships (such as brothers, cousins, etc.).</p>

<p>Here are my Prolog rules:</p>

<pre><code>is_father(Person)        :- is_parent(Person, _),
                            is_male(Person).
is_father(Person, Child) :- is_parent(Person, Child),
                            is_male(Person).

is_mother(Person)        :- is_parent(Person, _),
                            is_female(Person).
is_mother(Person, Child) :- is_parent(Person, Child),
                            is_female(Person).

ancestor(Ancestor, Person) :- is_parent(Ancestor, Person).
ancestor(Ancestor, Person) :- is_parent(Ancestor, Child),
                              ancestor(Child, Person).

is_sibling(Person, Sibling) :- is_parent(X, Person),
                               is_parent(X, Sibling).

is_cousin(Person, Cousin) :- is_parent(X, Person),
                             is_parent(Y, Cousin),
                             is_sibling(X, Y).</code></pre>

<p>One advantage to separating my logic is that I can troubleshoot it before I even write the Perl code, loading the rules into a Prolog interpreter or IDE such as <a href="http://xgp.sourceforge.net">XGP</a> (for Macintosh users) and testing them. However, AI::Prolog conveniently provides its own solution: by typing <code>aiprolog</code> at the command line, I can access a Prolog shell, load in my file, and run some tests.</p>

<p>At this point, however, I am mostly interested in accessing these rules from Perl. While there are several options for accessing Prolog from within Perl, the <code>AI::Prolog</code> module is perhaps the easiest with which to start. Moreover, it is quite simple to use, the rules used to build the Prolog database being fed in when creating the <code>AI::Prolog</code> object. The ability to hand the object constructor a filehandle is not currently supported, but would indeed be a nice improvement. While there are other ways to accomplish the task of reading in the data, such as calling the Prolog command <code>consult</code>, I will read in the Prolog file (<a href="/2005/12/15/examples/ancestry.pl"><em>ancestry.pl</em></a>) and provide a string representation of the contents.</p>

<pre><code>open( PROLOGFILE, 'ancestry.pl' ) or die "$! \n";
local $/;
my $prologRules = &lt;PROLOGFILE&gt;;
close( PROLOGFILE );

my $prologDB = AI::Prolog-&gt;new( $prologRules );</code></pre>

<csperl file="grab" domain="on" record="b/1714" template="b/article_sidebar2.view">













<p>Now that I have loaded my Prolog database, I need to feed it some more information. I need to take my data, in Dot format, and translate it into something that my Prolog interpreter will understand. There are some modules out there that may be helpful, such as <a href="/pub/a/2004/09/23/fsms.html">DFA::Simple</a>, but since I can assume that my data will look a certain way--having written it from my other application--I will build my own simple parser. First, I am going to take a look at the data.</p>

<p>The visualization program created the diagram in Figure 1 from the code:</p>

<pre><code>digraph family_tree {
   { jill [ color = pink ]
     rob  [ color = blue ] } -&gt; { ann [ color = pink ]
                                  joe [ color = blue ] } ;

   { sue [ color = pink ] 
     dan [ color = blue ] } -&gt; { sara [ color = pink ]
                                 mike [ color = blue ] } ;

   { nan [ color = pink ]
     tom [ color = blue ] } -&gt; sue ;

   { nan
     jim [ color = blue ] } -&gt; rob ;

   { kate  [ color = pink ]
     steve [ color = blue ] } -&gt; dan ;

   { lucy  [ color = pink ]
     chris [ color = blue ] } -&gt; jill ;
}</code></pre>

<p><img src="/pub/2005/12/15/graphics/family_tree.gif" width="500" height="192" alt="a family tree" /><br />
<em>Figure 1. A family tree from the sample data</em>
</p>

<p>There are a few peculiarities worth mentioning here. First, it may seem that the all-lower-case names are a bit strange, but I am already preparing for the convention that data in Prolog is typically lower-case. Also, I inserted an extra space before the semicolons in an effort to make matching them easier. While both of these conventions are easy to code around, they seems to create extra questions when illustrating a point. Therefore, assume that the above Dot snippet illustrates the range of possible formats in the example. While the "real-world examples" may provide a richer set of possibilities, the fact that applications with defined behavior generated this data will limit the edge cases.</p>

<p>Returning to the data, it will be easiest to parse the Dot data using a simple state machine. Previously, I had defined some constants to represent states:</p>

<pre><code>use constant { modInit   =&gt; 0,
               modTag    =&gt; 1,
               modValue  =&gt; 2 };</code></pre>

<p>Basically, I assume that anything on the left-hand side of the <code>=</code> is a parent and anything on the right is a child. Additionally, modifiers (in this case only color) begin with a left square-bracket and males have the <code>blue</code> modifier, whereas females are <code>pink</code>. I know that I have completed a parent-child relationship "block" when I hit the semicolon. Past these stipulations, if it isn't a character I know that I can safely ignore, then it must be a noun.</p>

<pre><code>sub parse_dotFile {
   ##----------------------------------------
   ##  Examine data a word at a time
   ##----------------------------------------
   my @dotData = split( /\s+/, shift() );

   my ( $familyBlock, $personName, @prologQry ) = ();
   my $personModPosition                        = modInit;
   my $relationship                             = 'parent';

   for ( my $idx = 3; $idx &lt; @dotData; $idx++ ) {
      chomp( $dotData[$idx] );

      SWITCH: {

         ## ignore
         if ( $dotData[ $idx ] =~ /[{}=\]]/ ) {
            last SWITCH; }

         ## begin adding attributes
         if ( $dotData[ $idx ] eq '[' ) {
            $personModPosition = modTag;
            last SWITCH; }

         ## switch from parents to children
         if ( $dotData[ $idx ] eq '-&gt;' ) {
            $relationship = 'child';
            last SWITCH; }

         ## end of this block
         if ( $dotData[ $idx ] =~ /\;/ ) {
           ##-----------------------------------------
           ##  Generate is_parent rules for Prolog
           ##-----------------------------------------
            foreach my $parentInBlock ( @{ $familyBlock-&gt;{ parent } } ) {
               foreach my $childInBlock ( @{ $familyBlock-&gt;{ child } } ) {
                  push( @prologQry,
                      "is_parent(${parentInBlock}, ${childInBlock})" );
               }
            }
            $familyBlock = ();
            $relationship = 'parent';
            last SWITCH; }

         ## I have a noun, need to set something
         else {

            ## I have a modifier tag, next is the value
            if ( $personModPosition == modTag ) {
               $personModPosition = modValue;
               last SWITCH;

            } elsif ( $personModPosition == modValue ) {
                 ##--------------------------------------
                 ##  Set modifier value and reset
                 ##  We currently assume it is color
                 ##--------------------------------------
               if ( $dotData[ $idx ] eq 'blue' ) {

                  push( @prologQry, "is_male(${personName})" );
               } else {
                  push( @prologQry, "is_female(${personName})" );
               }
               $personModPosition = modInit;
               $personName        = ();
               last SWITCH;
            } else {
                 ##--------------------------------------
                 ##  Grab the name and id as parent or child
                 ##--------------------------------------
               $personName = $dotData[ $idx ];
               push( @{ $familyBlock-&gt;{ $relationship } }, $personName );
            }
         }
      }
   }

   return( \@prologQry );
}</code></pre>

<p>Rather than simply pushing my new rules into the Prolog interpreter directly, I return an array that contains the full ruleset. I am doing this so that I can easily dump it to a file for troubleshooting purposes. I can simply write the rules to a file, and consult this file in a Prolog shell.</p>

<p>With a subroutine to parse my Dot file into Prolog rules, I can now push those rules into the interpreter:</p>

<pre><code>   ##-------------------------------------------
   ##  Read in Dot file containing relations
   ##  and feed it into the Prolog instance
   ##-------------------------------------------
   open( DOTFILE, '<a href="/2005/12/15/examples/family_tree.dot">family_tree.dot</a>' ) or die "$! \n";
   my $parsedDigraph = parse_dotFile( &lt;DOTFILE&gt; );
   close( DOTFILE );

   foreach ( @$parsedDigraph ) {
      $prologDB-&gt;do("assert($_).");
   }</code></pre>

<p>Now I can easily query my Prolog database using the query method in <code>AI::Prolog</code>:</p>

<pre><code>   ##-------------------------------------------
   ##  Run the query
   ##-------------------------------------------
   $prologDB-&gt;query( "is_cousin(joe, sara)." );
   while (my $results = $prologDB-&gt;results) { print "@$results\n"; }</code></pre>

<h3>What Next?</h3>

<p>Even though this is a trivial example, I think that it provides an idea of the powerful ways in which Perl can be supplemented with Prolog. Just within the context of evaluating genealogical data (a mainstay of Prolog tutorials and examples), it seems that a Perl/Prolog application that uses genealogical data from open source genealogical software or websites would be a killer application. The possibilities seem endless: rules based upon Google maps, mining information from online auctions or news services, or even harvesting information for that new test harness are all tremendous opportunities for the marriage of Perl and Prolog.</p>

        </div>



    </div>
    <div class="asset-footer"></div>
</div>


                            
                            <div id="entry-852" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2005/12/08/test_files.html" rel="bookmark">Testing Files and Test Modules</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author">Phil Crow</span> on <abbr class="published" title="2005-12-08T00:00:00-08:00">December  8, 2005 12:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            
<!-- sidebar begins -->
<!-- don't move sidebars-->
<!-- sidebar ends -->
<p>For the last several years, there has been more and more emphasis on automated testing. No self-respecting CPAN author can post a distribution without tests. Yet some things are hard to test. This article explains how writing <code>Test::Files</code> gave me a useful tool for validating one module's output and taught me a few things about the current state of Perl testing.</p>

<h3>Introduction</h3>

<p>My boss put me to work writing a moderately large suite in Perl. Among many other things, it needed to perform check out and commit operations on CVS repositories. In a quest to build quality tests for that module, I wrote <a href="http://search.cpan.org/perldoc/Test::Files"><code>Test::Files</code></a>, which is now on CPAN. This article explains how to use that module and, perhaps more importantly, how it tests itself.</p>

<h3>Using <code>Test::Files</code></h3>

<p>To use <code>Test::Files</code>, first use <a href="http://search.cpan.org/perldoc/Test::More"><code>Test::More</code></a> and tell it how many tests you want to run.</p>

<pre><code>use strict;
use warnings;
use Test::More tests =&gt; 5;
use Test::Files;</code></pre>

<p>After you use the module, there are four things it can help you do:</p>

<ul>
<li>Compare one file to a string or to another file.</li>

<li>Make sure that directories have the files you expect them to have.</li>

<li>Compare all the files in one directory to all the files in another directory.</li>

<li>Exclude some things from consideration.</li>
</ul>

<h3>Single Files</h3>

<p>In the simplest case, you have written a file. Now it is time to validate it. That could look like this:</p>

<pre><code>file_ok($file_name, "This is the\ntext\n",
    "file one contents");</code></pre>

<p>The <code>file_ok</code> function takes two (or optionally, and preferably, three) arguments. The first is the name of the file you want to validate. The second is a text string containing the text that should be in the file. The third is the name of the test. In the rush of writing, I'm likely to fail to mention the test names at some point, so let me say up front that all of the tests shown here take a name argument. Including a name makes finding the test easier.</p>

<p>If the file agrees with the string, the test passes with only an OK message. Otherwise, the test will fail and diagnostic messages will show where the two differed. The diagnostic output is really the reason to use <code>Test::Files</code>.</p>

<p>Some, including myself, prefer to check one file against another. I put one version in the distribution. The other one, my tests write. To compare two files, use:</p>

<pre><code>compare_ok($file1, $file2, $name);</code></pre>

<p>As with <code>file_ok</code>, if the files are the same, <code>Test::Files</code> only reports an OK message. Failure shows where the files differ.</p>

<h3>Directory Structures</h3>

<p>Sometimes, you need to validate that certain files are present in a directory. Other times, you need to make that check exclusive so that only known files are present. Finally, you might want to know that not only is the directory structure is the same, but that the files contain the same data.</p>

<p>To look for some files in a directory by name, write:</p>

<pre><code>dir_contains_ok($dir, [qw(list files here)], $name);</code></pre>

<p>This will succeed, even if the directory has some other files you weren't looking for.</p>

<p>To ensure that your list is exclusive, add only to the function name:</p>

<pre><code>dir_only_contains_ok($dir, [qw(list all files here)], $name);</code></pre>

<p>Both of these report a list of absent files if they fail due to them. The exclusive form also reports a list of unexpected files, if it sees any.</p>

<!-- sidebar begins -->
 <csperl file="grab" domain="on" record="b/1796" template="b/article_sidebar2.view">
<!-- sidebar ends -->













<h3>Directory Contents</h3>

<p>If knowing that certain file names are present is not enough, use the <code>compare_dirs_ok</code> function to check the contents of all files in one directory against files in another directory. A typical module might build one directory during <code>make test</code>, with the other built ahead of time and shipped with the distribution.</p>

<pre><code>compare_dirs_ok($test_built, $shipped, $name);</code></pre>

<p>This will generate a separate diagnostic <code>diff</code> output for each pair of files that differs, in addition to listing files that are missing from either distribution. (If you need to know which files are missing from the built directory, either reverse the order of the directories or use <code>dir_only_contains_ok</code> in addition to <code>compare_dirs_ok</code>. This is a bug and might eventually be fixed.) Even though this could yield many diagnostic reports, all of those separate failures only count as one failed test.</p>

<p>There are many times when testing <em>all</em> files in the directories is just wrong. In these cases, it is best to use <a href="http://search.cpan.org/perldoc/File::Find"><code>File::Find</code></a> or an equivalent, putting an exclusion criterion at the top of your wanted function and a call to <code>compare_ok</code> at the bottom. This probably requires you to use <code>no_plan</code> with <code>Test::More</code>:</p>

<pre><code>use Test::More qw(no_plan);</code></pre>

<p><code>Test::More</code> wants to know the exact number of tests you are about to run. If you tell it the wrong number, the test harness will think something is wrong with your test script, causing it to report failures. To avoid this confusion, use <code>no_plan</code>--but keep in mind that plans are there for a reason. If your test dies, the plan lets the harness know how many tests it missed. If you have <code>no_plan</code>, the harness doesn't always have enough information to keep score. Thus, you should put such tests in separate scripts, so that the harness can count your other tests properly.</p>

<h3>Filtering</h3>

<p>While the above list of functions seemed sufficient during planning, reality set in as soon as I tried it out on my CVS module. I wanted to compare two CVS repositories: one ready for shipment with the distribution, the other built during testing. As soon as I tried the test it failed, not because the operative parts of the module were not working, but because the CVS timestamps differed between the two versions.</p>

<p>To deal with cosmetic differences that should not count as failures, I added two functions to the above list: one for single files and the other for directories. These new functions accept a code reference that receives each line prior to comparison. It performs any needed alterations, and then returns a line suitable for comparison. My example function below redacts the offending timestamps. With the filtered versions in place, the tests pass and fail when they should.</p>

<p>My final tests for the CVS repository directories look like this:</p>

<pre><code>compare_dirs_filter_ok(
    't/cvsroot/CVSROOT',
    't/sampleroot/CVSROOT',
    \&amp;chop_dates,
    "make repo"
);</code></pre>

<p>The code reference argument comes between the directory names and the test name. The <code>chop_dates</code> function is not particularly complex. It removes two kinds of dates favored by CVS, as shown in its comments.</p>

<pre><code>sub chop_dates {
    my $line =  shift;

    #  2003.10.15.13.45.57 (year month day hour minute sec)
    $line    =~ s/\d{4}(.\d\d){5}//;

    #  Thu Oct 16 18:00:28 2003
    $line    =~ s/\w{3} \w{3} \d\d? \d\d:\d\d:\d\d \d{4}//;

    return $line;
}</code></pre>

<p>This shows the general behavior of filters. They receive a line of input which they must not directly change. Instead, they must return a new, corrected line.</p>

<p>In addition to <code>compare_dirs_filter_ok</code> for whole directory structures, there is also <code>compare_filter_ok</code>, which works similarly for single file comparisons. (There is no <code>file_filter_ok</code>, but maybe there should be.)</p>













<h3>Testing a Test Module</h3>

<p>The most interesting part of writing <code>Test::Files</code> was learning how to test it. Thanks to Schwern, I learned about <a href="http://search.cpan.org/perldoc/Test::Builder::Tester"><code>Test::Builder::Tester</code></a>, which eases the problems inherent in testing a Perl test module.</p>

<p>The difficulty with testing Perl tests has to do with how they normally run. The venerable test harness scheme expects test scripts to produce pass and fail data on standard out and diagnostic help on standard error. This is a great design. The simplicity is exactly what you would expect from a Unix-inspired tool. Yet, it poses a problem for testing test modules.</p>

<p>When eventual users use the test module, their harness expects it to write quite specific things to standard out and standard error. Among the things that must go to standard out are a sequence of lines such as <code>ok 1</code>. When you write a test of the test module, its harness also expects to see this sort of data on standard out and standard error. Having two different sources of <code>ok 1</code> is highly confusing, not least to the harness, which chokes on such duplications.</p>

<p>Test module writers need a scheme to trap the output from the module being tested, check it for correct content, and report that result onto the actual standard channels for the harness to see. This is tricky, requiring care in diversion of file handles at the right moments without the knowledge of the module whose output is diverted. Doing this by hand is inelegant and prone to error. Further, multiple test scripts might have to recreate home-rolled solutions (introducing the oldest of known coding sins: duplication of code). Finally, the diagnostic output, in the event of failure, from homemade diverters is unlikely to be helpful when tests of the test module fail.</p>

<p><em>Enter <code>Test::Builder::Tester</code>.</em>
</p>

<p>To help us test testers, Mark Fowler collected some code from Schwern, and used it to make <code>Test::Builder::Tester</code>. With it, tests of test modules are relatively painless and their failure diagnostics are highly informative. Here are two examples from the <code>Test::Files</code> test suite. The first shows a file comparison that should pass:</p>

<pre><code>test_out("ok 1 - passing file");
compare_ok("t/ok_pass.dat", "t/ok_pass.same.dat",
    "passing file");
test_test("passing file");</code></pre>

<p>This test should work, generating <code>ok 1 - passing file</code> on standard output. To tell <code>Test::Builder::Tester</code> what the standard output should be, I called <code>test_out</code>. After the test, I called <code>test_test</code> with only the name of my test. (To avoid confusion, I made the test names the same.)</p>

<p>Between the call to <code>test_out</code> and the one to <code>test_test</code>, <code>Test::Builder::Tester</code> diverted the regular output channels so the harness won't see them.</p>

<p>The second example shows a failed test and how to check both standard out and standard error. The later contains the diagnostic data the module should generate.</p>

<pre><code>test_out("not ok 1 - failing file");
$line = line_num(+9);
test_diag("    Failed test (t/03compare_ok.t at line $line)",
'+---+--------------------+-------------------+',
'|   |Got                 |Expected           |',
'| Ln|                    |                   |',
'+---+--------------------+-------------------+',
'|  1|This file           |This file          |',
'*  2|is for 03ok_pass.t  |is for many tests  *',
'+---+--------------------+-------------------+'  );
compare_ok("t/ok_pass.dat", "t/ok_pass.diff.dat",
    "failing file");
test_test("failing file");</code></pre>

<p>Two new functions appear here. First, <code>line_num</code> returns the current line number plus or minus an offset. Because failing tests report the line number of the failure, checking standard error for an exact match requires matching that number. Yet, no one wants his tests to break because he inserted a new line at the top of the script. With <code>line_num</code>, you can obtain the line number of the test relative to where you are. Here, there are nine lines between the call to <code>line_num</code> and the actual test.</p>

<p>The other new function is <code>test_diag</code>. It allows you to check the standard error output, where diagnostic messages appear. The easiest way to use it is to provide each line of output as a separate parameter.</p>

<h3>Summary</h3>

<p>Now you know how to use <code>Test::Files</code> and how to test modules that implement tests. There is one final way I use <code>Test::Files</code>. I use it outside of module testing any time I want to know how the contents of text files in two directory hierarchies compare. With this, I can quickly locate differences in archives, for example, enabling me to debug builders of those archives. In one example, I used it compare more than 400 text files in two WebSphere .ear archives. My program had only about 30 operative lines (there were also comments and blank lines) and performed the comparison in under five seconds. This is testament to the leverage of Perl and CPAN.</p>

<p>(Since doing that comparison, I have moved to a new company. In the process I exchanged WebSphere for <code>mod_perl</code> and am generally happier with the latter.)</p>

        </div>



    </div>
    <div class="asset-footer"></div>
</div>


                            
                            <div id="entry-850" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2005/12/01/client_side_success.html" rel="bookmark">Perl Success Story: Client-Side Collection and Reporting</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author">Jiann Wang</span> on <abbr class="published" title="2005-12-01T00:00:00-08:00">December  1, 2005 12:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            
<!-- sidebar begins -->
<!-- don't move sidebars-->
<!-- sidebar ends -->
<p>Accurate software inventory management is critical to any organization. Without an accurate software inventory, organizations may either be out of compliance with their vendor licensing agreements or they may be paying extra for licenses that they do not need.</p>

<p>Hitachi Global Storage Technologies (Hitachi GST) formed in 2003 as a result of the strategic combination of Hitachi and IBM's storage technology businesses. The company offers customers worldwide a comprehensive range of hard disk drives for desktop computers, high-performance servers, and mobile devices. With offices and manufacturing facilities spanning the globe, deployment of the corporate business intelligence (BI) tool suite is extensive. The company uses BI tools throughout the business, from manufacturing to sales and warranty operations, for analysis of data that reside in operational data stores and data warehouses. With each new manufacturing site comes requests for additional licenses.</p>

<h3>A Business Intelligence Problem</h3>

<p>To avoid unnecessary spending on licenses, the company needs a detailed assessment of both the number and type of licenses actually deployed at the various sites. We operate in a highly competitive environment in the technology industry and can ill afford to continue purchasing unnecessary licenses. An effort was started to determine how we deploy the current pool of licenses. The initial effort to perform a software inventory for the BI tool involved a manual inventory by each site owner or application owner. As expected, the results returned appear to indicate a significant under-licensing with one of the products from the BI suite. Looking at the raw information sent in by each owner, we had speculated that we double-counted some users and that some users may be misreporting the client that they have installed on their system, thus driving up the license count for the respective product.</p>

<csperl file="grab" domain="on" record="b/1795" template="b/article_sidebar.view">

<p>Based on the preliminary analysis of the information collected, it became evident that we needed to deploy a software inventory tool to assess each workstation and determine what users have actually installed on their machines. The corporate software asset management tool was not a viable option, because it had limited deployment, with some organizations maintaining software inventory using manual methods. The licensing issues of deploying a commercial tool, along with the customizations needed in order to accurately capture the different types of licenses, would be prohibitive from both a time and cost perspective.</p>

<p>In order to generate an accurate license count, the software inventory tool must be able to detect the different types of BI clients that may be installed on a given PC. The release information of each version is also important. We can use this information to determine which users need upgrades to the latest supported release. Our license entitlement limits the number of each type of client from the BI suite that we can deploy across the enterprise. To further complicate matters, there are two different types of client-server tools that use the same binary, with no easy way to distinguish between them by looking at the installed applications listing in Windows. The difference in cost between these two tools is approximately $3,400 per license, so it is imperative that the inventory count is correct for each specific type of client. In addition, a web-based version of the BI tool is available as a plugin. However, the plugin version information is inaccurate in the binary file and the client-server tool version is incomplete in the registry. In preliminary tests of a commercial tool, it was unable to distinguish between the two types of clients and missed the web plugin altogether.</p>

<h3>The Design of a Solution</h3>

<p>Given this challenge, we had to develop a custom solution to address the problem. I had previously used Perl to develop an automated software delivery and installation solution on the Windows platform, and some of what I had already developed was very similar to what we needed. Leveraging this prior experience reduced the amount of time and effort needed for development of the software inventory solution to address our immediate needs.</p>

<p>The solution criteria that we set forth required that the client inventory tool must be relatively compact and not require any installation. The tool also must be a self-contained executable that a user can download and run on their client. If a tool is difficult to use or install, this severely curtails its adoption and use. The user population is spread across multiple locales, including Japan, South Korea, Taiwan, Singapore, Thailand, the United Kingdom, and the United States, so the tool must be simple to understand and must avoid complex procedures.</p>

<p>Each user also needs to authenticate against the corporate LDAP directory to ensure that their results are accurately recorded and ensure the authenticity of the result. In addition, the inventory results must be collected and stored on a central server to ease management of the inventory process. The results must also be readily accessible to all users and owners so they can see where they stand in comparison to what they had originally reported.</p>

<p>The solution involves a client tool and a server-side application. The combination of the two must authenticate the user against the corporate enterprise directory, inventory the client system, log the results, and record the results in a DB2 back-end database. The data stored in the DB2 back-end database is useful for generating both summary and detail reports via the Web. The specific modules used in the development of the solution included <code>Win32::OLE</code>, <code>Win32::GUI</code>, <code>Win32::File::VersionInfo</code>, <code>Win32::TieRegistry</code>, <code>IO::Socket</code>, <code>CGI</code>, <code>DBI</code>, <code>DBD::DB2</code>, and <code>Net::LDAP</code>.</p>













<h3>Building the Client</h3>

<p>Development started with the client component first. Because most end users are averse to command-line tools, we had to develop a GUI of sorts to guide the user through the authentication and inventory steps. In addition, the GUI could display error messages to the user. We used <code>Win32::GUI</code> to create the prompts as well as data entry dialog boxes. The GUI captures the information entered and passes it to the central server using HTTP.</p>

<p>All communications between the client and server use HTTP because coding the client to work directly with the LDAP server and the database server would have made troubleshooting any problems experienced by clients in distant locations inordinately difficult. In a situation such as this, we wanted a single controlled point of failure, as depicted in Figure 1. By using HTTP and a central-server-based application to broker requests, we can isolate problems on the client side to only HTTP-related transport issues.</p>

<p><img src="/pub/2005/12/01/graphics/figure1.gif" width="474" height="205" alt="The authentication process" /><br />
<em>Figure 1. The authentication process</em>
</p>

<p>The user that is running the inventory tool must authenticate first. This is important, as we need to track who has or has not reported their results based on the initial manual inventory information. We use <code>Net::LDAP</code> to perform the authentication against our LDAP server. The application prompts users for their intranet IDs and passwords, and the client passes this information to the server application so that it can issue a bind against the LDAP server. If the information provided by the user does not yield a successful bind, then the client requests that the user reenter his or her login information. Figure 1 depicts this authentication process.</p>

<p>To authenticate a user via LDAP using <code>Net::LDAP</code>, the server uses the user's intranet ID to prepare the distinguished name (DN). The DN is the unique identifier for the user's record in the LDAP directory. In order to perform the initial lookup, the server issues an anonymous bind against the LDAP directory and performs a search using the intranet ID provided. The search returns only the <code>uid</code>, which is the unique record identifier in our implementation of the corporate directory. After the server obtains this, it forms a DN string and issues another bind again using the password provided. If the bind is successful, the return code is undefined and the client proceeds to inventory the system.</p>

<p>Most software applications leave some type of signature in the system registry on a client system, and the BI tool suite deployed at Hitachi GST is no exception. I knew that the software leaves specific signatures when installed on a client system. This information is in the system registry under both the <code>HKEY_LOCAL_MACHINE</code> and <code>HKEY_CURRENT_USER</code> registry entries. We use <code>Win32::TieRegistry</code> to retrieve registry values for determining the type of client that is installed, as well as the binary install location and install key used. <code>Win32::TieRegistry</code> makes it extremely easy to access and modify registry values.</p>

<p>The exact version of the BI client deployed is not accurate in the system registry as we also want to determine the specific point release deployed on the client systems. To achieve this, we use <code>Win32::File::VersionInfo</code> to extract the <code>ProductVersion</code> information from the binary files. Looking at the properties for the file in Windows Explorer for the BI web client binary, we can clearly see that the <code>FileVersion</code> information in the executable is incorrect. We settled on using <code>ProductVersion</code> instead.</p>

<p>In addition to checking the various client versions that may be installed, the tool must also log the client machine serial number. We achieved this by using <code>Win32::OLE</code> and querying information from the <code>Win32_BIOS</code> WMI class. Because some users may have multiple workstations or laptops, we use the machine serial to differentiate multiple entries logged by a single user. The WMI classes yield a wealth of information. Extending the features of this tool simply requires querying additional WMI classes to obtain additional hardware information, such as hard disk, CPU, and memory.</p>

<h3>Deploying the Client</h3>

<p>Once we developed and tested the client code, we had to package the script itself. Not every client machine has Perl installed. Even if they did have Perl installed, there is no guarantee that the appropriate modules needed by the application are available on the target systems. To package the final script into a single executable file, we used PerlApp from ActiveState's PDK to compile the script and the associated modules. This allowed us to neatly package and deploy the client as a single executable that users can run from their client system without performing any type of installation or setup.</p>

<p>When all of the requisite information is collected on the client machine, it passes back to the server which records it on the server's local file system first. This initial logging allows us to capture the client inventory results even if the database server is down. The logged results are easy to import into the database, should there be an unexpected database outage. The <code>CGI</code> module handles the information passed from the client to the server, and <code>DBI</code> and <code>DBD::DB2</code> handle the database connection. DB2 is the RDBMS of choice in our environment, and we were able to leverage an existing DB2 database environment, which further reduced the time to deployment.</p>













<h3>Learning from the Process</h3>

<p>All of this information that we collect is of little use if it is not easily accessible for analysis. We also wrote a script to retrieve and format information from the database and present it via the Web. This allowed users and application owners to see the current inventory status of their users, and also help them to determine which users still need to run the client inventory tool to complete their assessment. The script provides summary, detail, and exception views. With reports available through the Web, users can access it from any web browser, regardless of the user's geographic location. This empowers everyone involved to see the results in near real time.</p>

<p>Upon deployment of the tool, we then recorded and summarized user inventory information automatically. Some interesting results came to light. It became apparent that up to $163,000 worth of additional license purchases were unnecessary, as the existing pool of licenses had not been depleted (as we believed earlier), based on the manual inventory results submitted. Also, with the client inventory tool being an internally developed tool, there were no licensing costs for distributing it at various sites.</p>

<p>The client- and server-side components took two weeks to develop. We formed test cases before writing the code in order to minimize functional issues during final testing in the field, as well as to ensure that we did not overlook critical features and integration issues during the development process. Ultimately, as illustrated in Figure 2, the client and the various server components must work together as an integrated system.</p>

<p><img src="/pub/2005/12/01/graphics/figure2.gif" width="402" height="320" alt="The client and server working together" /><br />
<em>Figure 2. The client and server working together</em>
</p>

<p>The use of virtual machine software was also instrumental for testing and reduced overall development time. It allowed me to simulate client environments and test client code without having to use a physical machine for each version of the BI application. Using undo disks, I was able to return the VMs to a prior state very quickly without manually uninstalling the various BI tools from the VM. We initially tested the inventory tool in Singapore, Japan, and the U.S., and this testing confirmed that the tool was able to perform well even though users were spread across remote geographic locations.</p>

<p>Although we developed this tool for a one-time inventory of the number of BI clients deployed in the field, it also has a role going forward in helping to maintain an accurate picture of the licenses deployed. Possible enhancements include converting the tool so that we can install it as a service to run without user intervention for periodic updates of client inventory data from identified clients, auto-conversion of licensing from one client class to another, and automatic uninstall of clients, should the user decide that he or she no longer needs it. In staying with the near-zero client management paradigm, we can extend the client to contain auto-update features by checking the local version and verifying it against the latest published version on a central server.</p>

        </div>



    </div>
    <div class="asset-footer"></div>
</div>




                            <div class="content-nav">
                                <a href="/pub/2005/11/">&laquo; November 2005</a> |
                                <a href="/pub/">Main Index</a> |
                                <a href="/pub/archives.html">Archives</a>
                                | <a href="/pub/2006/01/">January 2006 &raquo;</a>
                            </div>


                        </div>
                    </div>


                    <div id="beta">
    <div id="beta-inner">


    
    <div class="widget-what-is-perl widget">
    <div class="widget-content widget-content-what-is-perl">
       Visit the home of the  Perl programming language: <a href="http://www.perl.org/">Perl.org</a
    </div>
</div>
<div class="widget-find-out-more widget-archives widget">
    <div class="widget-content">
        <ul>
            <li><a href="http://www.perl.org/get.html">Download</a></li>
            <li><a href="http://perldoc.perl.org/">Documentation</a></li>
            <li><a href="http://blogs.perl.org/">Perl Bloggers</a></li>
            <li><a href="http://news.perlfoundation.org/">Foundation News</a></li>
        </ul>
    </div>
</div><div class="widget-tcpc widget">
<h3 class="widget-header">Sponsored by</h3>
    <div class="widget-content">
        <a href="http://training.perl.com/" alt="Perl Training" target="_blank"><img src="/i/tcpc.png" width="150" height="50"></a>
    </div>
</div>

<div class="widget-syndication widget">
    <div class="widget-content">
        <ul>
            <li><img src="/mt-static/images/status_icons/feed.gif" alt="Subscribe to feed" width="9" height="9" /> <a href="/pub/atom.xml">Subscribe to this website's feed</a></li>

        </ul>
    </div>
</div>
<div class="widget-archive-monthly widget-archive widget">
    <h3 class="widget-header">Monthly <a href="/pub/archives.html">Archives</a></h3>
    <div class="widget-content">
        <ul>
        
            <li><a href="/pub/2014/02/">February 2014 (1)</a></li>
        
    
        
            <li><a href="/pub/2014/01/">January 2014 (1)</a></li>
        
    
        
            <li><a href="/pub/2013/10/">October 2013 (1)</a></li>
        
    
        
            <li><a href="/pub/2013/01/">January 2013 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/12/">December 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/11/">November 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/10/">October 2012 (2)</a></li>
        
    
        
            <li><a href="/pub/2012/08/">August 2012 (2)</a></li>
        
    
        
            <li><a href="/pub/2012/06/">June 2012 (11)</a></li>
        
    
        
            <li><a href="/pub/2012/05/">May 2012 (18)</a></li>
        
    
        
            <li><a href="/pub/2012/04/">April 2012 (17)</a></li>
        
    
        
            <li><a href="/pub/2012/02/">February 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/12/">December 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/09/">September 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/08/">August 2011 (2)</a></li>
        
    
        
            <li><a href="/pub/2011/06/">June 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/05/">May 2011 (3)</a></li>
        
    
        
            <li><a href="/pub/2011/04/">April 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/03/">March 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/02/">February 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/01/">January 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/11/">November 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/10/">October 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/09/">September 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/08/">August 2010 (3)</a></li>
        
    
        
            <li><a href="/pub/2010/07/">July 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/04/">April 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/03/">March 2010 (4)</a></li>
        
    
        
            <li><a href="/pub/2008/05/">May 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/04/">April 2008 (2)</a></li>
        
    
        
            <li><a href="/pub/2008/03/">March 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/02/">February 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/01/">January 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/12/">December 2007 (2)</a></li>
        
    
        
            <li><a href="/pub/2007/09/">September 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/08/">August 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/07/">July 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/06/">June 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/05/">May 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/04/">April 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/03/">March 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/02/">February 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/01/">January 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/12/">December 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/11/">November 2006 (2)</a></li>
        
    
        
            <li><a href="/pub/2006/10/">October 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/09/">September 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/08/">August 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/07/">July 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/06/">June 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/05/">May 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/04/">April 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/03/">March 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/02/">February 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2006/01/">January 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/12/">December 2005 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/11/">November 2005 (3)</a></li>
        
    
        
            <li><a href="/pub/2005/10/">October 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/09/">September 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/08/">August 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/07/">July 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/06/">June 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/05/">May 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/04/">April 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/03/">March 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2005/02/">February 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/01/">January 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/12/">December 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/11/">November 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/10/">October 2004 (5)</a></li>
        
    
        
            <li><a href="/pub/2004/09/">September 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/08/">August 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/07/">July 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/06/">June 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/05/">May 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2004/04/">April 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/03/">March 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/02/">February 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/01/">January 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/12/">December 2003 (4)</a></li>
        
    
        
            <li><a href="/pub/2003/11/">November 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/10/">October 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/09/">September 2003 (6)</a></li>
        
    
        
            <li><a href="/pub/2003/08/">August 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/07/">July 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/06/">June 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/05/">May 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/04/">April 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/03/">March 2003 (10)</a></li>
        
    
        
            <li><a href="/pub/2003/02/">February 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/01/">January 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/12/">December 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/11/">November 2002 (9)</a></li>
        
    
        
            <li><a href="/pub/2002/10/">October 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/09/">September 2002 (11)</a></li>
        
    
        
            <li><a href="/pub/2002/08/">August 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/07/">July 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/06/">June 2002 (4)</a></li>
        
    
        
            <li><a href="/pub/2002/05/">May 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/04/">April 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/03/">March 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/02/">February 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/01/">January 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/12/">December 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/11/">November 2001 (5)</a></li>
        
    
        
            <li><a href="/pub/2001/10/">October 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/09/">September 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/08/">August 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/07/">July 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/06/">June 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/05/">May 2001 (11)</a></li>
        
    
        
            <li><a href="/pub/2001/04/">April 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/03/">March 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/02/">February 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/01/">January 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2000/12/">December 2000 (6)</a></li>
        
    
        
            <li><a href="/pub/2000/11/">November 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/10/">October 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/09/">September 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/08/">August 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/07/">July 2000 (5)</a></li>
        
    
        
            <li><a href="/pub/2000/06/">June 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/05/">May 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/04/">April 2000 (3)</a></li>
        
    
        
            <li><a href="/pub/2000/03/">March 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/02/">February 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/01/">January 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/12/">December 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/11/">November 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/10/">October 1999 (5)</a></li>
        
    
        
            <li><a href="/pub/1999/09/">September 1999 (4)</a></li>
        
    
        
            <li><a href="/pub/1999/08/">August 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/07/">July 1999 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/06/">June 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/04/">April 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/03/">March 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/01/">January 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/12/">December 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/11/">November 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/07/">July 1998 (2)</a></li>
        
    
        
            <li><a href="/pub/1998/06/">June 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/03/">March 1998 (1)</a></li>
        
        </ul>
    </div>
</div>
        
    

<div class="widget-powered widget">
    <div class="widget-content">
        <a href="http://www.movabletype.com/"><img src="/mt-static/images/bug-pbmt-white.png" alt="Powered by Movable Type 5.13-en" width="120" height="75" /></a>
    </div>
</div>



    </div>
</div>






                </div>
            </div>


            <div id="footer">
    <div id="footer-inner">
        <div id="footer-content">
            <div class="widget-powered widget">
                <div class="widget-content">
                    Powered by <a href="http://www.movabletype.com/" rel="generator">Movable Type Pro</a>
                </div>
            </div>

            <div class="widget-creative-commons widget">
                <div class="widget-content">
                    This blog is licensed under a <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/">Creative Commons License</a>.
                </div>
            </div>

        </div>
    </div>
</div>



        </div>
    </div>
</body>
</html>
