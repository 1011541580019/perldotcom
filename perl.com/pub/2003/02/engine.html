<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" id="sixapart-standard">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="generator" content="Movable Type Pro 5.02" />
<link rel="stylesheet" href="/pub/styles.css" type="text/css" />
<link rel="start" href="/pub/" title="Home" />
<link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/pub/atom.xml" />
<script type="text/javascript" src="/pub/mt.js"></script>

<script type="text/javascript">

 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-50555-22']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type =
   'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
   'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0];
   s.parentNode.insertBefore(ga, s);
 })();

</script>
    
    <link rel="prev bookmark" href="/pub/2003/02/20030216.html" title="This week on Perl 6, week ending 2003-02-16" />
    <link rel="next bookmark" href="/pub/2003/02/20030223.html" title="This week on Perl 6, week ending 2003-02-23" />
    
    
    <title>Building a Vector Space Search Engine in Perl - Perl.com</title>
</head>
<body id="perl-com" class="mt-entry-archive layout-wt">
    <div id="container">
        <div id="container-inner">


            <div id="header">
    <div id="header-inner">
        <div id="header-content">
        <div id="top_advert"> 
<!-- Put any landscape advert in here -->
<a href="http://www.perlfoundation.org/" target="_new">
<img src="/i/tpf_banner.png" width="468" height="60" /></a>
        </div> 



            <div id="header-name"><a href="/pub/" accesskey="1">Perl.com</a></div>
            <div id="header-description"></div>




        </div>
    </div>
</div>



            <div id="content">
                <div id="content-inner">


                    <div id="alpha">
                        <div id="alpha-inner">


                            <div id="entry-1070" class="entry-asset asset hentry">
                                <div class="asset-header">
                                    <h1 id="page-title" class="asset-name entry-title">Building a Vector Space Search Engine in Perl</h1>
                                    <div class="asset-meta">
                                        <span class="byline">

                                            By <span class="vcard author">Maciej Ceglowski</span> on <abbr class="published" title="2003-02-19T00:00:00-08:00">February 19, 2003 12:00 AM</abbr>

                                        </span>


                                    </div>
                                </div>
                                <div class="asset-content entry-content">

                                    <div class="asset-body">
                                        
<!-- sidebar begins -->
<!-- don't move sidebars -->
<!-- sidebar ends -->

<a name="__index__"></a>
<!-- INDEX BEGIN -->

<ul>

	<li><a href="#building a vector space search engine in perl">Building a Vector Space Search Engine in Perl</a></li>
	<li><a href="#a few words about vectors">A Few Words About Vectors</a></li>
	<li><a href="#getting down to business">Getting Down To Business</a></li>
	<li><a href="#building the search engine">Building the Search Engine</a></li>
	<li><a href="#making it better">Making it Better</a></li>
	<li><a href="#further reading">Further Reading</a></li>
</ul>
<!-- INDEX END -->

<a name="building a vector space search engine in perl"></a>
<p><em>Why waste time reinventing the wheel, when you could be reinventing the engine?</em>
<em>-Damian Conway</em></p>
<p>As a Perl programmer, sooner or later you'll get an opportunity to build
a search engine. Like many programming tasks - parsing a date,
validating an e-mail address, writing to a temporary file - this turns
out to be easy to do, but hard to get right. Most people try end up with some kind of reverse index, a data structure that
associates words with lists of documents. Onto this, they graft a scheme
for ranking the results by relevance.</p>
<p>Nearly every search engine in use today - from Google on down - works on
the basis of a <strong>reverse keyword index</strong>. You can write such a keyword
engine in Perl, but as your project grows you will inevitably find
yourself gravitating to some kind of relational database system. Since
databases are customized for fast lookup and indexing, it's no surprise
that most keyword search engines make heavy use of them. But writing code for them isn't much fun.</p>
<p>More to the point, companies like Google and Atomz already offer
excellent, free search services for small Web sites. You can get an
instant search engine with a customizable interface, and spend no time
struggling with Boolean searches, text highlighting, or ranking
algorithms. Why bother duplicating all that effort?</p>
<p>As Perl programmers, we know that laziness is a virtue. But we also know
that there is more than one way to do things. Despite the ubiquity of
reverse-index search, there are many other ways to build a
search engine. Most of them originate in the field of information
retrieval, where researchers are having all kinds of fun. Unfortunately,
finding documentation about these alternatives isn't easy. Most of the
material available online is either too technical or too impractical to
be of use on real-world data sets. So programmers are left with the
false impression that vanilla search is all there
is.</p>
<p>In this article, I want to show you how to build and run a search
engine using a <strong>vector-space model</strong>, an alternative to reverse index
lookup that does not require a database, or indeed any file storage at
all. Vector-space search engines eliminate many of the disadvantages
of keyword search without introducing too many disadvantages of their
own. Best of all, you can get one up and running in just a few dozen
lines of Perl.</p>


<h1><a name="a few words about vectors">A Few Words About Vectors</a></h1>
<p>Vector-space search engines use the notion of a <strong>term space</strong>, where
each document is represented as a vector in a high-dimensional space.
There are as many dimensions as there are unique words in the entire
collection. Because a document's position in the term space is
determined by the words it contains, documents with many words in
common end up close together, while documents with few shared words end
up far apart.</p>
<p>To search our collection, we project a query into this term space and
calculate the distance from the query vector to all the document vectors
in turn. Those documents that are within a certain threshold distance
get added to our result set. If all this sounds like gobbledygook to
you, then don't worry - it will become clearer when we write the code.</p>
<p>The vector-space data model gives us a search engine with several
useful features:</p>
<ul>
<li>
Searches take place in RAM, there is no disk or database access</li>



<li>
Queries can be arbitrarily long</li>



<li>
Users don't have to bother with Boolean logic or regular expressions</li>



<li>
It's trivially easy to do 'find similar' searches on returned documents</li>



<li>
You can set up a 'saved results' basket, and do similarity searches on the
documents in it</li>



<li>
You get to talk about 'vector spaces' and impress your friends</li>


</ul>


<h1><a name="getting down to business">Getting Down to Business</a></h1>
<p>The easiest way to understand the vector model is with a concrete example.</p>
<p>Let's say you have a collection of 10 documents, and together they contain
50 unique words.   You can represent each document as a vector by counting
how many times a word appears in the document, and moving that distance along
the appropriate axis.  So if Document A contains the sentence &quot;cats like
chicken&quot;, then you find the axis for <code>cat</code>, move along one unit, and then do
the same for <code>like</code> and <code>chicken</code>. Since the other 47 words
don't appear in your document, you don't move along the corresponding
axes at all.</p>
<p>Plot this point and draw a line to it from the origin, and you have your
<strong>document vector</strong>. Like any vector, it has a magnitude (determined by
how many times each word occurs), and a direction (determined by which
words appeared, and their relative abundance).</p>
<p>There are two things to notice here:</p>
<p>The first is that we throw away all information word order, and there is
no guarantee that the vector will be unique. If we had started with the
sentence &quot;chickens like cats&quot; (ignoring plurals for the moment), then we
would have ended up with an identical document vector, even though the
documents are not the same.</p>
<p>This may seem to be a big limitation, but it turns out that word order
in natural language contains little information about content - you can
infer most of what a document is about by studying the word list. Bad
news for English majors, good news for us.</p>
<p>The second thing to notice is that with three non-zero values out of a
possible 50, our document vector is sparse. This will hold true for
any natural language collection, where a given document will contain
only a tiny proportion of all the possible words in the language. This
makes it possible to build in-RAM search engines even for large
collections, although the details are outside the scope of this article.
The point is, you can scale this model up quite far before having to
resort to disk access.</p>
<p>To run a vector-space search engine, we need to do the following:</p>
<ol>
<li>
Assemble a document collection</li>



<li>
Create a term space and map the documents into it</li>



<li>
Map an incoming query into the same term space</li>



<li>
Compare the query vector to the stored document vectors</li>



<li>
Return a list of nearest documents, ranked by distance</li>


</ol>
<p>Now let's see how to implement these steps in Perl.</p>


<h1><a name="building the search engine">Building the Search Engine</a></h1>
<p>We'll make things easy by starting with a tiny collection of four documents,
each just a few words long:</p>
<pre><code>
        &quot;The cat in the hat&quot;

        &quot;A cat is a fine pet.&quot;

        &quot;Dogs and cats make good pets.&quot;

        &quot;I haven't got a hat.&quot;</code></pre>
<p>Our first step is to find all the unique words in the document set. The
easiest way to do this is to convert each document into a word list, and
then combine the lists together into one. Here's one (awful) way do it:
</p>
<pre><code>

        sub get_words { 
                my ( $text ) = @_;
                return map { lc $_ =&gt; 1 }
                       map { /([a-z\-']+)/i } 
                       split /\s+/s, $text;
        }</code></pre>
<p>The subroutine splits a text string on whitespace, takes out all punctuation
except hyphens and apostrophes, and converts everything to lower case before
returning a hash of words.</p>
<p>The curious <code>do</code> statement is just a compact way of creating a lookup hash.
<code>%doc_words</code> will end up containing our word list as its keys, and its values
will be the number of times each word appeared.</p>
<p>If we run this 'parser' on all four documents in turn, then we get a master word
list:</p>
<pre><code>
        a
        and
        cat
        cats
        dogs
        fine
        good
        got
        hat
        haven't
        i
        in
        is
        make
        pet
        pets
        the</code></pre>
<p>Notice that many of the words in this list are junk words - pronouns, articles,
and other grammatical flotsam that's not useful in a search context.  A common
procedure in search engine design is to strip out words like these using a
<strong>stop list</strong>.    Here's the same subroutine with a rudimentary stop list added
in, filtering out the most common words:
</p>
<pre><code>

        our %stop_hash;
        our @stop_words = qw/i in a to the it have haven't was but is be from/;
        foreach @stop_words {$stop_hash{$_}++ };


        sub get_words {


                # Now with stop list action!


                my ( $text ) = @_;
                return map { $_ =&gt; 1 }
                       grep { !( exists $stop_hash{$_} ) }
                       map lc,
                       map { /([a-z\-']+)/i } 
                       split /\s+/s, $text;
        }</code></pre>
<p>A true stop list would be longer, and tailored to fit our document
collection. You can find a real stop list in the <code>DATA</code> section of
<a href="/2003/02/19/examples/VectorSpace.pm">Listing 1</a>, along with a complete implementation of the search engine
described here. Note that because of Perl's fast hash lookup algorithm,
we can have a copious stop list without paying a big price in program
speed. Because word frequencies in natural language obey a power-law
distribution, getting rid of the most common words removes a
disproportionate amount of bulk from our vectors.</p>
<p>Here is what our word list looks after we munge it with the stop list:</p>
<pre><code>
        cat
        cats
        dogs
        fine
        good
        got
        hat
        make
        pet
        pets</code></pre>
<p>We've narrowed the list down considerably, which is good.   But notice that our
list contains a couple of variants (&quot;cat&quot; and &quot;cats&quot;, &quot;pet&quot; and &quot;pets&quot;), that
differ only in number.   Also note that someone who searches on 'dog' in our
collection won't get any matches, even though 'dogs' in the plural form is a
valid hit.  That's bad.</p>
<p>This is a common problem in search engine design, so of course there is a module
on the CPAN to solve it.   The bit of code we need is called a <strong>stemmer</strong>, a set
of heuristics for removing suffixes from English words, leaving behind a common
root.   The stemmer we can get from CPAN uses the <strong>Porter stemming algorithm</strong>,
which is an imperfect but excellent way of finding word stems in English.</p>
<pre><code>
        use Lingua::Stem;</code></pre>
<p>We'll wrap the stemmer in our own subroutine, to hide the clunky Lingua::Stem
syntax:</p>
<pre><code>
        sub stem {
                my ( $word) = @_;
                my $stemref = Lingua::Stem::stem( $word );
                return $stemref-&gt;[0];
        }</code></pre>
<p>And here's how to fold it in to the <code>get_words</code> subroutine:</p>
<pre><code>
        return map { stem($_) =&gt; 1 }
               grep { !( exists $stop_hash{$_} ) }
               map lc,
               map { /([a-z\-']+)/i } 
               split /\s+/s, $text;</code></pre>
<p>Notice that we apply our stop list before we stem the words.   Otherwise, 
a valid word like <code>beings</code> (which stems to <code>be</code>) would be caught by the
overzealous stop list.  It's easy to make little slips like this in search algorithm design, so be extra careful.</p>
<p>With the stemmer added in, our word list now looks like this:</p>
<pre><code>
        cat
        dog
        fine
        good
        got
        hat
        make
        pet</code></pre>
<p>Much better!  We have halved the size of our original list, while
preserving all of the important content.</p>















<p>Now that we have a complete list of <strong>content words</strong>, we're ready for the second
step - mapping our documents into the term space.   Because our collection has a
vocabulary of eight content words, each of our documents will map onto an
eight-dimensional vector.</p>
<p>Here is one example:</p>
<pre><code>
        # A cat is a fine pet



        $vec = [ 1, 0, 1, 0, 0, 0, 1 ];</code></pre>
<p>The sentence &quot;A cat is a fine pet&quot; contains three content words. Looking
at our sorted list of words, we find <code>cat</code>, <code>fine</code>, and <code>pet</code> at
positions one, three, and eight respectively, so we create an anonymous
array and put ones at those positions, with zeroes everywhere else.</p>
<p>If we wanted to go in the opposite direction, then we could take the vector
and look up the non-zero values at the appropriate position in a sorted
word list, getting back the content words in the document (but no
information about word order).</p>
<p>The problem with using Perl arrays here is that they won't scale. Perl
arrays eat lots of memory, and there are no native functions for
comparing arrays to one another. We would have to loop through our
arrays, which is slow.</p>
<p>A better data way to do it is to use the PDL module, a set of compiled
C extensions to Perl made especially for use with matrix algebra. You
can find it on the CPAN. PDL stands for &quot;Perl Data Language&quot;, and it
is a powerful language indeed, optimized for doing math operations
with enormous multidimensional matrices. All we'll be using is a tiny
slice of its functionality, the equivalent of driving our Ferrari to
the mailbox.</p>
<p>It turns out that a PDL vector (or &quot;piddle&quot;) looks similar to our
anonymous array:
</p>
<pre><code>

        use PDL;
        my $vec = piddle [ 1, 0, 1, 0, 0, 0, 1 ];


        &gt; print $vec

        [1 0 0 1 0 0 0 1]</code></pre>
<p>We give the piddle constructor the same anonymous array as an
argument, and it converts it to a smaller data structure, requiring
less storage.</p>
<p>Since we already know that most of our values in each document
vector will be zero (remember how sparse natural language is),
passing full-length arrays to the piddle constructor might get a
little cumbersome. So instead we'll use a shortcut to create a
zero-filled piddle, and then set the non-zero values explicitly. For
this we have the <code>zeroes</code> function, which takes the size of the
vector as its argument:</p>
<pre><code>
        my $num_words = 8;
        my $vec = zeroes $num_words;



        &gt; print $vec

        [0 0 0 0 0 0 0 0 0]</code></pre>
<p>To set one of the zero values to something else, we'll have to use the
obscure PDL syntax:</p>
<pre><code>
        my $value = 3;
        my $offset = 4;



        index( $vec, $offset ) .= $value;

        &gt; print $vec;

        [0 0 0 3 0 0 0 0 0]</code></pre>
<p>Here we've said &quot;take this vector, and set the value at position 4 to
3&quot;.</p>
<p>This turns out to be all we need to create a document vector. Now we
just have to loop through each document's word list, and set the
appropriate values in the corresponding vector. Here's a subroutine that
does the whole thing:</p>
<pre><code>
        # $word_count is the total number of words in collection
        # %index is a lookup hash of word to its position in the master list



        sub make_vector {
                my ( $doc ) = @_;
                my %words = get_words( $doc );  
                my $vector = zeroes $word_count;


                foreach my $w ( keys %words ) {
                        my $value = $words{$w};
                        my $offset = $index{$w};
                        index( $vector, $offset ) .= $value;
                }
                return $vector;
        }</code></pre>
<p>Now that we can generate a vector for each document in our collection,
as well as turn an incoming query into a query vector (by feeding the
query into the <code>make_vector</code> subroutine), all we're missing is a way to
calculate the distance between vectors.</p>
<p>There are many ways to do this. One of the simplest (and most intuitive)
is the <strong>cosine measure</strong>. Our intuition is that document vectors with
many words in common will point in roughly the same direction, so the
angle between two document vectors is a good measure of their
similarity. Taking the cosine of that angle gives us a value from
zero to one, which is handy. Documents with no words in common will
have a cosine of zero; documents that are identical will have a cosine
of one. Partial matches will have an intermediate value - the closer
that value is to one, the more relevant the document.</p>
<p>The formula for calculating the cosine is this:</p>
<pre><code>
        cos  = ( V1 * V2 ) / ||V1|| x ||V2||</code></pre>
<p>Where V2 and V2 are our vectors, the vertical bars indicate the 2-norm,
and the <code>*</code> indicates the inner product. You can take the math on
faith, or look it up in any book on linear algebra.</p>
<p>With PDL, we can express that relation easily:</p>
<pre><code>
        sub cosine {
                my ($vec1, $vec2 ) = @_;
                my $n1 = norm $vec1;
                my $n2 = norm $vec2;
                my $cos = inner( $n1, $n2 );    # inner product
                return $cos-&gt;sclr();  # converts PDL object to Perl scalar
        }</code></pre>
<p>We can normalize the vectors to unit length using the <code>norm</code> function, because we're not interested in their absolute magnitude, only the angle between them.</p>
<p>Now that we have a way of computing distance between vectors, we're
almost ready to run our search engine. The last bit of the puzzle is a
subroutine to take a query vector and compare it against all of the
document vectors in turn, returning a ranked list of matches:</p>
<pre><code>
        sub get_cosines {
                my ( $query_vec ) = @_;
                my %cosines;
                while ( my ( $id, $vec ) = each  %document_vectors ) {
                        my $cosine = cosine( $vec, $query_vec );
                        next unless $cosine &gt; $threshold;
                        $cosines{$id} = $cosine;
                }
                return %cosines;
        }</code></pre>
<p>This gives us back a hash with document IDs as its keys, and cosines as its
values.  We'll call this subroutine from a <code>search</code> subroutine that will be 
our module's interface with the outside world:</p>
<pre><code>
        sub search {
                my ( $query ) = @_;
                my $query_vec = make_vector( $query );
                my %results = get_cosines( $query_vec );
                return %results;
        }</code></pre>
<p>All that remains is to sort the results by the cosine (in descending
order), format them, and display them to the user.</p>
<p>You can find an object-oriented implementation of this code in <a href="/2003/02/19/examples/VectorSpace.pm">Listing 1</a>, complete with built-in stop list and some small changes to make the
search go faster (for the curious, we normalize the document vectors
before storing them, to save having to do it every time we run the
<code>cosine</code> subroutine).</p>
<p>Once we've actually written the code, using it is straightforward:</p>
<pre><code>
    use Search::VectorSpace;



    my @docs = get_documents_from_somewhere();


    my $engine = Search::VectorSpace-&gt;new( docs =&gt; \@docs );


    $engine-&gt;build_index();
    $engine-&gt;set_threshold( 0.8 );


    while ( my $query = &lt;&gt; ) {
        my %results = $engine-&gt;search( $query );
        foreach my $result ( sort { $results{$b} &lt;=&gt; $results{$a} }
                             keys %results ) {
                print &quot;Relevance: &quot;, $results{$result}, &quot;\n&quot;;
                print $result, &quot;\n\n&quot;;
        }


        print &quot;Next query?\n&quot;;
    }</code></pre>
<p>And there we have it, an instant search engine, all in Perl.</p>


<h1><a name="making it better">Making It Better</a></h1>
<p>There are all kinds of ways to improve on this basic model. Here are a
few ideas to consider:</p>
<dl>
<dt><strong><a name="item_Better_parsing">Better parsing</a></strong></dt>

<dd>
Our <code>get_words</code> subroutine is rudimentary - the code equivalent of
a sharpened stick. For one thing, it will completely fail on text
containing hyperlinks, acronyms or XML. It also won't recognize
proper names or terms that contain more than one word ( like
&quot;Commonwealth of Independent States&quot;). You can make the parser smarter
by stripping out HTML and other markup with a module like
<code>HTML::TokeParser</code>, and building in a part-of-speech tagger to find
proper names and noun phrases (look for our own Lingua::Tagger::En,
coming soon on the CPAN).</dd>



<dt><strong><a name="item_Non%2DEnglish_collections">Non-English Collections</a></strong></dt>

<dd>
Perl has great Unicode support, and the vector model doesn't care about
language, so why limit ourselves to English? As long as you can write a
parser, you can adapt the search to work with any language.
<p>Most likely you will need a special stemming algorithm. This can be
easy as pie for some languages (Chinese, Italian), and really hard for
others (Arabic, Russian, Hungarian). It depends entirely on the
morphology of the language. You can find published stemming algorithms
online for several Western European languages, including German,
Spanish and French.</p></dd>



<dt><strong><a name="item_Similarity_search">Similarity Search</a></strong></dt>

<dd>
It's easy to add a &quot;find similar&quot; feature to your search engine. Just
use an existing document vector as your query, and everything else falls
into place. If you want to do a similarity search on multiple documents,
then add the vectors together.</dd>



<dt><strong><a name="item_Term_weighting">Term Weighting</a></strong></dt>

<dd>
<strong>Term weighting</strong> is a fancy way of saying &quot;some words are more
important than others&quot;. Done properly, it can greatly improve 
search results.
<p>You calculate weights when building document vectors. <strong>Local weighting</strong> assigns values to words based on how many times they appear in
a single document, while <strong>global weighting</strong> assigns values based on
word frequency across the entire collection. The intuition is that rare
words are more interesting than common words (global weighting), and
that words that appear once in a document are not as relevant as words
that occur multiple times (local weighting).</p></dd>



<dt><strong><a name="item_Incorporating_metadata">Incorporating Metadata</a></strong></dt>

<dd>
If your documents have metadata descriptors (dates, categories, author
names), then you can build those in to the vector model. Just add a slot for
each category, like you did for your keywords, and apply whatever kind
of weighting you desire.</dd>



<dt><strong><a name="item_Exact_phrase_matching">Exact Phrase Matching</a></strong></dt>

<dd>
You can add arbitrary constraints to your result set by adding a chain
of filters to your result set. An easy way to do exact phrase matching
is to loop through your result set with a regular expression. This kind
of post-processing is also a convenient way to sort your results by
something other than relevance.</dd>


</dl>



<h1><a name="further reading">Further Reading</a></h1>
<p>There's a vast body of material available on search engine design, but
little of it is targeted at the hobbyist or beginner. The following
are good places to start:</p>
<dl>
<dt><strong><a name="item_http%3A%2F%2Fhotwired%2Elycos%2Ecom%2Fwebmonkey%2F"></a><a href="http://hotwired.lycos.com/webmonkey/code/97/16/index2a.html?collection=perl">http://hotwired.lycos.com/webmonkey/code/97/16/index2a.html?collection=perl</a></strong></dt>

<dd>
This Webmonkey article dates back to 1997, but it's still the best tutorial on
writing a reverse index search engine in Perl.</dd>




<dt><strong><a name="item_http%3A%2F%2Fmoskalyuk%2Ecom%2Fsoftware%2Fperl%2Fs"></a><a href="http://moskalyuk.com/software/perl/search/kiss.htm">http://moskalyuk.com/software/perl/search/kiss.htm</a></strong></dt>

<dd>
An example of a simple keyword search engine - no database, just
a deep faith in Perl's ability to parse files quickly.</dd>



<dt><strong><a name="item_http%3A%2F%2Fwww%2Emovabletype%2Eorg%2Fdownload%2E"></a><a href="http://www.movabletype.org/download.shtml">http://www.movabletype.org/download.shtml</a></strong></dt>

<dd>
Movable Type is a popular weblog application, written in Perl. The
search engine lives in MT::App::Search, and supports several advanced
features. It's not pretty, but it's real production code.</dd>



<dt><strong><a name="item_http%3A%2F%2Fjakarta%2Eapache%2Eorg%2Flucene%2Fdoc"></a><a href="http://jakarta.apache.org/lucene/docs/index.html">http://jakarta.apache.org/lucene/docs/index.html</a></strong></dt>

<dd>
Lucene is a Java-based keyword search engine, part of the Apache project.
It's a well-designed, open-source search engine, intended for larger projects.
The documentation discusses some of the challenges of implementing a large
search engine; it's worth reading even if you don't know Java.</dd>



<dt><strong><a name="item_http%3A%2F%2Fmitpress%2Emit%2Eedu%2Fcatalog%2Fitem"></a><a href="http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&tid=3391">http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=3391</a></strong></dt>

<dd>
<em>Foundations of Statistical Natural Language Processing</em>, MIT Press (hardcover textbook).  Don't be put off by the title - this book is a fantastic introduction to all kinds of issues in text search, and includes a thorough 
discussion of vector space models.</dd>



<dt><strong><a name="item_http%3A%2F%2Fwww%2Enitle%2Eorg%2Flsi%2Fintro%2F"></a><a href="http://www.nitle.org/lsi/intro/">http://www.nitle.org/lsi/intro/</a></strong></dt>

<dd>
An introduction to <strong>latent semantic indexing</strong>,  the vector model on steroids.  The document is aimed at nontechnical readers, but gives some more background information on using vector techniques to search and visualize data collections.
<p>The adventurous can also download some Perl code for latent semantic
indexing at <a href="http://www.nitle.org/lsi.php.">http://www.nitle.org/lsi.php.</a> Both the code and the article
come from my own work for the National Institute for Technology and
Liberal Education.</p></dd>


</dl>



                                    </div>


                                </div>
                                <div class="asset-footer">

    
                                    <div class="entry-categories">
                                        <h4>Categories<span class="delimiter">:</span></h4>
                                        <ul>
                                            <li><a href="/pub/text-tools/" rel="tag">Text Tools</a></li>
                                        </ul>
                                    </div>
    


                                    <div class="entry-tags">
                                        <h4>Tags<span class="delimiter">:</span></h4>
                                        <ul>
                                            <li><a href="javascript:void(0)" onclick="location.href='http://www.perl.com/mt-search.cgi?blog_id=2&amp;tag=search%20engine%20vector%20space&amp;limit=20';return false;" rel="tag">search engine vector space</a></li>
                                        </ul>
                                    </div>

                                </div>
                            </div>


                    
                    


                        </div>
                    </div>


                    <div id="beta">
    <div id="beta-inner">


    
    <div class="widget-what-is-perl widget">
    <div class="widget-content widget-content-what-is-perl">
       Visit the home of the  Perl programming language: <a href="http://www.perl.org/">Perl.org</a
    </div>
</div>
<div class="widget-find-out-more widget-archives widget">
    <div class="widget-content">
        <ul>
            <li><a href="http://www.perl.org/get.html">Download</a></li>
            <li><a href="http://perldoc.perl.org/">Documentation</a></li>
            <li><a href="http://blogs.perl.org/">Perl Bloggers</a></li>
            <li><a href="http://news.perlfoundation.org/">Foundation News</a></li>
        </ul>
    </div>
</div><div class="widget-tcpc widget">
<h3 class="widget-header">Sponsored by</h3>
    <div class="widget-content">
        <a href="http://training.perl.com/" alt="Perl Training" target="_blank"><img src="/i/tcpc.png" width="150" height="50"></a>
    </div>
</div>

<div class="widget-syndication widget">
    <div class="widget-content">
        <ul>
            <li><img src="/mt-static/images/status_icons/feed.gif" alt="Subscribe to feed" width="9" height="9" /> <a href="/pub/atom.xml">Subscribe to this website's feed</a></li>

        </ul>
    </div>
</div>
<div class="widget-archive-monthly widget-archive widget">
    <h3 class="widget-header">Monthly <a href="/pub/archives.html">Archives</a></h3>
    <div class="widget-content">
        <ul>
        
            <li><a href="/pub/2010/07/">July 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/05/">May 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/04/">April 2008 (2)</a></li>
        
    
        
            <li><a href="/pub/2008/03/">March 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/02/">February 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/01/">January 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/12/">December 2007 (2)</a></li>
        
    
        
            <li><a href="/pub/2007/09/">September 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/08/">August 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/07/">July 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/06/">June 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/05/">May 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/04/">April 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/03/">March 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/02/">February 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/01/">January 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/12/">December 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/11/">November 2006 (2)</a></li>
        
    
        
            <li><a href="/pub/2006/10/">October 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/09/">September 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/08/">August 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/07/">July 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/06/">June 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/05/">May 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/04/">April 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/03/">March 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/02/">February 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2006/01/">January 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/12/">December 2005 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/11/">November 2005 (3)</a></li>
        
    
        
            <li><a href="/pub/2005/10/">October 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/09/">September 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/08/">August 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/07/">July 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/06/">June 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/05/">May 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/04/">April 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/03/">March 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2005/02/">February 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/01/">January 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/12/">December 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/11/">November 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/10/">October 2004 (5)</a></li>
        
    
        
            <li><a href="/pub/2004/09/">September 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/08/">August 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/07/">July 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/06/">June 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/05/">May 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2004/04/">April 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/03/">March 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/02/">February 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/01/">January 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/12/">December 2003 (4)</a></li>
        
    
        
            <li><a href="/pub/2003/11/">November 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/10/">October 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/09/">September 2003 (6)</a></li>
        
    
        
            <li><a href="/pub/2003/08/">August 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/07/">July 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/06/">June 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/05/">May 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/04/">April 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/03/">March 2003 (10)</a></li>
        
    
        
            <li><a href="/pub/2003/02/">February 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/01/">January 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/12/">December 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/11/">November 2002 (9)</a></li>
        
    
        
            <li><a href="/pub/2002/10/">October 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/09/">September 2002 (11)</a></li>
        
    
        
            <li><a href="/pub/2002/08/">August 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/07/">July 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/06/">June 2002 (4)</a></li>
        
    
        
            <li><a href="/pub/2002/05/">May 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/04/">April 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/03/">March 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/02/">February 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/01/">January 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/12/">December 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/11/">November 2001 (5)</a></li>
        
    
        
            <li><a href="/pub/2001/10/">October 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/09/">September 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/08/">August 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/07/">July 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/06/">June 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/05/">May 2001 (11)</a></li>
        
    
        
            <li><a href="/pub/2001/04/">April 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/03/">March 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/02/">February 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/01/">January 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2000/12/">December 2000 (6)</a></li>
        
    
        
            <li><a href="/pub/2000/11/">November 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/10/">October 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/09/">September 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/08/">August 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/07/">July 2000 (5)</a></li>
        
    
        
            <li><a href="/pub/2000/06/">June 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/05/">May 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/04/">April 2000 (3)</a></li>
        
    
        
            <li><a href="/pub/2000/03/">March 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/02/">February 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/01/">January 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/12/">December 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/11/">November 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/10/">October 1999 (5)</a></li>
        
    
        
            <li><a href="/pub/1999/09/">September 1999 (4)</a></li>
        
    
        
            <li><a href="/pub/1999/08/">August 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/07/">July 1999 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/06/">June 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/04/">April 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/03/">March 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/01/">January 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/12/">December 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/11/">November 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/07/">July 1998 (2)</a></li>
        
    
        
            <li><a href="/pub/1998/06/">June 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/03/">March 1998 (1)</a></li>
        
        </ul>
    </div>
</div>
        
    

<div class="widget-powered widget">
    <div class="widget-content">
        <a href="http://www.movabletype.com/"><img src="/mt-static/images/bug-pbmt-white.png" alt="Powered by Movable Type 5.02" width="120" height="75" /></a>
    </div>
</div>



    </div>
</div>






                </div>
            </div>


            <div id="footer">
    <div id="footer-inner">
        <div id="footer-content">
            <div class="widget-powered widget">
                <div class="widget-content">
                    Powered by <a href="http://www.movabletype.com/" rel="generator">Movable Type Pro</a>
                </div>
            </div>

        </div>
    </div>
</div>



        </div>
    </div>
</body>
</html>
