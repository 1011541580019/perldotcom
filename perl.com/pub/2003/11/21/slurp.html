<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" id="sixapart-standard">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="generator" content="Movable Type Pro 5.13-en" />
<link rel="stylesheet" href="/pub/styles.css" type="text/css" />
<link rel="start" href="/pub/" title="Home" />
<link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/pub/atom.xml" />
<script type="text/javascript" src="/pub/mt.js"></script>
<!--
<rdf:RDF xmlns="http://web.resource.org/cc/"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<Work rdf:about="/pub/2003/11/21/slurp.html">
<dc:title>Perl Slurp-Eaze</dc:title>
<dc:description><![CDATA[ One of the common Perl idioms is processing text files line by line: while( &lt;FH&gt; ) { do something with $_ } This idiom has several variants, but the key point is that it reads in only one line...]]></dc:description>
<dc:creator>Uri Guttman</dc:creator>
<dc:date>2003-11-21T00:00:00-08:00</dc:date>
<license rdf:resource="http://creativecommons.org/licenses/by-nc-nd/3.0/" />
</Work>
<License rdf:about="http://creativecommons.org/licenses/by-nc-nd/3.0/">
</License>
</rdf:RDF>
-->

<script type="text/javascript">

 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-50555-22']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type =
   'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
   'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0];
   s.parentNode.insertBefore(ga, s);
 })();

</script>
<script type='text/javascript' src='http://partner.googleadservices.com/gampad/google_service.js'></script>
<script type='text/javascript'>
GS_googleAddAdSenseService("ca-pub-4136420132070439");
GS_googleEnableAllServices();
</script>
<script type='text/javascript'>
GA_googleAddSlot("ca-pub-4136420132070439", "Perl_728x90");
</script>
<script type='text/javascript'>GA_googleFetchAds();</script>
    
    <link rel="prev bookmark" href="/pub/2003/11/17/lmsolve.html" title="Solving Puzzles with LM-Solve" />
    <link rel="next bookmark" href="/pub/2003/11/p6pdigest/20031123.html" title="This fortnight on Perl 6, week ending 2003-11-23" />
    
    
    <title>Perl Slurp-Eaze - Perl.com</title>
</head>
<body id="perl-com" class="mt-entry-archive layout-wt">
    <div id="container">
        <div id="container-inner">


            <div id="header">
    <div id="header-inner">
        <div id="header-content">
        <span id="top_advert"> 
<!-- Put any landscape advert in here -->
<!-- Perl_728x90 -->
<script type='text/javascript'>
GA_googleFillSlot("Perl_728x90");
</script>
        </span> 



            <div id="header-name"><a href="/pub/" accesskey="1">Perl.com</a></div>
            <div id="header-description">news and views of the Perl programming language</div>




        </div>
    </div>
</div>



            <div id="content">
                <div id="content-inner">


                    <div id="alpha">
                        <div id="alpha-inner">


                            <div id="entry-1220" class="entry-asset asset hentry">
                                <div class="asset-header">
                                    <h1 id="page-title" class="asset-name entry-title">Perl Slurp-Eaze</h1>
                                    <div class="asset-meta">
                                        <span class="byline">

                                            By <span class="vcard author">Uri Guttman</span> on <abbr class="published" title="2003-11-21T00:00:00-08:00">November 21, 2003 12:00 AM</abbr>

                                        </span>


                                    </div>
                                </div>
                                <div class="asset-content entry-content">

                                    <div class="asset-body">
                                        
<!-- sidebar begins -->
<!-- don't move sidebars -->
<!-- sidebar ends -->

<p>One of the common Perl idioms is processing text files line by line:</p>
<pre><code>
while( &lt;FH&gt; ) {
    do something with $_
}</code></pre>
<p>This idiom has several variants, but the key point is that it reads in
only one line from the file in each loop iteration. This has several
advantages, including limiting memory use to one line, the ability to
handle any size file (including data piped in via STDIN), and it is
easily taught to and understood by Perl beginners. Unfortunately, it
means they then go on to do things like this:</p>
<pre><code>
while( &lt;FH&gt; ) {
    push @lines, $_ ;
}

foreach ( @lines ) {
    do something with $_
}</code></pre>
<p>Line by line processing is fine, but it isn't the only way to deal with
reading files. The other common style is reading the entire file into a
scalar or array, and that is commonly known as slurping. Now, slurping has
somewhat of a poor reputation, and this article is an attempt at
rehabilitating it.</p>
<p>Slurping files has advantages and limitations, and is not something you
should just do when line by line processing is fine. It is best when you
need the entire file in memory for processing all at once. Slurping with
in memory processing can be faster and lead to simpler code than line by
line if done properly.</p>
<p>The biggest issue to watch for with slurping is file size. Slurping very
large files or unknown amounts of data from STDIN can be disastrous to
your memory usage and cause swap disk thrashing.  You can slurp STDIN if
you know that you can handle the maximum size input without
detrimentally affecting your memory usage, and so I advocate slurping only
disk files and only when you know their size is reasonable and you have
a real reason to process the file as a whole.</p>

<csperl file="grab" domain="on" record="b/515" template="b/article_sidebar.view">

<p>Note that &quot;reasonable&quot; size these days is larger than it was in the bad
old days of limited RAM. Slurping in a megabyte is not an issue on most
systems. But most of the files I tend to slurp in are much smaller than
that. Typical files that work well with slurping are configuration
files, (mini-)language scripts, some data (especially binary) files, and
other files of known sizes which need fast processing.</p>
<p>Another major win for slurping over line by line is speed. Perl's IO
system (like many others) is slow. Calling <code>&lt;&gt;</code> for each line
requires a check for the end of line, checks for EOF, copying a line,
munging the internal handle structure, etc. Plenty of work for each line
read in. On the other hand, slurping, if done correctly, will usually
involve only one I/O call and no extra data copying. The same is true
for writing files to disk, and we will cover that as well.</p>
<p>Finally, when you have slurped the entire file into memory, you can do
operations on the data that are not possible or easily done with line by
line processing. These include global search/replace (without regard for
newlines), grabbing all matches with one call of <code>//g</code>, complex parsing
(which in many cases must ignore newlines), processing *ML (where line
endings are just white space) and performing complex transformations
such as template expansion.</p>

<h3><a name="global operations">Global Operations</a></h3>
<p>Here are some simple global operations that can be done quickly and
easily on an entire file that has been slurped in. They could also be
done with line by line processing but that would be slower and require
more code.</p>
<p>A common problem is reading in a file with key/value pairs. There are
modules which do this but who needs them for simple formats? Just slurp
in the file and do a single parse to grab all the key/value pairs.</p>
<pre><code>
my $text = read_file( $file ) ;
my %config = $test =~ /^(\w+)=(.+)$/mg ;</code></pre>
<p>That matches a key which starts a line (anywhere inside the string
because of the <code>/m</code> modifier), the '=' char and the text to the end of the
line (again, <code>/m</code> makes that work). In fact the ending <code>$</code> is not even needed
since <code>.</code> will not normally match a newline. Since the key and value are
grabbed and the <code>m//</code> is in list context with the <code>/g</code> modifier, it will
grab all key/value pairs and return them. The <code>%config</code> hash will be
assigned this list and now you have the file fully parsed into a hash.</p>
<p>Various projects I have worked on needed some simple templating and I
wasn't in the mood to use a full module (please, no flames about your
favorite template module :-). So I rolled my own by slurping in the
template file, setting up a template hash and doing this one line:</p>
<pre><code>
$text =~ s/&lt;%(.+?)%&gt;/$template{$1}/g ;</code></pre>
<p>That only works if the entire file was slurped in. With a little
extra work it can handle chunks of text to be expanded:</p>
<pre><code>
$text =~ s/&lt;%(\w+)_START%&gt;(.+)&lt;%\1_END%&gt;/ template($1, $2)/sge ;</code></pre>
<p>Just supply a <code>template</code> sub to expand the text between the markers and
you have yourself a simple system with minimal code. Note that this will
work and grab over multiple lines due the the <code>/s</code> modifier. This is
something that is much trickier with line by line processing.</p>
<p>Note that this is a very simple templating system, and it can't directly
handle nested tags and other complex features. But even if you use one
of the myriad of template modules on the CPAN, you will gain by having
speedier ways to read and write files.</p>
<p>Slurping in a file into an array also offers some useful advantages. 
One simple example is reading in a flat database where each record has
fields separated by a character such as <code>:</code>:</p>
<pre><code>
my @pw_fields = map [ split /:/ ], read_file( '/etc/passwd' ) ;</code></pre>
<p>Random access to any line of the slurped file is another advantage. Also
a line index could be built to speed up searching the array of lines.</p>

<h3><a name="traditional slurping">Traditional Slurping</a></h3>
<p>Perl has always supported slurping files with minimal code. Slurping of
a file to a list of lines is trivial, just call the <code>&lt;&gt;</code> operator
in a list context:</p>
<pre><code>
my @lines = &lt;FH&gt; ;</code></pre>
<p>and slurping to a scalar isn't much more work. Just set the built in
variable <code>$/</code> (the input record separator) to the undefined value and read
in the file with <code>&lt;&gt;</code>:</p>
<pre><code>
{
    local( $/, *FH ) ;
    open( FH, $file ) or die &quot;sudden flaming death\n&quot;
    $text = &lt;FH&gt;
}</code></pre>
<p>Notice the use of <code>local()</code>. It sets <code>$/</code> to <code>undef</code> for you and when
the scope exits it will revert <code>$/</code> back to its previous value (most
likely &quot;\n&quot;).</p>
<p>Here is a Perl idiom that allows the <code>$text</code> variable to be declared,
and there is no need for a tightly nested block. The <code>do</code> block will
execute <code>&lt;FH&gt;</code> in a scalar context and slurp in the file named by
<code>$file</code>:</p>
<pre><code>
    local( *FH ) ;
    open( FH, $file ) or die &quot;sudden flaming death\n&quot;
    my $text = do { local( $/ ) ; &lt;FH&gt; } ;</code></pre>
<p>Both of those slurps used localized filehandles to be compatible with
5.005. Here they are with 5.6.0 lexical autovivified handles:</p>
<pre><code>
{
    local( $/ ) ;
    open( my $fh, $file ) or die &quot;sudden flaming death\n&quot;
    $text = &lt;$fh&gt;
}

        open( my $fh, $file ) or die &quot;sudden flaming death\n&quot;
        my $text = do { local( $/ ) ; &lt;$fh&gt; } ;</code></pre>
<p>And this is a variant of that idiom that removes the need for the open
call:</p>
<pre><code>
my $text = do { local( @ARGV, $/ ) = $file ; &lt;&gt; } ;</code></pre>
<p>The filename in <code>$file</code> is assigned to a localized <code>@ARGV</code> and the
null filehandle is used which reads the data from the files in <code>@ARGV</code>.</p>
<p>Instead of assigning to a scalar, all the above slurps can assign to an
array and it will get the file but split into lines (using <code>$/</code> as the
end of line marker).</p>
<p>There is one common variant of those slurps which is very slow and not
good code. You see it around, and it is almost always cargo cult code:</p>
<pre><code>
my $text = join( '', &lt;FH&gt; ) ;</code></pre>
<p>That needlessly splits the input file into lines (<code>join</code> provides a
list context to <code>&lt;FH&gt;</code>) and then joins up those lines again. The
original coder of this idiom obviously never read <em>perlvar</em> and learned
how to use <code>$/</code> to allow scalar slurping.</p>

<h3><a name="write slurping">Write Slurping</a></h3>
<p>While reading in entire files at one time is common, writing out entire
files is also done. We call it &quot;slurping&quot; when we read in files, but
there is no commonly accepted term for the write operation. I asked some
Perl colleagues and got two interesting nominations: Peter Scott said to
call it &quot;burping&quot; (rhymes with &quot;slurping&quot; and suggests movement in
the opposite direction); others suggested &quot;spewing&quot; which has a
stronger visual image :-) Tell me your favorite or suggest your own. I
will use both in this section so you can see how they work for you.</p>
<p>Spewing a file is a much simpler operation than slurping. You don't have
context issues to worry about and there is no efficiency problem with
returning a buffer. Here is a simple burp subroutine:</p>
<pre><code>
sub burp {
    my( $file_name ) = shift ;
    open( my $fh, &quot;&gt;$file_name&quot; ) || 
        die &quot;can't create $file_name $!&quot; ;
    print $fh @_ ;
}</code></pre>
<p>Note that it doesn't copy the input text but passes @_ directly to
print. We will look at faster variations of that later on.</p>

<h3><a name="slurp on the cpan">Slurp on the CPAN</a></h3>
<p>As you would expect there are modules in the CPAN that will slurp files
for you. The two I found are called Slurp.pm (by Rob Casey - ROBAU on
CPAN) and File::Slurp.pm (by David Muir Sharnoff - MUIR on CPAN).</p>
<p>Here is the code from Slurp.pm:</p>
<pre><code>
sub slurp { 
    local( $/, @ARGV ) = ( wantarray ? $/ : undef, @_ ); 
    return &lt;ARGV&gt;;
}

sub to_array {
    my @array = slurp( @_ );
    return wantarray ? @array : \@array;
}

sub to_scalar {
    my $scalar = slurp( @_ );
    return $scalar;
}</code></pre>
<p>The subroutine <code>slurp()</code> uses the magic undefined value of <code>$/</code> and
the magic file handle <code>ARGV</code> to support slurping into a scalar or
array. It also provides two wrapper subs that allow the caller to
control the context of the slurp. And the <code>to_array()</code> subroutine will
return the list of slurped lines or a anonymous array of them according
to its caller's context by checking <code>wantarray</code>. It has 'slurp' in
<code>@EXPORT</code> and all three subroutines in <code>@EXPORT_OK</code>.</p>
<p>File::Slurp.pm has this code:</p>
<pre><code>
sub read_file
{
    my ($file) = @_;

    local($/) = wantarray ? $/ : undef;
    local(*F);
    my $r;
    my (@r);

    open(F, &quot;&lt;$file&quot;) || croak &quot;open $file: $!&quot;;
    @r = &lt;F&gt;;
    close(F) || croak &quot;close $file: $!&quot;;

    return $r[0] unless wantarray;
    return @r;
}</code></pre>
<p>This module provides several subroutines including <code>read_file()</code> (more
on the others later). <code>read_file()</code> behaves similarly to
<code>Slurp::slurp()</code> in that it will slurp a list of lines or a single
scalar depending on the caller's context. It also uses the magic
undefined value of <code>$/</code> for scalar slurping but it uses an explicit
open call rather than using a localized <code>@ARGV</code> and the other module
did. Also it doesn't provide a way to get an anonymous array of the
lines but that can easily be rectified by calling it inside an anonymous
array constructor <code>[]</code>.</p>
<p>Both of these modules make it easier for Perl coders to slurp in
files. They both use the magic <code>$/</code> to slurp in scalar mode and the
natural behavior of <code>&lt;&gt;</code> in list context to slurp as lines. But
neither is optimized for speed nor can they handle <code>binmode()</code> to
support binary or unicode files. See below for more on slurp features
and speedups.</p>

<h3><a name="slurping api design">Slurping API Design</a></h3>
<p>The slurp modules on CPAN are have a very simple API and don't support
<code>binmode()</code>. This section will cover various API design issues such as
efficient return by reference, <code>binmode()</code> and calling variations.</p>
<p>Let's start with the call variations. Slurped files can be returned in
four formats: as a single scalar, as a reference to a scalar, as a list
of lines or as an anonymous array of lines. But the caller can only
provide two contexts: scalar or list. So we have to either provide an
API with more than one subroutine (as Slurp.pm did) or just provide one
subroutine which only returns a scalar or a list (not an anonymous
array) as File::Slurp does.</p>
<p>I have used my own <code>read_file()</code> subroutine for years and it has the
same API as File::Slurp: a single subroutine that returns a scalar or a
list of lines depending on context. But I recognize the interest of
those that want an anonymous array for line slurping. For one thing, it
is easier to pass around to other subs and, for another, it eliminates
the extra copying of the lines via <code>return</code>. So my module will support
multiple subroutines with one that returns the file based on context, and
the other returns only lines (either as a list or as an anonymous
array). So this API is in between the two CPAN modules. There is no need
for a specific slurp-in-as-a-scalar subroutine as the general <code>slurp()</code>
will do that in scalar context. If you wanted to slurp a scalar into an
array, just select the desired array element and that will provide
scalar context to the <code>read_file()</code> subroutine.</p>
<p>The next area to cover is what to name these subs. I will go with
<code>read_file()</code> and <code>read_file_lines()</code>. They are descriptive, simple and don't
use the 'slurp' nickname (though that nickname is in the module name).</p>
<p>Another critical area when designing APIs is how to pass in
arguments. The <code>read_file*()</code> subroutines takes one required argument
which is the file name. To support <code>binmode()</code> we need another optional
argument. A third optional argument is needed to support returning a
slurped scalar by reference. My first thought was to design the API with
3 positional arguments - file name, buffer reference and binmode. But if
you want to set the binmode and not pass in a buffer reference, you have
to fill the second argument with <code>undef</code> and that is ugly. So I decided
to make the filename argument positional and the other two named. The
subroutine starts off like this:</p>
<pre><code>
sub read_file {

    my( $file_name, %args ) = @_ ;

    my $buf ;
    my $buf_ref = $args{'buf'} || \$buf ;</code></pre>
<p>The binmode argument will be handled later (see code below).</p>
<p>The other sub (<code>read_file_lines()</code>) will only take an optional binmode
(so you can read files with binary delimiters). It doesn't need a buffer
reference argument since it can return an anonymous array if the called
in a scalar context. So this subroutine could use positional arguments,
but to keep its API similar to the API of <code>read_file()</code>, it will also
use pass by name for the optional arguments. This also means that new
optional arguments can be added later without breaking any legacy
code. A bonus with keeping the API the same for both subs will be seen
how the two subs are optimized to work together.</p>
<p>Write slurping (or spewing or burping <code>:-)</code>) needs to have its API
designed as well. The biggest issue is not only needing to support
optional arguments but a list of arguments to be written is needed. Perl
6 will be able to handle that with optional named arguments and a final
slurp argument. Since this is Perl 5, we have to do it using some
cleverness. The first argument is the file name and it will be
positional as with the <code>read_file</code> subroutine. But how can we pass in
the optional arguments and also a list of data? The solution lies in the
fact that the data list should never contain a reference.
Burping/spewing works only on plain data. So if the next argument is a
hash reference, we can assume it contains the optional arguments and
the rest of the arguments is the data list. So the <code>write_file()</code>
subroutine will start off like this:</p>
<pre><code>
sub write_file {

    my $file_name = shift ;

    my $args = ( ref $_[0] eq 'HASH' ) ? shift : {} ;</code></pre>
	
<p>Whether or not optional arguments are passed in, we leave the data list
in <code>@_</code> to minimize any more copying. You call <code>write_file()</code> like this:</p>
<pre><code>
write_file( 'foo', { binmode =&gt; ':raw' }, @data ) ;
write_file( 'junk', { append =&gt; 1 }, @more_junk ) ;
write_file( 'bar', @spew ) ;</code></pre>













<h3><a name="fast slurping">Fast Slurping</a></h3>
<p>Somewhere along the line, I learned about a way to slurp files faster
than by setting $/ to undef. The method is very simple, you do a single
read call with the size of the file (which the -s operator provides).
This bypasses the I/O loop inside perl that checks for EOF and does all
sorts of processing. I then decided to experiment and found that
sysread is even faster as you would expect. sysread bypasses all of
Perl's stdin and reads the file from the kernel buffers directly into a
Perl scalar. This is why the slurp code in File::Slurp uses
sysopen/sysread/syswrite. All the rest of the code is just to support
the various options and data passing techniques.</p>
<p></p>


<h3>Benchmarks</h3>
<p>Benchmarks can be enlightening, informative, frustrating and
deceiving. It would make no sense to create a new and more complex slurp
module unless it also gained significantly in speed. So I created a
benchmark script which compares various slurp methods with differing
file sizes and calling contexts. This script can be run from the main
directory of the tarball like this:</p>
<pre><code>
perl -Ilib extras/slurp_bench.pl</code></pre>
<p>If you pass in an argument on the command line, it will be passed to
<code>timethese()</code> and it will control the duration. It defaults to -2 which
makes each benchmark run to at least 2 seconds of CPU time.</p>
<p>The following numbers are from a run I did on my 300Mhz sparc. You will
most likely get much faster counts on your boxes but the relative speeds
shouldn't change by much. If you see major differences on your
benchmarks, please send me the results and your Perl and OS
versions. Also you can play with the benchmark script and add more slurp
variations or data files.</p>
<p>The rest of this section will be discussing the results of the
benchmarks. You can refer to extras/slurp_bench.pl to see the code for
the individual benchmarks. If the benchmark name starts with cpan_, it
is either from Slurp.pm or File::Slurp.pm. Those starting with new_ are
from the new File::Slurp.pm. Those that start with file_contents_ are
from a client's code base. The rest are variations I created to
highlight certain aspects of the benchmarks.</p>
<p>The short and long file data is made like this:</p>
<pre><code>
my @lines = ( 'abc' x 30 . &quot;\n&quot;)  x 100 ;
my $text = join( '', @lines ) ;

@lines = ( 'abc' x 40 . &quot;\n&quot;)  x 1000 ;
$text = join( '', @lines ) ;</code></pre>
<p>So the short file is 9,100 bytes and the long file is 121,000
bytes.</p>

<h4><a name="scalar slurp of short file">Scalar Slurp of Short File</a></h4>
<pre><code>
file_contents        651/s
file_contents_no_OO  828/s
cpan_read_file      1866/s
cpan_slurp          1934/s
read_file           2079/s
new                 2270/s
new_buf_ref         2403/s
new_scalar_ref      2415/s
sysread_file        2572/s</code></pre>

<h4><a name="scalar slurp of long file">Scalar Slurp of Long File</a></h4>
<pre><code>
file_contents_no_OO 82.9/s
file_contents       85.4/s
cpan_read_file       250/s
cpan_slurp           257/s
read_file            323/s
new                  468/s
sysread_file         489/s
new_scalar_ref       766/s
new_buf_ref          767/s</code></pre>
<p>The primary inference you get from looking at the numbers above is that
when slurping a file into a scalar, the longer the file, the more time
you save by returning the result via a scalar reference. The time for
the extra buffer copy can add up. The new module came out on top overall
except for the very simple sysread_file entry which was added to
highlight the overhead of the more flexible new module which isn't that
much. The file_contents entries are always the worst since they do a
list slurp and then a join, which is a classic newbie and cargo culted
style which is extremely slow. Also the OO code in file_contents slows
it down even more (I added the file_contents_no_OO entry to show this).
The two CPAN modules are decent with small files but they are laggards
compared to the new module when the file gets much larger.</p>

<h4><a name="list slurp of short file">List Slurp of Short File</a></h4>
<pre><code>
cpan_read_file          589/s
cpan_slurp_to_array     620/s
read_file               824/s
new_array_ref           824/s
sysread_file            828/s
new                     829/s
new_in_anon_array       833/s
cpan_slurp_to_array_ref 836/s</code></pre>

<h4><a name="list slurp of long file">List Slurp of Long File</a></h4>
<pre><code>
cpan_read_file          62.4/s
cpan_slurp_to_array     62.7/s
read_file               92.9/s
sysread_file            94.8/s
new_array_ref           95.5/s
new                     96.2/s
cpan_slurp_to_array_ref 96.3/s
new_in_anon_array       97.2/s</code></pre>
<p>This is perhaps the most interesting result of this benchmark. Five
different entries have effectively tied for the lead. The logical
conclusion is that splitting the input into lines is the bounding
operation, no matter how the file gets slurped. This is the only
benchmark where the new module isn't the clear winner (in the long file
entries - it is no worse than a close second in the short file
entries).</p>
<p>Note: In the benchmark information for all the spew entries, the extra
number at the end of each line is how many wall-clock seconds the whole
entry took. The benchmarks were run for at least 2 CPU seconds per
entry. The unusually large wall-clock times will be discussed below.</p>

<h4><a name="scalar spew of short file">Scalar Spew of Short File</a></h4>
<pre><code>
cpan_write_file 1035/s  38
print_file      1055/s  41
syswrite_file   1135/s  44
new             1519/s  2
print_join_file 1766/s  2
new_ref         1900/s  2
syswrite_file2  2138/s  2</code></pre>

<h4><a name="scalar spew of long file">Scalar Spew of Long File</a></h4>
<pre><code>
cpan_write_file 164/s   20
print_file      211/s   26
syswrite_file   236/s   25
print_join_file 277/s   2
new             295/s   2
syswrite_file2  428/s   2
new_ref         608/s   2</code></pre>
<p>In the scalar spew entries, the new module API wins when it is passed a
reference to the scalar buffer. The <code>syswrite_file2</code> entry beats it
with the shorter file due to its simpler code. The old CPAN module is
the slowest due to its extra copying of the data and its use of print.</p>

<h4><a name="list spew of short file">List Spew of Short File</a></h4>
<pre><code>
cpan_write_file  794/s  29
syswrite_file   1000/s  38
print_file      1013/s  42
new             1399/s  2
print_join_file 1557/s  2</code></pre>

<h4><a name="list spew of long file">List Spew of Long File</a></h4>
<pre><code>
cpan_write_file 112/s   12
print_file      179/s   21
syswrite_file   181/s   19
print_join_file 205/s   2
new             228/s   2</code></pre>
<p>Again, the simple <code>print_join_file</code> entry beats the new module when
spewing a short list of lines to a file. But is loses to the new module
when the file size gets longer. The old CPAN module lags behind the
others since it first makes an extra copy of the lines and then it calls
<code>print</code> on the output list and that is much slower than passing to
<code>print</code> a single scalar generated by join. The <code>print_file</code> entry
shows the advantage of directly printing <code>@_</code> and the
<code>print_join_file</code> adds the join optimization.</p>
<p>Now about those long wall-clock times. If you look carefully at the
benchmark code of all the spew entries, you will find that some always
write to new files and some overwrite existing files. When I asked David
Muir why the old File::Slurp module had an <code>overwrite</code> subroutine, he
answered that by overwriting a file, you always guarantee something
readable is in the file. If you create a new file, there is a moment
when the new file is created but has no data in it. I feel this is not a
good enough answer. Even when overwriting, you can write a shorter file
than the existing file and then you have to truncate the file to the new
size. There is a small race window there where another process can slurp
in the file with the new data followed by leftover junk from the
previous version of the file. This reinforces the point that the only
way to ensure consistent file data is the proper use of file locks.</p>
<p>But what about those long times? Well it is all about the difference
between creating files and overwriting existing ones. The former have to
allocate new inodes (or the equivalent on other file systems) and the
latter can reuse the existing inode. This mean the overwrite will save on
disk seeks as well as on cpu time. In fact when running this benchmark,
I could hear my disk going crazy allocating inodes during the spew
operations. This speedup in both cpu and wall-clock is why the new module
always does overwriting when spewing files. It also does the proper
truncate (and this is checked in the tests by spewing shorter files
after longer ones had previously been written). The <code>overwrite</code>
subroutine is just an typeglob alias to <code>write_file</code> and is there for
backwards compatibility with the old File::Slurp module.</p>

<h4><a name="benchmark conclusion">Benchmark Conclusion</a></h4>
<p>Other than a few cases where a simpler entry beat it out, the new
File::Slurp module is either the speed leader or among the leaders. Its
special APIs for passing buffers by reference prove to be very useful
speedups. Also it uses all the other optimizations including using
<code>sysread/syswrite</code> and joining output lines. I expect many projects
that extensively use slurping will notice the speed improvements,
especially if they rewrite their code to take advantage of the new API
features. Even if they don't touch their code and use the simple API
they will get a significant speedup.</p>

<h3><a name="error handling">Error Handling</a></h3>
<p>Slurp subroutines are subject to conditions such as not being able to
open the file, or I/O errors. How these errors are handled, and what the
caller will see, are important aspects of the design of an API. The
classic error handling for slurping has been to call <code>die()</code> or even
better, <code>croak()</code>. But sometimes you want the slurp to either
<code>warn()</code>/<code>carp()</code> or allow your code to handle the error. Sure, this
can be done by wrapping the slurp in a <code>eval</code> block to catch a fatal
error, but not everyone wants all that extra code. So I have added
another option to all the subroutines which selects the error
handling. If the 'err_mode' option is 'croak' (which is also the
default), the called subroutine will croak. If set to 'carp' then carp
will be called. Set to any other string (use 'quiet' when you want to
be explicit) and no error handler is called. Then the caller can use the
error status from the call.</p>
<p><code>write_file()</code> doesn't use the return value for data so it can return a
false status value in-band to mark an error. <code>read_file()</code> does use its
return value for data, but we can still make it pass back the error
status. A successful read in any scalar mode will return either a
defined data string or a reference to a scalar or array. So a bare
return would work here. But if you slurp in lines by calling it in a
list context, a bare <code>return</code> will return an empty list, which is the
same value it would get from an existing but empty file. So now,
<code>read_file()</code> will do something I normally strongly advocate against,
i.e., returning an explicit <code>undef</code> value. In the scalar context this
still returns a error, and in list context, the returned first value
will be <code>undef</code>, and that is not legal data for the first element. So
the list context also gets a error status it can detect:</p>
<pre><code>
my @lines = read_file( $file_name, err_mode =&gt; 'quiet' ) ;
your_handle_error( &quot;$file_name can't be read\n&quot; ) unless
    @lines &amp;&amp; defined $lines[0] ;</code></pre>

<h3><a name="the implementation">The implementation</a></h3>
<p>Here's the whole code which implements my faster slurp:</p>
<pre><code>
sub read_file {

    my( $file_name, %args ) = @_ ;

    my $buf ;
    my $buf_ref = $args{'buf_ref'} || \$buf ;

    my $mode = O_RDONLY ;
    $mode |= O_BINARY if $args{'binmode'} ;

    local( *FH ) ;
    sysopen( FH, $file_name, $mode ) or
        carp &quot;Can't open $file_name: $!&quot; ;

    my $size_left = -s FH ;

    while( $size_left &gt; 0 ) {

        my $read_cnt = sysread( FH, ${$buf_ref},
            $size_left, length ${$buf_ref} ) ;

        unless( $read_cnt ) {

            carp &quot;read error in file $file_name: $!&quot; ;
            last ;
        }

            $size_left -= $read_cnt ;
    }

# handle void context (return scalar by buffer reference)
    return unless defined wantarray ;

# handle list context
    return split m|?&lt;$/|g, ${$buf_ref} if wantarray ;

# handle scalar context
    return ${$buf_ref} ;
}

sub read_file_lines {
# handle list context
return &amp;read_file if wantarray;
# otherwise handle scalar context
return [ &amp;read_file ] ;
}

sub write_file {

    my $file_name = shift ;

    my $args = ( ref $_[0] eq 'HASH' ) ? shift : {} ;
    my $buf = join '', @_ ;

    my $mode = O_WRONGLY ;
    $mode |= O_BINARY if $args-&gt;{'binmode'} ;
    $mode |= O_APPEND if $args-&gt;{'append'} ;

    local( *FH ) ;
    sysopen( FH, $file_name, $mode ) or
        carp &quot;Can't open $file_name: $!&quot; ;

    my $size_left = length( $buf ) ;
    my $offset = 0 ;

    while( $size_left &gt; 0 ) {

        my $write_cnt = syswrite( FH, $buf,
                $size_left, $offset ) ;

        unless( $write_cnt ) {

            carp &quot;write error in file $file_name: $!&quot; ;
            last ;
        }

        $size_left -= $write_cnt ;
        $offset += $write_cnt ;
    }

    return ;
}</code></pre>

<h3><a name="in summary">In Summary</a></h3>
<p>We have compared classic line-by-line processing with munging a whole
file in memory. Slurping files can speed up your programs and simplify
your code, if done properly. You must still be aware to not slurp
humongous files (logs, DNA sequences, and so forth), or STDIN, where you don't
know how much data you will read in. But slurping megabyte-size files
is not a major issue on today's systems with the typical amount of RAM
installed. When Perl was first being used in-depth (Perl 4), slurping
was limited by the smaller RAM size of ten years ago. Now, you should be
able to slurp almost any reasonably sized file, whether it contains
configuration, source code, or data.</p>

                                    </div>


                                </div>
                                <div class="asset-footer">


                                    <div class="entry-tags">
                                        <h4>Tags<span class="delimiter">:</span></h4>
                                        <ul>
                                            <li><a href="javascript:void(0)" onclick="location.href='http://www.perl.com/mt-search.cgi?IncludeBlogs=2&amp;tag=slurp%20slurping%20file%20io&amp;limit=20';return false;" rel="tag">slurp slurping file io</a></li>
                                        </ul>
                                    </div>

                                </div>
                            </div>


                    
                    


                        </div>
                    </div>


                    <div id="beta">
    <div id="beta-inner">


    
    <div class="widget-what-is-perl widget">
    <div class="widget-content widget-content-what-is-perl">
       Visit the home of the  Perl programming language: <a href="http://www.perl.org/">Perl.org</a
    </div>
</div>
<div class="widget-find-out-more widget-archives widget">
    <div class="widget-content">
        <ul>
            <li><a href="http://www.perl.org/get.html">Download</a></li>
            <li><a href="http://perldoc.perl.org/">Documentation</a></li>
            <li><a href="http://blogs.perl.org/">Perl Bloggers</a></li>
            <li><a href="http://news.perlfoundation.org/">Foundation News</a></li>
        </ul>
    </div>
</div><div class="widget-tcpc widget">
<h3 class="widget-header">Sponsored by</h3>
    <div class="widget-content">
        <a href="http://training.perl.com/" alt="Perl Training" target="_blank"><img src="/i/tcpc.png" width="150" height="50"></a>
    </div>
</div>

<div class="widget-syndication widget">
    <div class="widget-content">
        <ul>
            <li><img src="/mt-static/images/status_icons/feed.gif" alt="Subscribe to feed" width="9" height="9" /> <a href="/pub/atom.xml">Subscribe to this website's feed</a></li>

        </ul>
    </div>
</div>
<div class="widget-archive-monthly widget-archive widget">
    <h3 class="widget-header">Monthly <a href="/pub/archives.html">Archives</a></h3>
    <div class="widget-content">
        <ul>
        
            <li><a href="/pub/2014/02/">February 2014 (1)</a></li>
        
    
        
            <li><a href="/pub/2014/01/">January 2014 (1)</a></li>
        
    
        
            <li><a href="/pub/2013/10/">October 2013 (1)</a></li>
        
    
        
            <li><a href="/pub/2013/01/">January 2013 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/12/">December 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/11/">November 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/10/">October 2012 (2)</a></li>
        
    
        
            <li><a href="/pub/2012/08/">August 2012 (2)</a></li>
        
    
        
            <li><a href="/pub/2012/06/">June 2012 (11)</a></li>
        
    
        
            <li><a href="/pub/2012/05/">May 2012 (18)</a></li>
        
    
        
            <li><a href="/pub/2012/04/">April 2012 (17)</a></li>
        
    
        
            <li><a href="/pub/2012/02/">February 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/12/">December 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/09/">September 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/08/">August 2011 (2)</a></li>
        
    
        
            <li><a href="/pub/2011/06/">June 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/05/">May 2011 (3)</a></li>
        
    
        
            <li><a href="/pub/2011/04/">April 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/03/">March 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/02/">February 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/01/">January 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/11/">November 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/10/">October 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/09/">September 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/08/">August 2010 (3)</a></li>
        
    
        
            <li><a href="/pub/2010/07/">July 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/04/">April 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/03/">March 2010 (4)</a></li>
        
    
        
            <li><a href="/pub/2008/05/">May 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/04/">April 2008 (2)</a></li>
        
    
        
            <li><a href="/pub/2008/03/">March 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/02/">February 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/01/">January 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/12/">December 2007 (2)</a></li>
        
    
        
            <li><a href="/pub/2007/09/">September 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/08/">August 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/07/">July 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/06/">June 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/05/">May 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/04/">April 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/03/">March 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/02/">February 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/01/">January 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/12/">December 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/11/">November 2006 (2)</a></li>
        
    
        
            <li><a href="/pub/2006/10/">October 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/09/">September 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/08/">August 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/07/">July 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/06/">June 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/05/">May 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/04/">April 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/03/">March 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/02/">February 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2006/01/">January 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/12/">December 2005 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/11/">November 2005 (3)</a></li>
        
    
        
            <li><a href="/pub/2005/10/">October 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/09/">September 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/08/">August 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/07/">July 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/06/">June 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/05/">May 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/04/">April 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/03/">March 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2005/02/">February 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/01/">January 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/12/">December 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/11/">November 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/10/">October 2004 (5)</a></li>
        
    
        
            <li><a href="/pub/2004/09/">September 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/08/">August 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/07/">July 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/06/">June 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/05/">May 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2004/04/">April 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/03/">March 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/02/">February 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/01/">January 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/12/">December 2003 (4)</a></li>
        
    
        
            <li><a href="/pub/2003/11/">November 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/10/">October 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/09/">September 2003 (6)</a></li>
        
    
        
            <li><a href="/pub/2003/08/">August 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/07/">July 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/06/">June 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/05/">May 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/04/">April 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/03/">March 2003 (10)</a></li>
        
    
        
            <li><a href="/pub/2003/02/">February 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/01/">January 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/12/">December 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/11/">November 2002 (9)</a></li>
        
    
        
            <li><a href="/pub/2002/10/">October 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/09/">September 2002 (11)</a></li>
        
    
        
            <li><a href="/pub/2002/08/">August 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/07/">July 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/06/">June 2002 (4)</a></li>
        
    
        
            <li><a href="/pub/2002/05/">May 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/04/">April 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/03/">March 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/02/">February 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/01/">January 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/12/">December 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/11/">November 2001 (5)</a></li>
        
    
        
            <li><a href="/pub/2001/10/">October 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/09/">September 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/08/">August 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/07/">July 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/06/">June 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/05/">May 2001 (11)</a></li>
        
    
        
            <li><a href="/pub/2001/04/">April 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/03/">March 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/02/">February 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/01/">January 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2000/12/">December 2000 (6)</a></li>
        
    
        
            <li><a href="/pub/2000/11/">November 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/10/">October 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/09/">September 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/08/">August 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/07/">July 2000 (5)</a></li>
        
    
        
            <li><a href="/pub/2000/06/">June 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/05/">May 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/04/">April 2000 (3)</a></li>
        
    
        
            <li><a href="/pub/2000/03/">March 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/02/">February 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/01/">January 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/12/">December 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/11/">November 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/10/">October 1999 (5)</a></li>
        
    
        
            <li><a href="/pub/1999/09/">September 1999 (4)</a></li>
        
    
        
            <li><a href="/pub/1999/08/">August 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/07/">July 1999 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/06/">June 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/04/">April 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/03/">March 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/01/">January 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/12/">December 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/11/">November 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/07/">July 1998 (2)</a></li>
        
    
        
            <li><a href="/pub/1998/06/">June 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/03/">March 1998 (1)</a></li>
        
        </ul>
    </div>
</div>
        
    

<div class="widget-powered widget">
    <div class="widget-content">
        <a href="http://www.movabletype.com/"><img src="/mt-static/images/bug-pbmt-white.png" alt="Powered by Movable Type 5.13-en" width="120" height="75" /></a>
    </div>
</div>



    </div>
</div>






                </div>
            </div>


            <div id="footer">
    <div id="footer-inner">
        <div id="footer-content">
            <div class="widget-powered widget">
                <div class="widget-content">
                    Powered by <a href="http://www.movabletype.com/" rel="generator">Movable Type Pro</a>
                </div>
            </div>

            <div class="widget-creative-commons widget">
                <div class="widget-content">
                    This blog is licensed under a <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/">Creative Commons License</a>.
                </div>
            </div>

        </div>
    </div>
</div>



        </div>
    </div>
</body>
</html>
