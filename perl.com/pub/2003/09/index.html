<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" id="sixapart-standard">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="generator" content="Movable Type Pro 5.13-en" />
<link rel="stylesheet" href="/pub/styles.css" type="text/css" />
<link rel="start" href="/pub/" title="Home" />
<link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/pub/atom.xml" />
<script type="text/javascript" src="/pub/mt.js"></script>
<!--
<rdf:RDF xmlns="http://web.resource.org/cc/"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<Work rdf:about="/pub/">
<dc:title>Perl.com</dc:title>
<dc:description>news and views of the Perl programming language</dc:description>
<license rdf:resource="http://creativecommons.org/licenses/by-nc-nd/3.0/" />
</Work>
<License rdf:about="http://creativecommons.org/licenses/by-nc-nd/3.0/">
</License>
</rdf:RDF>
-->

<script type="text/javascript">

 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-50555-22']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type =
   'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
   'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0];
   s.parentNode.insertBefore(ga, s);
 })();

</script>
<script type='text/javascript' src='http://partner.googleadservices.com/gampad/google_service.js'></script>
<script type='text/javascript'>
GS_googleAddAdSenseService("ca-pub-4136420132070439");
GS_googleEnableAllServices();
</script>
<script type='text/javascript'>
GA_googleAddSlot("ca-pub-4136420132070439", "Perl_728x90");
</script>
<script type='text/javascript'>GA_googleFetchAds();</script>
    <title>Perl.com: September 2003 Archives</title>


    <link rel="prev" href="/pub/2003/08/" title="August 2003" />
    <link rel="next" href="/pub/2003/10/" title="October 2003" />

</head>
<body id="perl-com" class="mt-archive-listing mt-datebased-monthly-archive layout-wt">
    <div id="container">
        <div id="container-inner">


            <div id="header">
    <div id="header-inner">
        <div id="header-content">
        <span id="top_advert"> 
<!-- Put any landscape advert in here -->
<!-- Perl_728x90 -->
<script type='text/javascript'>
GA_googleFillSlot("Perl_728x90");
</script>
        </span> 



            <div id="header-name"><a href="/pub/" accesskey="1">Perl.com</a></div>
            <div id="header-description">news and views of the Perl programming language</div>




        </div>
    </div>
</div>



            <div id="content">
                <div id="content-inner">


                    <div id="alpha">
                        <div id="alpha-inner">


                            <h1 id="page-title" class="archive-title">September 2003 Archives</h1>





                            
                            <div id="entry-1192" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2003/09/25/searching.html" rel="bookmark">Adding Search Functionality to Perl Applications</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author">Aaron Trevena</span> on <abbr class="published" title="2003-09-25T00:00:00-08:00">September 25, 2003 12:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            
<!-- sidebar begins -->
<!-- don't move sidebars -->
<!-- sidebar ends -->
<h3> Introduction to Searching </h3>
<p>Usually, when building an application, a lot of thought goes into how 
    the data is entered and updated, rather than finding it again. Finding 
    data is an afterthought, especially when developing with a small dataset. 
</p>
<p>If you are building a small, simple database-backed web site with only 
    a couple of hundred records, then relatively simple SQL should be all 
    you need. It would be trivial to add a simple <i>and Foo_Name like '%keyword%'</i> 
    to the queries being used. </p>
<p>When your needs go beyond this, there are three ways you can proceed: 
    you can use native database full-text searching, an external search 
    engine, or you can roll your own. Most relational databases come with 
    a full-text search functionality, but can have disadvantages: </p>
<ul>
    <li> Mutually incompatible syntax and behavior.</li>
    <li> Poor and often unconfigurable ranking and scoring.</li>
    <li> Difficult or impossible to query across multiple tables.</li>
    <li> Require schema changes and rebuilding of indexes for any additional 
        or removed fields.</li>
    <li> Lack of advanced features such as application context, word</li>
    stemming, synonyms, and handling misspellings.</li> 
</ul>
<p>An external search engine, such as <code>htdig</code>, offers independence from your 
    database and application, as well as powerful indexing and 
    searching functionality. However, this solution is limited in how it 
    can interact with your application -- it depends both on its crawler 
    and own your applications interface. An external search engine can quickly 
    become out of date, as changes to your data will not be reflected until 
    it next reads through your site. </p>
<p>Integrating customized searching into your application can provide you 
    with many benefits:</p>
<ul>
    <li> A cross-platform search component that: 
        <ul>
            <li>Doesn't tie you to a specific database.</li>
            <li>Is easy to abstract and re-use.</li>
        </ul>
    </li>
    <li> The ability to customize how searching works: 
        <ul>
            <li> Search subsets of data or across tables.</li>
            <li> Tune scoring, weighting, stemming, stop-words, etc.</li>
            <li> Utilize relationships to provide additional data.</li>
            <li> Specify when and how to update the index according to your 
                needs.</li>
            <li> Add extra columns or tables without modifying the schema 
                or interface.</li>
        </ul>
    </li>
    <li> Leverage the metadata and word index: 
        <ul>
            <li> Re-use the data to provide extra features, such as computing 
                vectors to find similar records.</li>
            <li> Categorize data according to vectors or important keywords, 
                rather than using tables or by hand.</li>
        </ul>
    </li>
</ul>
<p>When you build searching into your application, it can make the difference 
    between users finding the right information on your site or going somewhere 
    else -- advanced search syntax and features are no substitute for finding 
    the right results for the user in the first place!</p>
<h3>Organizing and Indexing Your Data</h3>
<p>Most search engines use a reverse (or inverted) index to store a list 
    of words or phrases and locations where they are found. This means building 
    up a list of locations, which could be web pages, files, objects or 
    database records, and then adding an entry into the index for each word 
    found, specifying the location, and possibly some metadata like a score 
    or the type of location. </p>
<p>A reverse index can be just a simple table:</p>
<pre><code>create table ReverseIndex (
 ReverseIndex_Word varchar(32) not null,
 ReverseIndex_Document varchar(255) not null,
 ReverseIndex_Score int,
 primary key (ReverseIndex_Word, ReverseIndex_Document)
)</code></pre>

<p>This table assumes that each document has a score for each word, based 
    on, perhaps, the number of occurrences. Some example data would look something 
    like this: </p>

<table border="1" cellpadding="2">
    <tr> 
        <th>ReverseIndex_Word </th>
        <th> ReverseIndex_Document </th>
        <th> ReverseIndex_Score</th>
    </tr>
    <tr>
        <td>art</td>
        <td>/samantha/stuff/ballet.doc</td>
        <td>2</td>
    </tr>
    <tr>
        <td>ballet</td>
        <td>/samantha/stuff/ballet.doc</td>
        <td>5</td>
    </tr>
    <tr>
        <td>boy</td>
        <td>/aaron/simpsons/homer/quotes.foo</td>
        <td>2</td>
    </tr>
    <tr>
        <td>boy</td>
        <td>/samantha/stuff/ballet.doc</td>
        <td>1</td>
    </tr>
    <tr>
        <td>dance</td>
        <td>/aaron/simpsons/homer/quotes.foo</td>
        <td>2</td>
    </tr>
    <tr>
        <td>dance</td>
        <td>/samantha/stuff/ballet.doc</td>
        <td>5</td>
    </tr>
    <tr>
        <td>monkey</td>
        <td>/aaron/simpsons/homer/quotes.foo</td>
        <td> 1 </td>
    </tr>
</table>
<p>To search the index for Homer's "Dance monkey boy dance!" quote, you 
    would split, lowercase, remove duplicates and punctuation, and build 
    a query from the array: </p>

<pre><code>
SELECT ReverseIndex_Document as Name, 
       Sum(ReverseIndex_Score) as Total_Score, 
       Count(ReverseIndex_Score) as Matches
FROM ReverseIndex
WHERE ReverseIndex_Word IN ('dance','monkey','boy')
GROUP BY ReverseIndex_Document
ORDER BY Matches DESC , Total_Score DESC</code></pre>

<p>This query returns:</p>
<table border="1" cellpadding="2">
    <tr>
        <td><b>Name</b></td>
        <td><b>Total_Score</b></td>
        <td><b>Count</b></td>
    </tr>
    <tr>
        <td>/aaron/simpsons/homer/quotes.foo</td>
        <td>5</td>
        <td>3</td>
    </tr>
    <tr>
        <td>/samantha/stuff/ballet.doc</td>
        <td>6</td>
        <td>2</td>
    </tr>
</table>

<p>This query has a few features that make it more effective. The query 
    tests not only the sum of scores, but also the number of matches. Ordering 
    by matches before scores is a crude measure to give slightly better 
    results than just by score, where a single highly scored word in a document 
    can skew the results. </p>
<p>Because your search results are only as good as your index, it is worth 
    investing the time to polishing your index to minimize skewed results. 
    You can limit your scores per record or normalize the whole index. This 
    would ensure that results are more even, and therefore more likely to 
    give the results the user is looking for. </p>
<p>The key to integrating a customized search into your application is the 
    ability to use additional contextual information to give more accurate 
    results. This additional information could be records in other tables, 
    filenames, or any other metadata you have available. In the example 
    above, if we also indexed the words "homer" and "quote" from the file 
    name and path, and the user had entered "homer" and/or "quote," the score 
    and rank for the "quotes.foo" document would be much better and more 
    accurately reflect what the user was looking for. </p>
<h3>Adding Indexing and Searching to a Legacy Application</h3>
<p>Although it can be easier to provide a search engine externally through 
    Lucene or Swish, you don't have to tightly integrate searching at a 
    code level to reap benefits from customized indexing. Adding your own 
    search engine can be a high-level operation. When adding search functionality 
    to a legacy application, you have the choice of reworking the code, annexing, 
    or adding triggers. </p>
<a name="annexing"></a>

<h4>Annexing Searching to an Application</h4>
<p>Annexing searching to your application can be as simple as couple of 
    extra tables in a database and a <code>perl</code> script called from <code>cron</code>. The database 
    need only contain the reverse index and some summary information about 
    the locations that would be displayed in search results. </p>
<p>Your searching logic should do the minimum of work to ensure fast results, 
    with as much of the work as possible being done up front. This is the 
    flaw in just adding simple SQL queries to pages to provide searching: they're simply not efficient. Exact matches on indexed columns as, 
    in a reverse index, are far faster than the SQL-like/wildcard queries 
    people tack onto a page to allow searching, and built-in database full-text 
    indexes will be very slow or may not even be available when searching 
    columns not specified in the index. This leaves a lot of work to be 
    done for each search, which is avoided when you roll your own. </p>
<p>This simple example uses two tables, a script for indexing, and a <code>mod_perl</code> 
    handler for searching. The <code>ReverseIndex</code> table is going to be three columns: <code>Word</code>, <code>Score</code>, and <code>Location</code>. </p>

<pre><code>create table ReverseIndex ( 
ReverseIndex_Word varchar(64), 
ReverseIndex_Score float, 
Location_ID int, 
primary key( ReverseIndex_Word, ReverseIndex_Score )
)</code></pre>

<p>The Location table will have seven columns: <code>Location_ID</code>, <code>Title</code>, <code>Type</code>, <code>Key</code>, 
    <code>Identifier</code>, <code>URL</code>, and <code>Summary</code>.</p>

<pre><code>create table Location (
Location_ID integer primary key auto_increment,
Location_Title varchar(64),
Location_Type varchar(16),
Location_Key varchar(32),
Location_Identifier integer,
Location_URL varchar(255),
Location_Summary text
)</code></pre>













<p>The indexing script just reads records from the application table and 
    populates the reverse index and locations tables. This example uses 
    a simple local weighting based on the fields and doesn't check if locations 
    already exist. (If you store your application data in XML, it should 
    still be relatively simple to change the code fetching data from the 
    database to pull from XML files instead.) </p>

<pre><code># give fields weighting
my %weight = ( Pub_Name => 1, 
               Pub_Type => 0.5, 
               Pub_Description => 0.8, 
               Brewery_Name=> 0.6, 
               Town_Name => 0.4);

# fetch records from the Pub table, joined against Town and Brewery
my $sth = $dbh->prepare('select 
    Pub_ID, Pub_Name, Pub_Type, Pub_Description, 
    Brewery_Name, Town_Name 
    from Pubs, Brewerys, Towns 
    where Towns.Town_ID = Pubs.Town_ID and 
          Brewerys.Brewery_ID = Pubs.Brewery_ID');
my $rv = $sth->execute();

while (my $record = $sth->fetchrow_hashref() ) {
  my %words = ();
  # create the location
  # index the record
  my $location_sth = $dbh->prepare_cached("
    insert into Location 
        (Location_Title, Location_Type, Location_Key, 
        Location_Identifier, Location_URL, 
        Location_Summary ) 
    values (?,'Pub','Pub_ID',?,'/pub.cgi', ?) 
  ");
  (my $summary) = $record->{Pub_Description} =~ /(\w+\s+){0,20}/;
  my $rv = $location_sth->execute(
        $record->{Pub_Name}, $record->{Pub_ID}, "$summary .."
  );
  my $location = $dbh->{mysql_insertid};

  # short stop-word dictionary
  my @stopwords = qw/a i you he she they the it is as to 
                     not on or no/;
  my %stopwords; @stopwords{@stopwords} = @stopwords;

  # delete all old words for this location
  my $deleted = $dbh->do("
    delete from ReverseIndex 
    where Location_ID = $location");

  foreach my $field ( keys %$record ) {
    # split the words out of the field ( from Tim Kientzle's article )
    my @words = split(/[^a-zA-Z0-9\xc0-\xff\+\/\_\-]+/, 
                        lc $record->{$field});

                # Strip leading punct
    @words    = grep { s/^[^a-zA-Z0-9\xc0-\xff\_\-]+//; $_ } 
                # Must be longer than one character
                grep { length > 1 }	
                # must have an alphanumeric
                grep { /[a-zA-Z0-9\xc0-\xff]/ }	@words;

    # score the words
    foreach (@words) { 
      next if $stopwords{$_};
      $words{$_} += $weight{$field} 
        unless defined $words{$_} && $words{$_} > 5;
    }
  }

  # insert the new words into the index
  my $sth = $dbh->prepare('
 insert into ReverseIndex 
        (ReverseIndex_Word, ReverseIndex_Score, Location_ID) 
 values (?,?,? ) ');
  foreach my $word (keys %words) {
    my $rv = $sth->execute($word,$words{$word},$location);
  }
}</code></pre>

<p>The search handler only really needs a simple SQL query with an autogenerated 
    clause, and a short dictionary of stop words (see above). </p>

<pre><code>package Search::Pub;

use strict;
use DBI;
use Template;

use Apache;
use Apache::Constants;

my %stopwords;
@stopwords{(qw(a i at be do to or is not no the 
               that they then these them who where 
               why can find on an of and it by))} = 1 x 27;

my $dbh = DBI->connect("DBI:mysql:pubs:host", 'username', 'password');

# initialise and create template
my $config = {
    INCLUDE_PATH => '/search/path',  # or list ref
    POST_CHOMP   => 1,               # cleanup whitespace
};
my $template_file = 'results.tt';
my $template = Template->new($config);

sub handler {
  my $r = shift;

  # remove stoplist words
  my @wordlist  = split(/\s+/,$r->param('searchstring'));
  my @shortlist = ();
  my @arglist   = ();

  foreach my $word (@wordlist) {
    next if ($stopwords{$word});
    push(@shortlist, $word);
    push(@arglist,'?')
  }
  
  # build SQL
  my $where = 'WHERE ReverseIndex_Word IN (' 
              . join(',',@arglist) . ') ';
  my $sql = qq{
  SELECT Location_Title, 
         sum(ReverseIndex_Score) as score, 
         count(*) as count, 
         Location_Summary, Location_ID, Location_Key, 
         Location_Identifier, Location_URL
  FROM   ReverseIndex, Location
  $where
  AND ReverseIndex.Location_ID = Location.Location_ID
  Group By ReverseIndex.Location_ID 
  Order By score DESC, Count DESC };

  my $sth = $dbh->prepare($sql) 
    or $r->warn("couldn't prepare statement!\n");
  $sth->execute(@shortlist);
  my $results = $sth->fetchall_arrayref();

  # populate template variables
  my $template_vars = { foo=>'bar'};
  $template_vars->{Results} = $results;
  $template_vars->{Words} = @shortlist;

  # output page
  $r->send_http_header('TEXT/HTML');
  $template->process($template_file, $template_vars, $r) 
    || die $template->error();

  return OK;
}</code></pre>
<a name="modifying"></a>

<h4>Modifying Your Objects to Use a Trigger</h4>
<p>An easy way to add indexing to objects is to use <code>Class::Trigger</code>. 
    A good example of this can be seen in Kake Pugh's <a
    href="#kh">article</a>, where she combines <code>Search::InvertedIndex</code> 
    with <code>Class::DBI</code>'s trigger support, or in Tony Bowden's <code>Class::DBI::mysql::FullTextSearch</code>.</p>
<p>Using triggers provides an alternative to hacking calls to reindex the 
    object in each place it is updated. More importantly, it allows you 
    to separate the indexing from the object to another piece of code -- 
    possibly implementing the update outside of the object, in the application, 
    or even in a <code>mod_perl</code> cleanup handler (tricky, but possible). </p>
<p>If you already have objects to which you wish to add indexing, then using 
    triggers means minimal changes to your objects and therefore less regression 
    testing -- allowing you to get on with adding your indexing and searching 
    code to your application. You can also build objects that index themselves 
    with minimal code. For example: </p>

<pre><code>
 use Class::Trigger

 . . .

 sub set_foo {
      my ($self,$new_value) = @_;

      . . .

      $self->call_trigger('after_update');

      . . .
 }
</code></pre>

<p>You could then add a trigger elsewhere in the application, or possibly 
    in a subclass, that would call your indexing logic:</p>

<pre><code>
 $object->add_trigger( after_update => sub {
      my $self = shift;
      # logic to index object
      reindex($self->{id},$self); # pass identifier and object
      return;
  } );
</code></pre>













<p>The indexing logic would update the reverse index table based on the 
    object's identifier and type. If you are keeping data about your objects/locations 
    in a separate table, then you will need to get the foreign key that 
    joins the tables before updating the reverse index table itself. </p>

<pre><code>
sub reindex {
  my ($id,$object) = @_;
 
  # fetch the foreign key if required
  my ($location) = $dbh->selectrow_array("
    select Location_ID 
    from Location 
    where Location_Type = '$type' 
        and Location_Identifier = $id");

  # build new word/score data structure according to object type
  my %words = ();
  foreach my $field ( @{$objectfields{$type}} ) {
    my $text = $object->{$field->{name}};
    my @words = split(/[^a-zA-Z0-9\xc0-\xff\+\/\_\-]+/, lc $text);
    @words    = grep { s/^[^a-zA-Z0-9\xc0-\xff\_\-]+//; $_ }
	        grep { length > 1 }         
	        grep { /[a-zA-Z0-9\xc0-\xff]/ } 
	        @words;

    # score the words
    foreach (@words) { 
      next if $stopwords{$_};
      $words{$_} += $field->{weight} 
        unless ($words{$_} > 5 );
    }
  }

  # mark old indexed values and fetch them
  $dbh->do("update ReverseIndex 
            set ReverseIndex_Obselete = 1 
            where Location_ID = $location");
  my @oldvalues = $dbh->selectcol_arrayref("
        select ReverseIndex_Word 
        from ReverseIndex 
        where Location_ID = $location" );

  # update values already present
  my $sth = $dbh->prepare('update ReverseIndex 
    set ReverseIndex_Score = ?, 
    set ReverseIndex_Obselete = 0 
    where Location_ID = ? and ReverseIndex_Word = ?');

  foreach my $word (@oldvalues) {
    next unless ( defined $words{$word} );
    $sth->execute($words{$word},$location,$word);
    delete $words{$word};
  }

  # insert new values
  $sth = $dbh->prepare('
    insert into ReverseIndex 
    (ReverseIndex_Word, ReverseIndex_Score, 
        Location_ID, ReverseIndex_Obselete) 
    values ( :word, :score, :location, 0) ');

  foreach my $word (keys %words) {
    $sth->execute($word,$words{$word},$location);
    delete $words{$word};
  }

  # delete remaining obselete values
  $dbh->do("delete from ReverseIndex 
            where Location_ID = $location 
                and ReverseIndex_Obselete = 1");
}
</code></pre>

<p>This process ensures the minimum of interruption to service -- rather than 
    doubling entries or removing all entries for an object while it was 
    being updated. It would be slower than a simple wipe and replace, but 
    for frequently read and updated objects, it would ensure more consistent 
    search results. It would be simple to add object-level locking by checking 
    before the update that no entries for an object are marked obselete; 
    this would stop corruption of the index when multiple processes are 
    updating a single object. </p>
<p>That takes care of indexing; for searching, you can either re-use the 
    <code>mod_perl</code> search handler above, or add a new search method to your class. 
    The following example assumes it is called as <code>$objects = myapp->myclass::search($searchstring);</code>: 
</p>

<pre><code>sub search {
  my ($class,$searchstring) = @_;

  # remove stoplist words
  . . .
  
  # build SQL
  my $where = 'WHERE ReverseIndex_Word IN (' 
                    . join(',',('?' x scalar @shortlist)) . ') ';
  my $sql = qq{
  SELECT Location_Title as title, 
         sum(ReverseIndex_Score) as score, 
         count(*) as count, 
         Location_Summary as summary, 
         Location_Identifier, 
         Location_URL as url
  FROM   ReverseIndex, Location
  $where
      AND ReverseIndex.Location_ID = Location.Location_ID
  Group By ReverseIndex.Location_ID 
  Order By score DESC, Count DESC };

  my $sth = $dbh->prepare($sql) or warn "couldn't prepare statement !\n";
  $sth->execute(@shortlist);

  # build a list of objects from the search results
  my $objects = [];
  while ( my $result = $sth->fetchrow_hashref ) {
    my $object = myapp::myclass->new(id => $result->{Location_Identifier}));
    push (@$objects, { object  => $object, 
                       score   => $result->{score}, 
                       count   => $result->{count},
                       url     => $result->{url}, 
                       summary => $result->{summary}, 
                       title   => $result->{title<!---->} );
  }

  return $objects;
}</code></pre>
<a name="integrating"></a>

<h3>Integrating Indexing Into a New Class or Application</h3>
<p>Whether building a new application or refactoring an old one, it is worth 
    factoring "searchability" into the design. Designing in searching at 
    the start can save a lot of work later as database schemas and business 
    logic change. </p>
<p>The foundation of your application's searching facilities will be the 
    index. One way to proceed is to have a two-level index, with the normal 
    reverse index table, plus a lookup table that provides additional information 
    about the objects indexed. This lookup table can be used to hold all 
    of the information you wish to display with the results in a single place. 
</p>

<pre><code>create table ReverseIndex (
 ReverseIndex_Word varchar(64) not null,
 Location_ID int not null,
 ReverseIndex_Score int default 0,
 ReverseIndex_Fields text,
 primary key (ReverseIndex_Word,Location_ID)
)

create table Location (
 Location_ID int primary key auto_increment,
 Location_Type varchar(32),
 Location_Key varchar(32),
 Location_KeyValue int,
 Location_Title varchar(128),
 Location_Summary text,
 Location_URL varchar(255)
)</code></pre>

<p>Any extra information you wish to show in the results -- such as paths, 
    icons, or the objects status -- should be stored in the <code>Location</code> table. 
    If a location has been replaced or should only be visible under certain 
    conditions, you can keep relevant flags in this table and check them 
    when processing the results. </p>
<p>Turning to the code side of searching, a good trick is to use <code>perl</code>'s 
    multiple inheritance to make your application's objects inherit from 
    a superclass that contains the search logic. This <code>IndexedObject</code> class 
    provides a fine-grained, incremental update to the index, reindexing 
    individual object attributes as they are changed. If your object only 
    updates the database when the object is synchronized explicitly, then 
    you can either reindex the whole object or keep track of changes and 
    index the fields that have been changed as part of your synchronize 
    method. Here's a sample base class that provides a few reverse indexing 
    methods: </p>

<pre><code>
package myapp::classes::IndexedObject;
use strict;

use myapp::libraries::Search;

################
# public methods

sub index_object {
  my $self = shift;
  foreach $field (keys %{$self->{_RIND_fields}} ) {
    $self->index_field($self->,$field,$self->{$field});
  }
}

sub index_field {
  my ($self, $field, $value) = @_;
  return 0 unless $self->{_RIND_fields}{$field};
  my $location = $self->{_RIND_Location};
  my $query = "select * from $self->{table} 
               where Location_ID = ?";
  my $sth = $self->{_RIND_DBH}->prepare($query);
  my $rv = $sth->execute($location);
  my %newwords = ();
  my @newwords = get_words($string);
  foreach my $word (@newwords) {
    next if ($stopwords{$word});
    $newwords{$word} += $self->{_RIND_fields}{$field}{weight};
  }

  while ( my $row = $sth->fetchrow_hashref() ) {
    next unless ($row->{ReverseIndex_Fields} =~ m/'$field'/);
    $self->{locationwords}{$row->{ReverseIndex_Word}} = $row;

    my %fields = ( $row->{ReverseIndex_Fields} =~ m/'(.*?)':([\d.]+)/g );

    if ( exists $newwords{$row->{ReverseIndex_Word}} ) {
      $self->_RIND_UpdateFieldEntry( $row, $field, 
                       $newwords{$row->{ReverseIndex_Word}});
      delete $newwords{$row->{ReverseIndex_Word}};
    } else {
      $self->_RIND_RemoveFieldEntry($row,$field,$lid);
    }
  }

  foreach my $word ( keys %newwords ) {
    $self->_RIND_AddFieldEntry($lid,$word,$newwords{$word},$field);
  }

}

sub delete_location {
  my $self = shift;

  my $query = "delete from ReverseIndex where Location_ID = ?";
  my $sth = $self->{_RIND_DBH}->prepare($query);
  my $rv1 = $sth->execute($self->{_RIND_Location});

  $query = "delete from Location where Location_ID = ?";
  $sth = $self->{_RIND_DBH}->prepare($query);
  my $rv2 = $sth->execute($self->{_RIND_Location});

  return $rv1 + $rv2;
}

sub indexed_fields {
  my ($self,%args) = @_;
  if (keys %args) {
    $self->{_RIND_DBH} = $args{dbh} if defined $args{dbh};
    if defined $args{key} {
      $self->{_RIND_Key} = $args{key};
      ($self->{_RIND_Location}) = 
        $self->{_RIND_DBH}->selectrow_array("
            select Location_ID 
            from Location 
            where Location_Key = '$args{key}' 
            and Location_KeyValue = $self->{$args{key}}");
    }
    if ( defined $args{fields} ) {
      foreach (@{$args{$fields}}) { 
        $self->{_RIND_fields}{$_->{name}} = $_ ; 
      }
    }
  }
  return @{$self->{_RIND_FIELDS}} if wantarray; 
}

#################
# private methods 

sub _RIND_UpdateFieldEntry {
  my ($self,$row, $field,$score) = @_;
  my %fields = ($row->{Location_Fields} =~ m/'(.*?)':([\d.]+)/g);

  # recalculate total score
  my $newscore = ($row->{ReverseIndex_Score} - $fields{$field}) 
                 + $score;
  if ($fields{$field} == $score) {
    # skip if the same
    return 1;
  }

  # update entry, removing field and score from end
  $fields{$field} = $score;
  my $newfields;
  foreach (keys %fields) {
    $newfields .= "'$_':$fields{$_}";
  }
  $self->_RIND_UpdateIndex(
        word      => $row->{ReverseIndex_Word},
        location  => $row->{Location_ID},
        newscore  => $newscore,
        newfields => $newfields);
}

sub _RIND_AddFieldEntry {
  my ($self,$location, $word, $score, $field) = @_;

  # check if record already exists for this location 
  # and update/insert entry
  if (exists $self->{locationwords}{$word}) {
    # recalculate total score
    my $newscore = $self->{locationwords}{$word}{ReverseIndex_Score} 
                  + $score;
    # update entry, appending field and score to end
    my $newfields = $self->{locationwords}{$word}{Location_Fields} 
                    . "'$field':$score";
    $self->_RIND_UpdateIndex(
        word      => $word,
        location  => $location,
        newscore  => $newscore,
        newfields => $newfields);
  } else {
    # insert new entry
    $self->_RIND_UpdateIndex(
        insert   => 1,
        word     => $word,
        location => $location,
        score    => $score,
        fields   =>"'$field':$score");
  }
}

sub _RIND_RemoveFieldEntry {
  my ($self,$row,$field,$lid) = @_;

  # check if record contains other fields
  my %fields = ( $row->{Location_Fields} =~ m/'(.*?)':([\d.]+)/g );
  if ( keys %fields > 1 ) {
    # recalculate total score
    my $newscore = $row->{ReverseIndex_Score} - $fields{$field};
    delete $fields{$field};
    # update entry, removing field and score from end
    my $newfields = '';
    foreach (keys %fields) {
      $newfields .= "'$_':$fields{$_}";
    }
    $self->_RIND_UpdateIndex(
        word      => $row->{ReverseIndex_Word},
        location  => $lid,
        newscore  => $newscore,
        newfields => $newfields
    );
  } else {
    # delete entry
    $self->_RIND_UpdateIndex(
        word      => $row->{ReverseIndex_Word},
        location  => $lid,
        newscore  => $newscore,
        newfields => $newfields,
        delete    => 1
    );
  }
}

sub _RIND_UpdateIndex {
  my ($self,%args) = @_;
  my $query = "update $self->{table} 
               set ReverseIndex_Score = ?, 
                   Location_Fields = ? 
               where ReverseIndex_Word = ? 
                   and Location_ID = ?";

  my @args = ($args{newscore},$args{newfields},$args{word},$args{location});

  SWITCH : {
    if ($args{insert} == 1) {
      $query = "insert into $self->{table} 
                (ReverseIndex_Score, Location_Fields, 
                 ReverseIndex_Word, Location_ID) 
                values (?,?,?,?) "; 
      last;
    }
    if ($args{delete} == 1) {
      $query = "delete from $self->{table} 
                where ReverseIndex_Word = ? 
                    and Location_ID = ?";
      @args = ($args{word},$args{location});
      last;
    }
  } # end of SWITCH
  my $sth = $self->{dbh}->prepare($query);
  my $rv = $sth->execute(@args);
  return;
}
</code></pre>













<p>The code that extracts words from objects and search queries has to 
    be the same, so it is a good candidate for putting into a separate library; 
    this also helps make the code more manageable. </p>

<pre><code>myapp::libraries::Search;
use strict;
require Exporter;

our @ISA = qw(Exporter);
our @EXPORT = qw(%stopwords &amp;get_words);

# stop words
my %stopwords;
@stopwords{(qw(a i at be do to or is not no the that they 
    then these them who where why can find on an of and it by))} = 1 x 27;

sub get_words {
  my $text = shift;
  # Split text into Array of words
  my @words = split(/[^a-zA-Z0-9\xc0-\xff\+\/\_\-]+/, lc $text);
           # Strip leading punct
  @words = grep { s/^[^a-zA-Z0-9\xc0-\xff\_\-]+//; $_ } 
           # Must be longer than one character
	       grep { length > 1 }         
           # must have an alphanumeric
	       grep { /[a-zA-Z0-9\xc0-\xff]/ } @words;
  return @words;
}</code></pre>

<p>Your own objects can then inherit the index and search methods from the 
    superclass and provide their own logic to manage how metadata is stored. 
</p>

<pre><code>package myapp::classes::Pub;
use strict;

our @ISA = qw(myapp::classes::IndexedObject 
              myapp::classes::DatabaseObject);

sub new {

 . . .

 $self->indexed_fields(
                       dbh=>$self->get_dbh, key=>'Pub_ID',
                       fields=>[
                                { name=>'Pub_Name', weight=>1}, 
                                  . . .
                               ],
                      );
 return $self;
}

sub create {
  my ($class,%args) = @_;
  my $self = $class->_new();
  $self->_initialise_from_values(%args);
  $self->create_location(%args);
  $self->index_object();
  return $self;
}

sub load {
  my ($class,%args) = @_;
  my $self = $class->_new();
  $self->_initialise_from_db(%args);
  return $self;
}

sub update {
  my ($self, $field, $value) = @_;
  $self->{$field} = $value;
  $self->execute("update Pubs 
                  set $field = ? 
                  where Pub_ID = ?",
                  $value, $self->{Pub_ID});

  $self->IndexField($self->{Pub_ID},$field,$value);
  return 1;
}

sub delete {
  my $self = shift;
  $self->delete_location();
  $self->execute("delete from pubs 
                  where = Pub_ID = ?",$value);
}</code></pre>

<p>Adding lookups and replacements to your objects indexing logic can be 
    pretty painless. Here's the data that gets passed to <code>indexed_fields</code> 
    for a <code>Pub</code> object. </p>

<pre><code>      fields=>[
           { name=>'Pub_Name', weight=>1}, 
           { name   => 'Brewery_Name', 
             weight => '0.4', 
             lookup => 'Brewery_ID', 
             table  => 'Brewery'},
           { name   =>'Pub_IsCAMRA', 
             weight =>'0.6', 
             replace=>'CAMRA Real Ale'}
          ],
      table=>'Pub',
</code></pre>

The hard work can be done in the superclass, updating the <code>index_fields</code> 
method to do lookups and replacements. 

<pre><code>sub index_fields {
  my ($self, $field, $value) = @_;
  return 0 unless $self->{_RIND_fields}{$field};
  my $location = $self->{_RIND_Location};
  my $query = 'select * from $self->{table} where Location_ID = ?';
  my $sth = $self->{_RIND_DBH}->prepare($query);
  my $rv = $sth->execute($location);
  my %newwords = ();

  if ( defined $self->{_RIND_fields}{$field}{replace} ) {
    @words = get_words($self->{_RIND_fields}{$field}{replace});
  } elsif ( defined $self->{_RIND_fields}{$field}{lookup} ) {
    my $column = $self->{_RIND_fields}{$field}{lookup};
    my $table = $self->{_RIND_fields}{$field}{table};
    my $words = $self->{_RIND_DBH}->selectrow_array("
        select $field 
        from $table 
        where $table.$column = $self->{table}.$column ");
    @words = get_words($words);
  } else {
    warn "this is just a normal field\n";
    @words = get_words ($fields{$field->{name}});
  }

  my @newwords = get_words($string);
  foreach my $word (@newwords) {
    next if ($stopwords{$word});
    $newwords{$word} += $self->{_RIND_fields}{$field}{weight};
  }

  while ( my $row = $sth->fetchrow_hashref() ) {
    $self->{locationwords}{$row->{ReverseIndex_Word}} = $row;
    next unless ($row->{ReverseIndex_Fields} =~ m/'$field'/);
    my %fields = ( $row->{ReverseIndex_Fields} =~ m/'(.*?)':([\d.]+)/g );
    if ( exists $newwords{$row->{ReverseIndex_Word}} ) {
      $self->_RIND_UpdateFieldEntry($row,$field,
                        $newwords{$row->{ReverseIndex_Word}});
      delete $newwords{$row->{ReverseIndex_Word}};
    } else {
      $self->_RIND_RemoveFieldEntry($row,$field,$lid);
    }
  }

  foreach my $word ( keys %newwords ) {
    $self->_RIND_AddFieldEntry($lid,$word,$newwords{$word},$field);
  }

}</code></pre>

<p>The problem with doing lookups is that it's possible that another object could 
    update some data that affects other objects. To avoid this, you'll 
    have to make the other object check which objects would be affected 
    by changes to itself. </p>
<p>If you store the indexed fields in the database, it's possible to only 
    check those object types affected with two queries: the first query 
    will get the object types that index the changed field, and the second 
    will update the affected records, joining as per the original lookup. 
    An alternative to keeping the indexed fields in the database would be 
    to keep the indexing information in an XML file -- such a file could also 
    contain configuration options that the search system could check, such 
    as whether to use stemming, ranges for grades, and so on. </p>
<p>The two-level solution we discussed with the additional metadata table 
    lets us store data about which object attributes are indexed and how, 
    and it also allows for easy reporting. Additionally, we can control 
    the indexing process purely by updating the database or XML, without 
    having to modify the codebase at all. </p>

<h4>Normalizing and Global Weighting</h4>
<p>Normalizing scores within the reverse index ensures that all scores are 
    within constrained limits, making them much easier to interpret and 
    use in your application. How you normalize the scores depends on both 
    the data you have indexed and how it will be searched. A common scenario 
    is that the index breaks down into three groups of words. </p>
<ul>
    <li> <b>A small number of high-scoring words, with relatively low frequency.</b> 
        These words are usually rare across the data set, but appear frequently 
        in a small number of objects.</li>
    <li> <b>Some middle-scoring words with a high frequency across the index.</b> 
        These words are common across the whole data set.</li>
    <li> <b>A large number of low-scoring words with low frequency.</b> These words 
        occur rarely in the data set and rarely in any object.</li>
</ul>
<img src="/pub/2003/09/25/graphics/normal2.gif" align="right" alt="" /> 
<p>A simple way to normalize scores, while at the same time narrowing the 
    gap between high-scoring and low-scoring words, is to use the sine curve 
    to reshape the distribution of scores. </p>
<p>This graph shows the area of the sine curve we are using -- the flat top 
    reducing the impact of outlying high scores and translating scores into 
    a value between 0 and 1 -- in this case, the maximum is assumed to be 
    10. The normalize function show here can be added to the <code>myapp::libraries::Search</code> 
    module and called from <code>IndexObject</code>'s indexing methods. 
</p>

<pre><code> sub normalise {
   my $score = shift;
   return sin(($score/$max)/(PI/4));
 }
</code></pre>

<p>If your data (scores by frequency) follow more of a bell curve, with 
    a small number of low-scoring words, many middle-scoring words and a 
    few high-scoring words, you would want to normalize using mu-law or a-law 
    functions. In this example, outliers at top and bottom are compressed 
    to fit within the range of 0 to 1 -- see the chart below. </p>

<img src="/pub/2003/09/25/graphics/normal4.gif" alt="" /> <br />

<pre><code>use Math::Trig;

. . .

sub normalise {
   my $score = shift;
   $score = ($score / $max) * 10;
   return sin(1 + tanh($score -5 )) / 2;
} 
</code></pre>

<p>When indexing, you can weight scores both locally and globally. Local 
    weighting is covered earlier in the article, and global weighting reduces 
    the scores of frequently found or particularly highly scoring words 
    that can skew results, as well as increase the scores of rare words. 
</p>













<p>For the best results when weighting scores globally, you should normalize 
    in advance to ensure a limited range of scores; this can also reign 
    in outlying scores that could skew the weighting. Global weighting of 
    scores requires that scores still reflect the relevance of an object, 
    and can be problematic if the solution doesn't consider that a rare 
    word with a low mean score can still have a few high scores that could 
    end up being scored too highly, or vice versa, making results less, 
    rather than more, useful. </p>

<pre><code>
sub global_weighted_score {
  my ($word,$score) = @_;
  my $word_avg = get_average($word); # get average score for word
  my $global_avg = get_average($word);       # get average score across index
  $score = normalise($score);                # normalise score before weighting
  if ($word_avg > $global_avg) {
    $score += (($global_avg - $word_avg) * 0.25) / 
                ($global_avg / $score ); 
  } else {
    $score += (($global_avg - $word_avg) * 0.25) / 
                ($score / $global_avg );
  }
  return $score;
}

sub get_average {
  my $word = shift;
  my $query = 'select avg(ReverseIndex_Score) 
                 from ReverseIndex';
  if ($word) {
    $word = $dbh->quote($word);
    $query .= " where ReverseIndex_Word = $word";
  }
  my ($avg) = $dbh->selectrow_array($query);
  return $avg;
}
</code></pre>

<p>There is nothing stopping you from keeping multiple scores in your index 
    for each word; as long as you index them appropriately, there will not 
    be a significant impact on performance. In particular, you could weight 
    scores at the class level as well as at the global level. Keeping track of original, 
    normalized, and weighted scores means that changes to code require only 
    recalculating of scores rather than re-indexing everything. This additional 
    information could also be included in data made available through web 
    services. </p>

<h4>Stopwords</h4>
<p>Integrating indexing and searching into your classes allows you to have 
    class-level or even object-level stopwords. This can be particularly 
    handy when one word is so frequent in one class or set of objects as 
    to become meaningless, while rare and useful in others, and resolving 
    the limitations of global weighting. </p>
<p>Stopwords can be normalized by ignoring them while building the word 
    list and adding them later, based on other object attributes. For instance, 
    if you had a load of objects representing pubs, you could add the pub's 
    town to the global or class stopword list and then give all pubs in 
    "Watford" the same score for "Watford" in the index. Other options would 
    be to score down words in the index based on object attributes such 
    as location, or even having stopwords apply to specific fields -- for 
    example, if you ignored the word "watford" in the description of a pub, 
    you could still increase the pub's score for "watford" if it was in 
    a name or address field -- so a pub called "The Watford Arms" would score 
    higher than "The Kings Head."</p>
<a name="results"></a>

<h3>Integrating the Search into Your Application</h3>
<p>The results are the important part as far as the user is concerned -- 
    this where all the hard work should bear fruit with a responsive site 
    and useful information. </p>
<p>Critical considerations are:</p>
<ul>
    <li>What information is needed.</li>
    <li>How ranking and scoring will be determined. </li>
    <li>How to normalize scores if they are shown. </li>
</ul>
<p>Showing results for subsets or grouping can also be important. Your 
    presentation of the results can also make a difference -- paging and 
    balancing the trade-off between the amount of information you can show 
    for each result and how many results you can fit on a page. </p>
<p>Assuming the database schema outlined earlier, it would be possible to 
    denormalize some of the information held into the <code>Location</code> table. Although 
    this will consume some more memory, it saves on joining tables when searching, 
    and would be updated at the same time as the index, so remaining in sync 
    with the application data itself. </p>
<p>When displaying results to your users, you are heavily constrained in 
    how much data you can present at once. This means some form of paging 
    is often required if you have more than a screenful of results. It also 
    means that you must sacrifice the number of results shown per page if 
    you want to show more than a trivial amount of information in that 
    page. </p>
<p>Often it can be difficult to grade the quality of results returned to 
    the user -- although index scores are limited and normalized, you also 
    need to be able to display scores in a meaningful way to the user. This 
    means both simplifying and explaining the scores. A numeric score without 
    qualification is meaningless: is 5 out of 5, or 10, or 100? </p>
<p>The simplest way to grade scores is to work out the maximum score and 
    divide it into grades. For example, if you have a maximum of 5 points 
    per word matched, then you could divide the score by the number of words 
    searched for and grade it by rounding up to 1, 2, 3, 4 or 5 out of 5. 
    This information can then be presented using text and/or graphics, the 
    latter allowing for color-coding of results. A small colored bar for 
    each result allows you to show both the score and the grade in the minimum 
    of space. The bar can easily be replaced by stars or other symbols, 
    to fit in with the look and feel of an application. </p>
<p>By normalizing the scores as you index the objects (see above), you make 
    the results much easier to use. If you know that the maximum score per 
    search term is 1, then scores can be easily graded with a simple piece 
    of code into something users can understand. </p>

<pre><code>my $wc = scalar @searchwords;
foreach my $result (@$results) {
  $result->{grade} = get_grade($result->{score}/$wc);
}

sub get_grade {
  my $score = shift;
  return 'poor' if ($score &lt; 0.35);
  return 'good' if ($score &lt; 0.65);
  return 'very good' if ($score &lt; 0.85);
  return 'excellent';
}</code></pre>

<p>There are many ways of getting extra value from your results. You can 
    group results by object type, either by adding logic to the query or 
    by using an <code>Iterator</code> class that differentiates between object types. </p>
<p>By checking the status or type of each item in the result list, you can 
    present it in a different way or provide additional information. Items 
    in a catalogue that have been recalled or replaced can include a link 
    to the replacement or recall notice -- again, this is one of the benefits 
    of keeping such information in a metadata table. </p>
<p>You can check for spelling mistakes and alternative words using CPAN modules 
    such as <a href="http://search.cpan.org/author/DPAVLIN/Lingua-Spelling-Alternative-0.01/Alternative.pm"><code>Lingua::Spelling::Alternative</code></a>. 
    You can also provide related links for items or keyword-based advertising. 
</p>
<a name="tuning"></a>
<h3>Tuning and Customizing</h3>
<p>Once you have your search engine working and integrated with your application, 
    you can work on tuning it for more accurate scoring and more intuitive 
    results. You can also work on customizing it further to meet the needs 
    of your application. </p>
<p>For instance, if part of your application was a catalogue, then you could 
    add a status field to your locations. This would allow your to mark 
    old items as replaced and provide an alternative result in its place 
    in search results, with a note saying which item it replaced. You could 
    also provide similar features for items that have been recalled or books 
    no longer in print. </p>
<p>You can further tune results using two powerful modules on CPAN -- <code>Lingua::Stem::En</code> 
    (replace <code>En</code> with whichever language suits your needs) and <code>Lingua::EN::Tagger</code>. 
    For the sake of simplicity, I haven't used these in this article, but they 
    are relatively simple to integrate into searching and indexing. </p>
<p><code>Linga::Stem::En</code> provides Porter Stemming for <code>perl</code>. Porter's 
    algorithm is a well-known way of cutting down a word to its stem -- removing 
    grammatical information from words to find their root. For instance, 
    you'll want "training" and "trains" both to match the same results as 
    "train," so Porter Stemming can be used to reduce both words to "train." 
    As well as increasing the accuracy of your search, this technique also 
    drastically reduces the number of words in the index. If you are getting 
    a high number of word misses on your index, this can improve results 
    greatly -- if you are already getting plenty of word hits on your index, 
    then this can normalize your results more by losing grammatical information 
    in the words that may distinguish results better. A simple rule of thumb 
    is that if you get a low number of results for each word, then you need 
    it; if you have a high number of results for each word, you don't. To 
    add stemming to your index with a module like <code>Lingua::Stem::En</code>, 
    you would use the module's function to extract words rather than (or 
    as well as) your own, when splitting search phrases and text to be indexed 
    into keywords.</p>
<p>Tagger is a clever module that can add something approaching phrase matching 
    without having to muck about (too much) with your working index algorithm. 
    Tagger will pull out groups of words from a string of text (optionally 
    stemming words) by looking for nouns and "Parts Of Speech." By passing 
    text to be indexed and text to be searched for through the tagger, you 
    can extract groups of words. For example, instead of just indexing "Justice 
    Department" as two separate words, a good tagger will return it as a 
    single phrase. </p>
<p>Once you're used the tagger to segment your text, you can treat the individual 
    words and the phrases alike for both indexing and searching purposes. 
    This means you can avoid the slow and unpleasant task of doing phrase 
    matching properly -- because the tagger would also apply to the search 
    query, a phrase like "Justice Department" in a search term would be 
    automatically kept together. The phrase-matching process would be transparent 
    to the user, meaning there's no need for additional syntax such as putting 
    quotes around phrases.</p>
<p>Both <code>Tagger</code> and <code>Lingua::Stem</code> can be integrated 
    into the <code>get_words</code> function above, transparent to both 
    index and search logic.</p>
<p>When you control the indexing, it is possible to recognize dates and 
    convert them to an internal format for full-text searching, applying 
    similar logic to stemming -- as long as your internal date format is 
    consistent, it doesn't matter how dates are entered by the user or stored 
    in the data. They can be converted to the internal date format when 
    indexed or queried. This is useful if date information is particularly 
    important to your objects. </p>
<h3>References and Further Reading</h3>
<ul>
    <li>"<a href="/pub/a/2001/04/10/engine.html">Designing 
        a Search Engine</a>" by Pete Sergeant. Useful information on coping 
        without an RDBMS and implementing phrase-matching/Boolean searches. 
        (perl.com)</li>
    <li>"<a href="http://www.ddj.com/articles/2000/0012/">The Windows 2000 
        Content Index</a>" by Bartosz Milewski. The principles and design 
        of the Windows 2000 content index. (Dr. Dobb's Journal -- registration 
        required.)</li>
    <li>"<a href="http://www.ddj.com/articles/2001/0103/">Web Site Searching 
        and Indexing in Perl</a>" by Neil Gunton. Indexing websites using 
        MySQL and DBIx::FullTextSearch. (Dr. Dobb's Journal -- registration 
        required.)</li>
    <li>"<a href="http://www.ddj.com/articles/1999/9901/" name="tk">Full-text 
        indexing in perl</a>" by Tim Kientzle. A concise introduction to 
        full-text indexing in <code>perl</code> -- an essential read. (Dr. Dobb's Journal 
        -- registration required.)</li>
    <li>"<a href="/pub/a/2003/02/19/engine.html" name="mc">Building 
        a Vector Space Search Engine in Perl</a>" by Maciej Ceglowski. Covers 
        the Vector-based alternative to Reverse Index searching, as well 
        as pointers on splitting text into words, etc. (perl.com)</li>
    <li>"<a href="/pub/a/2003/07/15/nocode.html" name="kh">How 
        to Avoid Writing Code</a>" by Kake Pugh. Quick introduction to practical 
        use of Class::DBI including how to add a full-text search to an object. 
        (perl.com)</li>
</ul>

        </div>



    </div>
    <div class="asset-footer"></div>
</div>


                            
                            <div id="entry-1196" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2003/09/p6pdigest/20030921.html" rel="bookmark">This week on Perl 6, week ending 2003-09-21</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author">Piers Cawley</span> on <abbr class="published" title="2003-09-21T00:00:00-08:00">September 21, 2003 12:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            
<!-- sidebar begins -->
<!-- don't move sidebars -->
<!-- sidebar ends -->

<p>Deadlines, I love the sound they make as they fly past.</p>
<p>Those of you who receive this summary via mail may have noticed that
this summary is a little late, with any luck it will make up for its
tardiness by being inaccurate and badly written as well.</p>
<p>I'm going to reinstitute the tradition of starting with the internals
list this week, so without further ado:</p>

<h4><a name="pondering argument passing">Pondering argument passing</a></h4>
<p>Steve Fink pondered passing parameters properly, with a prototyped
Perl 6 example. Perl 5 certainly, and Perl 6 possibly, allow you to
ignore any function prototype by calling the function like
<code>&amp;f(1,2)</code>. Steve had concerns about what to do in the presence of
'splatted' argument lists. (Consider</p>
<pre><code>    sub foo(@a, $b) {...}

    @generated_arglist = ([1,2,3], 2);</code></pre>
<p>Calling <code>foo(@generated_arglist)</code> will throw an error, because the
function is expecting an array followed by a scalar. However, you can
get around that by using the <code>*</code> (splat) operator, which tells Perl
to wait until runtime and then treat @generated_arglist as if it were
a list of arguments to the function, and check its contents against
foo's parameter list. In Perl 5, if you had a prototyped function
<code>sub foo(@$) {...}</code> you would work around the problem by calling it
as <code>&amp;foo(@generated_arglist)</code>, but I have digressed a long way
already.)</p>
<p>I'm not entirely sure I got what this thread was about. I've just had
a chat with Dan about it on IRC, and I think I'm a little wiser, but
the thread that arose from Steve's post gave me the impression of
people talking past each other a little.</p>
<p><a href="http://groups.google.com/groups?threadm=20030915020357.GA12796%40foxglove">http://groups.google.com/groups</a></p>

<h4><a name="feature freeze for 0.0.11">Feature Freeze for 0.0.11</a></h4>
<p>Steve Fink announced that Parrot was feature frozen in the wee small
hours of Monday morning (at least it was Monday morning if you live
in GMT; it was still Sunday if you're in Steve's timezone). Everyone
set about tidying things up, nailing bugs and generally getting
Parrot's house in order for a public release.</p>
<p><a href="http://groups.google.com/groups?threadm=20030915034714.GA13768%40foxglove">http://groups.google.com/groups</a></p>

<h4><a name="some parrot people are disgustingly young">Some Parrot people are disgustingly young</a></h4>
<p>In a move calculated to annoy your summarizer, Dan Sugalski pointed
out that Piers is now twice the age of Brent Dax. I thought it was
bad enough back when I was working with Leon Brocard, who is also
disgustingly young, but at least he was old enough to drink beer and
vote. (It's very important that you do the former before the latter
apparently)</p>

<h4><a name="parrot musical chairs">Parrot musical chairs</a></h4>
<p>Some time after the next Parrot release everything's going to get
moved around in the parrot directory tree so things make a little more
sense. Dan laid out his vision. Leo liked it. Looks like it'll be
happening.</p>
<p><a href="http://groups.google.com/groups?threadm=Pine.LNX.4.44.0309150956370.3341-100000%40redcap.sidhe.org">http://groups.google.com/groups</a></p>

<h4><a name="sorting out dependencies">Sorting out dependencies</a></h4>
<p>Andy Dougherty has been shaking the parrot tree with different
versions of Perl and found some incompatibilities between the jako
and perl6 languages and Perl 5.005. A few patches and skipped tests
solved that.</p>
<p><a href="http://groups.google.com/groups?threadm=Pine.SOL.4.53.0309151151070.27327%40maxwell.phys.lafayette.edu">http://groups.google.com/groups</a></p>

<h4><a name="attaching debuggers">Attaching Debuggers</a></h4>
<p>Nicholas Clark passed on the concerns of a nameless interlocutor who
had expressed a desire for a Perl debugger which could attach itself
to a troubled running process. This is, after all, something that gdb
can already do for C programs. Dan punted on details, but thinks it
should be possible to implement. It's definitely post 0.0.11
though. Michal Wallace pointed out that Python is very 'hooky' and
supports this.</p>
<p><a href="http://groups.google.com/groups?threadm=20030919202225.Q4286%40plum.flirble.org">http://groups.google.com/groups</a></p>

<h4><a name="various fixes">Various fixes</a></h4>
<p>Because most of the week was spent under a feature freeze, the vast
majority of this week's threads have been the kind of short lived
``Patch! Applied!'' bugfix threads. Suffice to say, lots of bugs and
niggles got stamped on by the usual heroes plus a few more heroes for
good measure.</p>

<h4><a name="parrot 0.0.11 doubloon released">Parrot 0.0.11 ``Doubloon'' Released</a></h4>
<p>Parrot 0.0.11 got released on Saturday, narrowly missing ``International Talk
Like a Pirate Day''. It was almost immediately superceded by version
0.0.11.1 which fixed a slight oversight and introduced a new
bug. Breaking my 'midnight GMT cutoff' rule, the latest version,
released is actually 0.0.11.2, which deals with the fact that Parrot
isn't set up to handle 4 part version numbers.</p>
<p><a href="http://groups.google.com/groups?threadm=20030920075908.GO19481%40foxglove">http://groups.google.com/groups</a></p>
<p><a href="http://www.cpan.org/authors/id/S/SF/SFINK/parrot-0.0.11.2.tar.gz">http://www.cpan.org/authors/id/S/SF/SFINK/parrot-0.0.11.2.tar.gz</a>
-- The ``We really can't handle these version numbers'' release</p>

<h3><a name="meanwhile, in perl6language">Meanwhile, in perl6-language</a></h3>

<h4><a name="disposable optimization">Disposable optimization</a></h4>
<p>The increasingly poorly named ``Next Apocalypse'' thread went off into
discussing the possibilities of disposable optimizations that could
get thrown out when invariants that they depend on no longer
hold. This rapidly developed into serious blue sky stuff that I
can't help but think is a little premature. Fascinating certainly,
but I would like a working language before we got off making it do
all sorts of clever optimization stuff.</p>
<p><a href="http://groups.google.com/groups?threadm=Pine.LNX.4.44.0309150849030.3341-100000%40redcap.sidhe.org">http://groups.google.com/groups</a></p>

<h3><a name="acknowledgements, announcements, apologies">Acknowledgements, Announcements, Apologies</a></h3>
<p>Sorry it's late.</p>
<p>I promised there will be new content at
<a href="http://www.bofh.org.uk:8080/">http://www.bofh.org.uk:8080/</a> last week and, well, I put some photos
up. Maybe this week I'll actually write something.</p>
<p>As ever, if you've appreciated this summary, please consider one or
more of the following options:</p>
<ul>
<li>
Send money to the Perl Foundation at
<a href="http://donate.perl-foundation.org/">http://donate.perl-foundation.org/</a> and help support the ongoing
development of Perl.</li>


<li>
Get involved in the Perl 6 process. The mailing lists are open  to
all. <a href="http://dev.perl.org/perl6/">http://dev.perl.org/perl6/</a> and <a href="http://www.parrotcode.org/">http://www.parrotcode.org/</a>
are good starting points with links to the appropriate mailing lists.</li>


<li>
Send feedback, flames, money, requests for consultancy, photographic
and writing commissions, or a nice cup of tea to
<em><a href="mailto:p6summarizer@bofh.org.uk">p6summarizer@bofh.org.uk</a></em></li>

</ul>
        </div>



    </div>
    <div class="asset-footer"></div>
</div>


                            
                            <div id="entry-1190" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2003/09/17/perlcookbook.html" rel="bookmark">Cooking with Perl, Part 3</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author">perl.com</span> on <abbr class="published" title="2003-09-17T00:00:00-08:00">September 17, 2003 12:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            
<!-- sidebar begins -->
<!-- don't move sidebars -->
<!-- sidebar ends -->

<p><i>Editor's note: In this third and final batch of recipes excerpted from <a href="http://www.oreilly.com/catalog/perlckbk2/index.html?CMP=IL7015">Perl Cookbook</a>, you'll find solutions and code examples for extracting HTML table data, templating with HTML::Mason, and making simple changes to elements or text. </i></p>

<h3>Sample Recipe: Extracting Table Data</h3>

<h4>Problem</h4>


<p>You have data in an HTML table, and you would like to turn that 
into a Perl data structure. For example, you want to monitor changes to an 
author's CPAN module list.</p>

<h4>Solution</h4>

<p>Use the HTML::TableContentParser module from CPAN:</p>

<pre><code>use HTML::TableContentParser;
&nbsp;
$tcp = HTML::TableContentParser-&gt;new;
$tables = $tcp-&gt;parse($HTML);
&nbsp;
foreach $table (@$tables) {
  @headers = map { $_-&gt;{data} } @{ $table-&gt;{headers} };
  # attributes of table tag available as keys in hash
  $table_width = $table-&gt;{width};
&nbsp;
  foreach $row (@{ $tables-&gt;{rows} }) {
    # attributes of tr tag available as keys in hash
    foreach $col (@{ $row-&gt;{cols} }) {
      # attributes of td tag available as keys in hash
      $data = $col-&gt;{data};
    }
  }
}</code>
</pre>

<h4>Discussion</h4>

<csperl file="grab" domain="on" record="b/941" template="b/article_sidebar.view">

<p>The HTML::TableContentParser module converts all tables in the 
HTML document into a Perl data structure. As with HTML tables, there are three 
layers of nesting in the data structure: the table, the row, and the data in 
that row.</p>

<p>Each table, row, and data tag is represented as a hash reference. 
The hash keys correspond to attributes of the tag that defined that table, row, 
or cell. In addition, the value for a special key gives the contents of the 
table, row, or cell. In a table, the value for the <code>rows</code> key is a reference to an array of rows. In a row, the 
<code>cols</code> key points to an array of cells. In a cell, the 
<code>data</code> key holds the HTML contents of the data tag.</p>

<p>For example, take the following table:</p>

<pre><code>&lt;table width="100%" bgcolor="#ffffff"&gt;
  &lt;tr&gt;
    &lt;td&gt;Larry &amp;amp; Gloria&lt;/td&gt;
    &lt;td&gt;Mountain View&lt;/td&gt;
    &lt;td&gt;California&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Tom&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;Boulder&lt;/td&gt;
    &lt;td&gt;Colorado&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Nathan &amp;amp; Jenine&lt;/td&gt;
    &lt;td&gt;Fort Collins&lt;/td&gt;
    &lt;td&gt;Colorado&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;</code>
</pre>

<p>The <code>parse</code> method returns this data 
structure:</p>

<pre><code>[
  {
    'width' =&gt; '100%',
    'bgcolor' =&gt; '#ffffff',
    'rows' =&gt; [
               {
                'cells' =&gt; [
                            { 'data' =&gt; 'Larry &amp;amp; Gloria' },
                            { 'data' =&gt; 'Mountain View' },
                            { 'data' =&gt; 'California' },
                           ],
                'data' =&gt; "\n      "
               },
               {
                'cells' =&gt; [
                            { 'data' =&gt; '&lt;b&gt;Tom&lt;/b&gt;' },
                            { 'data' =&gt; 'Boulder' },
                            { 'data' =&gt; 'Colorado' },
                           ],
                'data' =&gt; "\n      "
               },
               {
                'cells' =&gt; [
                            { 'data' =&gt; 'Nathan &amp;amp; Jenine' },
                            { 'data' =&gt; 'Fort Collins' },
                            { 'data' =&gt; 'Colorado' },
                           ],
                'data' =&gt; "\n      "
               }
              ]
  }
]</code>
</pre>

<p>The data tags still contain tags and entities. If you don't want 
the tags and entities, remove them by hand using techniques from "Extracting or 
Removing HTML Tags."</p>

<!-- sidebar begins -->
<table width="220" border="0" cellspacing="8" cellpadding="4" align="right">
<tr>
<td width="220" valign="top" bgcolor="#efefef">
<div class="secondary">
<h4>Previous Articles in this Series</h4>
<p class="secondary">
&bull; <a href="/pub/a/2003/08/21/perlcookbook.html">Cooking with Perl</a><br />
&bull; <a href="/pub/a/2003/09/03/perlcookbook.html">Cooking with Perl, Part 2</a>
</p>
</div>
</td></tr></table>
<!-- sidebar ends -->

<p><a href="http://admin.oreillynet.com/catalog/perlckbk2/excerpts/ch20.html#77026">Example 
20-11</a> fetches a particular CPAN author's page and displays in plain text the 
modules they own. You could use this as part of a system that notifies you when 
your favorite CPAN authors do something new.</p>

<p><b>Example 20-11:</a></b> <b>Dump modules for a particular CPAN author </b></p>

<pre><code>  #!/usr/bin/perl -w
  # dump-cpan-modules-for-author - display modules a CPAN author owns
  use LWP::Simple;
  use URI;
  use HTML::TableContentParser;
  use HTML::Entities;
  use strict;
  our $URL = shift || 'http://search.cpan.org/author/TOMC/';
  my $tables = get_tables($URL);
  my $modules = $tables-&gt;[4];    # 5th table holds module data
  foreach my $r (@{ $modules-&gt;{rows} }) {
    my ($module_name, $module_link, $status, $description) = 
        parse_module_row($r, $URL);
    print "$module_name &lt;$module_link&gt;\n\t$status\n\t$description\n\n";
  } 
  sub get_tables {
    my $URL = shift;
    my $page = get($URL);
    my $tcp = new HTML::TableContentParser;
    return $tcp-&gt;parse($page);
  }
  sub parse_module_row {
    my ($row, $URL) = @_;
    my ($module_html, $module_link, $module_name, $status, $description);
    # extract cells
    $module_html = $row-&gt;{cells}[0]{data};  # link and name in HTML
    $status      = $row-&gt;{cells}[1]{data};  # status string and link
    $description = $row-&gt;{cells}[2]{data};  # description only
    $status =~ s{&lt;.*?&gt;}{  }g; # naive link removal, works on this simple HTML
    # separate module link and name from html
    ($module_link, $module_name) = $module_html =~ m{href="(.*?)".*?&gt;(.*)&lt;}i;
    $module_link = URI-&gt;new_abs($module_link, $URL); # resolve relative links
    # clean up entities and tags
    decode_entities($module_name);
    decode_entities($description);
    return ($module_name, $module_link, $status, $description);
  }</code>
</pre>

<h4>See Also</h4>

<p>The documentation for the CPAN module HTML::TableContentParser; <a href="http://search.cpan.org/">http://search.cpan.org/</a></p>















<h3>Sample Recipe: Templating with HTML::Mason</h3>

<h3>Problem</h3>

<p>You want to separate presentation (HTML formatting) from logic 
(Perl code) in your program. Your web site has a lot of components with only 
slight variations between them. You'd like to abstract out common elements and 
build your pages from templates without having a lot of "if I'm in this page, 
then print this; else if I'm in some other page . . . " conditional statements 
in a single master template.</p>

<h4>Solution</h4>

<p>Use HTML::Mason components and inheritance.</p>

<h4>Discussion</h4>

<p>HTML::Mason (also simply called Mason) offers the power of Perl in 
templates. The basic unit of a web site built with Mason is the component--a 
file that produces output. The file can be HTML, Perl, or a mixture of both. 
Components can take arguments and execute arbitrary Perl code. Mason has many 
features, documented at <a href="http://masonhq.com/">http://masonhq.com/</a> 
and in <cite>Embedding Perl in HTML with Mason</cite> by Dave 
Rolsky and Ken Williams (O'Reilly; online at <a href="http://masonbook.com/">http://masonbook.com/</a>).</p>

<p>Mason works equally well with CGI, mod_perl, and non-web programs. 
For the purposes of this recipe, however, we look at how to use it with 
mod_perl. The rest of this recipe contains a few demonstrations to give you a 
feel for what you can do with Mason and how your site will be constructed. There 
are more tricks, traps, and techniques for everything we discuss, though, so be 
sure to visit the web site and read the book for the full story.</p>

<h5>Configuration</h5>

<p>Install the HTML-Mason distribution from CPAN and add the 
following to your <em>httpd.conf</em>:</p>

<pre><code>PerlModule HTML::Mason::ApacheHandler
&lt;Location /mason&gt;
  SetHandler perl-script
  PerlHandler HTML::Mason::ApacheHandler
  DefaultType text/html
&lt;/Location&gt;</code>
</pre>

<p>This tells mod_perl that every URL that starts with <code>/mason</code> is handled by Mason. So if you request <code>/mason/hello.html</code>, the file <em>mason/hello.html</em> in your document directory will be compiled 
and executed as a Mason component. The DefaultType directive lets you omit the 
<em>.html</em> from component names.</p>
<p>Next create a directory for Mason to cache the compiled components 
in. Mason does this to speed up execution.</p>

<pre><code>cd $SERVER_ROOT
mkdir mason</code>
</pre>

<p>Then make a <em>mason</em> directory for components 
to live in:</p><pre><code>cd $DOCUMENT_ROOT
mkdir mason</code>
</pre>

<p>Now you're ready for "Hello, World". Put this in <em>mason/hello</em>:</p>

<pre><code>Hello, &lt;% ("World", "Puny Human")[rand 2] %&gt;</code>
</pre>

<p>Restart Apache and load up the <i>mason/hello</i> page. If you 
reload it, you should see "Hello, World" and "Hello, Puny Human" randomly. If 
not, look at the Mason FAQ (<a href="http://www.masonhq.com/docs/faq/">http://www.masonhq.com/docs/faq/</a>), 
which answers most commonly encountered problems.</p>

<h5>Basic Mason syntax</h5>

<p>There are four types of new markup in Mason components: 
substitutions, Perl code, component calls, and block tags. You saw a 
substitution in the "Hello World" example: <code>&lt;% ... 
%&gt;</code> evaluates the contents as Perl code and inserts the result into the 
surrounding text.</p>

<p>Perl code is marked with a <code>%</code> at the 
start of the line:</p>

<pre><code>% $now = localtime;   # embedded Perl
This page was generated on &lt;% $now %&gt;.</code>
</pre>

<p>Because substitutions can be almost any Perl code you like, this 
could have been written more simply as:</p>

<pre><code>This page was generated on &lt;% scalar localtime %&gt;.</code>
</pre>

<p>If either of these variations were saved in <em>footer.mas</em>, you could include it simply by saying:</p>

<pre><code>&lt;&amp; footer.mas &amp;&gt;</code>
</pre>

<p>This is an example of a component call--Mason runs the component 
and inserts its result into the document that made the call.</p>

<p>Block tags define different regions of your component. <code>&lt;%perl&gt; ... &lt;/%perl&gt;</code> identifies Perl code. 
While <code>%</code> at the start of a line indicates that just 
that line is Perl code, you can have any number of lines in a <code>&lt;%perl&gt;</code> block.</p>

<p>A <code>&lt;%init&gt; ... &lt;/%init&gt;</code> 
block is like an INIT block in Perl. The code in the block is executed before 
the main body of code. It lets you store definitions, initialization, database 
connections, etc. at the bottom of your component, where they're out of the way 
of the main logic.</p>

<p>The <code>&lt;%args&gt; ... &lt;/%args&gt;</code> 
block lets you define arguments to your component, optionally with default 
values. For example, here's <em>greet.mas</em>:</p>

<pre><code>&lt;%args&gt;
   $name =&gt; "Larry"
   $town =&gt; "Mountain View"
&lt;/%args&gt;
Hello, &lt;% $name %&gt;.  How's life in &lt;% $town %&gt;?</code>
</pre>

<p>Calling it with:</p>

<pre><code>&lt;&amp; greet.mas &amp;&gt;</code>
</pre>

<p>emits:</p>

<pre><code>Hello, Larry.  How's life in Mountain View?</code>
</pre>

<p>You can provide options on the component call:</p>

<pre><code>&lt;&amp; greet.mas, name =&gt; "Nat", town =&gt; "Fort Collins" &amp;&gt;</code>
</pre>

<p>That emits:</p>

<pre><code>Hello, Nat.  How's life in Fort Collins?</code>
</pre>

<p>Because there are default values, you can supply only some of the 
arguments:</p>

<pre><code>&lt;&amp; greet.mas, name =&gt; "Bob" &amp;&gt;</code>
</pre>

<p>That emits:</p>

<pre><code>Hello, Bob.  How's life in Mountain View?</code>
</pre>

<p>Arguments are also how Mason components access form parameters. 
Take this form:</p>

<pre><code>&lt;form action="compliment"&gt;
  How old are you?  &lt;input type="text" name="age"&gt; &lt;br /&gt;
  &lt;input type="submit"&gt;
&lt;/form&gt;</code>
</pre>

<p>Here's a <em>compliment</em> component that could 
take that parameter:</p>

<pre><code>&lt;%args&gt;
  $age
&lt;/%args&gt;
Hi.  Are you really &lt;% $age %&gt;?  You don't look it!</code>
</pre>

<h5>Objects</h5>

<p>All Mason components have access to a <code>$m</code> variable, which contains an HTML::Mason::Request object. 
Methods on this object give access to Mason features. For example, you can 
redirect with:</p>

<pre><code>$m-&gt;redirect($URL);</code>
</pre>

<p>The <code>$r</code> variable is the mod_perl request 
object, so you have access to the information and functions of Apache from your 
Mason handlers. For example, you can discover the client's IP address with:</p>

<pre><code>$ip = $r-&gt;connection-&gt;remote_ip;</code>
</pre>

<h5>Autohandlers</h5>

<p>When a page is requested through Mason, Mason can do more than 
simply execute the code in that page. Mason inspects each directory between the 
component root and the requested page, looking for components called <em>autohandler</em>. This forms a <em>wrapping 
chain</em>, with the top-level autohandler at the start of the chain and the 
requested page at the end. Mason then executes the code at the start of the 
chain. Each autohandler can say "insert the output of the next component in the 
chain here."</p>

<p>Imagine a newspaper site. Some parts don't change, regardless of 
which article you're looking at: the banner at the top, the random selection of 
ads, the list of sections down the lefthand side. However, the actual article 
text varies from article to article. Implement this in Mason with a directory 
structure like this:</p>

<pre><code>/sports
/sports/autohandler
/sports/story1
/sports/story2
/sports/story3</code>
</pre>

<p>The individual story files contain only the text of each story. 
The autohandler builds the page (the banner, the ads, the navigation bar), and 
when it wants to insert the content of the story, it says:</p>

<pre><code>% $m-&gt;call_next;</code>
</pre>

<p>This tells Mason to call the next component in the chain (the 
story) and insert its output here.</p>

<p>The technique of having a chain of components is called <em>inheritance</em>, and autohandlers aren't the only way to do it. 
In a component, you can designate a parent with:</p>

<pre><code>&lt;%flags&gt;
  inherit = 'parent.mas'
&lt;/%flags&gt;</code>
</pre>

<p>This lets you have different types of content in the one 
directory, and each contained component gets to identify its surrounding page 
(its parent).</p>

<h5>Dhandlers</h5>

<p>Sometimes it's nice to provide the illusion of a directory full of 
pages, when in reality they are all dynamically generated. For example, stories 
kept in a database could be accessed through URLs like:</p

><pre><code>/sports/1
/sports/2
/sports/3</code>
</pre>

<p>The Mason way to dynamically generate the pages at these URLs is 
with a component called <em>dhandler</em> in the <em>sports</em> directory. The <em>dhandler</em> 
component accesses the name of the missing page (<em>123</em> in 
this case) by calling:</p><pre><code>$m-&gt;dhandler_arg</code>
</pre>

<p>You could then use this to retrieve the story from the database 
and insert it into a page template.</p>

<h4>See Also</h4>

<p>Recipe 15.11 in <cite>mod_perl Developer's 
Cookbook</cite>; <cite>Embedding Perl in HTML with Mason</cite>; 
<a href="http://www.masonhq.com/">http://www.masonhq.com/</a> and <a href="http://www.masonbook.com/">http://www.masonbook.com/</a></p>















<h3>Sample Recipe: Making Simple Changes to Elements or Text</h3>

<h3>Problem</h3>

<p>You want to filter some XML. For example, you want to make 
substitutions in the body of a document, or add a price to every book described 
in an XML document, or you want to change <code>&lt;book 
id="1"&gt;</code> to <code>&lt;book&gt; 
&lt;id&gt;1&lt;/id&gt;</code>.</p>

<h4>Solution</h4>

<p>Use the XML::SAX::Machines module from CPAN:</p>

<pre><code>#!/usr/bin/perl -w
&nbsp;
use MySAXFilter1;
use MySAXFilter2;
use XML::SAX::ParserFactory;
use XML::SAX::Machines qw(Pipeline);
&nbsp;
my $machine = Pipeline(MySAXFilter1 =&gt; MySAXFilter2); # or more
$machine-&gt;parse_uri($FILENAME);</code>
</pre>

<p>Write a handler, inheriting from XML::SAX::Base as in "Parsing XML 
into SAX Events," then whenever you need a SAX event, call the appropriate 
handler in your superclass. For example:</p>

<pre><code>$self-&gt;SUPER::start_element($tag_struct);</code>
</pre>

<h4>Discussion</h4>

<p>A SAX filter accepts SAX events and triggers new ones. The 
XML::SAX::Base module detects whether your handler object is called as a filter. 
If so, the XML::SAX::Base methods pass the SAX events onto the next filter in 
the chain. If your handler object is not called as a filter, then the 
XML::SAX::Base methods consume events but do not emit them. This makes it almost 
as simple to write events as it is to consume them.</p>

<p>The XML::SAX::Machines module chains the filters for you. Import 
its <code>Pipeline</code> function, then say:</p>

<pre><code>my $machine = Pipeline(Filter1 =&gt; Filter2 =&gt; Filter3 =&gt; Filter4);
$machine-&gt;parse_uri($FILENAME);</code>
</pre>

<p>SAX events triggered by parsing the XML file go to Filter1, which 
sends possibly different events to Filter2, which in turn sends events to 
Filter3, and so on to Filter4. The last filter should print or otherwise do 
something with the incoming SAX events. If you pass a reference to a typeglob, 
XML::SAX::Machines writes the XML to the filehandle in that typeglob.</p>

<p><a href="http://admin.oreillynet.com/catalog/perlckbk2/excerpts/ch22.html#45625">Example 
22-5</a> shows a filter that turns the <code>id</code> attribute 
in <code>book</code> elements from the XML document in Example 
22-1 into a new <code>id</code> element. For example, <code>&lt;book id="1"&gt;</code> becomes <code>&lt;book&gt;&lt;id&gt;1&lt;/id&gt;</code>.</p>

<p><b><a name="45625">Example 22-5:</a></b> <b>filters-rewriteids </b></p>

<pre><code>package RewriteIDs;
# RewriteIDs.pm -- turns "id" attributes into elements
&nbsp;
use base qw(XML::SAX::Base);
&nbsp;
my $ID_ATTRIB = "{  }id";   # the attribute hash entry we're interested in
&nbsp;
sub start_element {
    my ($self, $data) = @_;
&nbsp;
    if ($data-&gt;{Name} eq 'book') {
        my $id = $data-&gt;{Attributes}{$ID_ATTRIB}{Value};
        delete $data-&gt;{Attributes}{$ID_ATTRIB};
        $self-&gt;SUPER::start_element($data);
&nbsp;
        # make new element parameter data structure for the &lt;id&gt; tag
        my $id_node = {  };
        %$id_node = %$self;
        $id_node-&gt;{Name} = 'id';     # more complex if namespaces involved
        $id_node-&gt;{Attributes} = {  };
&nbsp;
        # build the &lt;id&gt;$id&lt;/id&gt;
        $self-&gt;SUPER::start_element($id_node);
        $self-&gt;SUPER::characters({ Data =&gt; $id });
        $self-&gt;SUPER::end_element($id_node);
    } else {
        $self-&gt;SUPER::start_element($data);
    }
}
&nbsp;
1;</code>
</pre>

<p><a href="http://admin.oreillynet.com/catalog/perlckbk2/excerpts/ch22.html#15387">Example 
22-6</a> is the stub that uses XML::SAX::Machines to create the pipeline for 
processing <em>books.xml</em> and print the altered XML.</p>

<p><b><a name="15387">Example 22-6:</a></b> <b>filters-rewriteprog </b></p>

<pre><code>#!/usr/bin/perl -w
# rewrite-ids -- call RewriteIDs SAX filter to turn id attrs into elements
&nbsp;
use RewriteIDs;
use XML::SAX::Machines qw(:all);
&nbsp;
my $machine = Pipeline(RewriteIDs =&gt; *STDOUT);
$machine-&gt;parse_uri("books.xml");</code>
</pre>

<p>The output of <a href="http://admin.oreillynet.com/catalog/perlckbk2/excerpts/ch22.html#15387">Example 
22-6</a> is as follows (truncated for brevity):</p>

<pre><code>&lt;book&gt;&lt;id&gt;1&lt;/id&gt;
    &lt;title&gt;Programming Perl&lt;/title&gt;
 ...
&lt;book&gt;&lt;id&gt;2&lt;/id&gt;
    &lt;title&gt;Perl &amp;amp; LWP&lt;/title&gt;
 ...</code>
</pre>

<p>To save the XML to the file <em>new-books.xml</em>, 
use the XML::SAX::Writer module:</p>

<pre><code>#!/usr/bin/perl -w
&nbsp;
use RewriteIDs;
use XML::SAX::Machines qw(:all);
use XML::SAX::Writer;
&nbsp;
my $writer = XML::SAX::Writer-&gt;new(Output =&gt; "new-books.xml");
my $machine = Pipeline(RewriteIDs =&gt; $writer);
$machine-&gt;parse_uri("books.xml");</code>
</pre>

<p>You can also pass a scalar reference as the <code>Output</code> parameter to have the XML appended to the scalar; as 
an array reference to have the XML appended to the array, one array element per 
SAX event; or as a filehandle to have the XML printed to that filehandle.</p>

<h4>See Also</h4>

<p>The documentation for the modules XML::SAX::Machines and 
XML::SAX::Writer</p>
        </div>



    </div>
    <div class="asset-footer"></div>
</div>


                            
                            <div id="entry-1188" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2003/09/10/bioinformatics.html" rel="bookmark">A Chromosome at a Time with Perl, Part 1</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author">James D. Tisdall</span> on <abbr class="published" title="2003-09-11T00:00:00-08:00">September 11, 2003 12:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            
<!-- sidebar begins -->
<!-- don't move sidebars -->
<!-- sidebar ends -->
<p><i>James D. Tisdall is the author of the soon-to-be-released </i><a href="http://www.oreilly.com/catalog/mperlbio/index.html?CMP=IL7015">Mastering 
    Perl for Bioinformatics</a><i>.</i></p>

<p> For some time now, the use of Perl in biology has been standard practice. 
    Perl remains the most popular language among biologists for a multitude 
    of programming tasks. The same reasons why Perl has been a success story 
    among system administrators, as well as one of the big success stories 
    in the early days of the Web and CGI programming, have also made it 
    the lingua franca of programming in biology, known as <i>bioinformatics</i>. 
</p>
<p> One of the reasons why Perl has been equally well suited to dealing 
    with things like DNA and protein sequence data is that it's so easy 
    to declare and use a string. You just use it, without worrying about 
    allocating memory, or managing memory as the string shrinks or grows. 
    DNA and proteins and other standard biological data are almost always 
    represented in Perl as strings, so this facility with strings translates 
    directly into a facility with DNA and proteins. </p>
<p> For example, say you have a subroutine <code>get_chromosome</code> that returns 
    a string of all the DNA in a human chromosome. In humans, this might 
    be a string about 100Mb in length. This snippet of code calls <code>get_chromosome</code> 
    to initialize a scalar variable, <code>$chromosome1</code>, with the string 
    of DNA sequence data that summarizes human chromosome 1: </p>

<pre><code>$chromosome1 = get_chromosome( 1 );</code></pre>

<p> This programming is as easy as cake. I mean, simple as pie. Well, you 
    know what I mean. </p>
	
	<csperl file="grab" domain="on" record="b/889" template="b/article_sidebar.view">
	
<p> But beneath this wonderful ease of programming lurks a problem. It's 
    a problem that can make your wonderful, intuitive code for tossing around 
    chromosomes and genomes--which looks so elegant in your printout, and 
    which appears so neatly divided into intuitively satisfying, interacting 
    subroutines--an inefficient mess that barely runs at all, when it's 
    not completely clogging up your computer. </p>
<p> So, in this short article I'll show you a handful of tricks 
    that enable you to write code for dealing with large amounts of biological 
    sequence data--in this case, very long strings--while still getting 
    satisfactory speed from the program. </p>
<h3>Memory is the Bottleneck</h3>
<p> What is the problem, exactly? It usually comes down to this: by dealing 
    with very large strings, each one of which uses a significant portion 
    of the main memory that your computer uses to hold a running program, 
    you can easily overtax the amount of main memory available. </p>
<p> When a program on your computer (a <i>process</i> on your Linux, Unix, 
    or Mac OS X computer) runs out of main memory, its performance starts 
    to seriously degrade. It may try to overcome the lack of fast and efficient 
    main memory by enlisting a portion of disk space to hold the part of 
    the running program that it can no longer fit. </p>
<p> But when a program starts writing and reading to and from hard disk 
    memory it can get awfully slow awfully fast. And depending on the nature 
    of the computation, the program may start "thrashing," that is, repeatedly 
    writing and reading large amounts of data between main memory and hard 
    disk. Your elegant program has turned into a greedy, lazy misanthrope 
    that grabs up all the resources available and then seems to just sit 
    there. You've created a monster! </p>
<p> Take the snippet of code above that calls <code>get_chromosome</code>. Without 
    knowing anything more about the subroutine, it's a pretty good bet that 
    it is fetching the 100Mb of data from somewhere, perhaps a disk file, 
    or a relational database, or a web site. To do so, it must be using 
    at least 100Mb of memory. Then, when it returns the data to be stored 
    in <code>$chromosome1</code>, the program uses another 100Mb of memory. Now, 
    perhaps you want to do a regular expression search on the chromosome, 
    saving the desired expression with parentheses that set the special 
    variables <code>$1</code>, <code>$&amp;</code>, and so on. These special 
    variables can be quite large, and that means use of even more memory 
    by your program. </p>
<p> And since this is elegant, simple code you've written, you may well 
    make other copies of the chromosome data or portions of it, in your 
    tenacious hunt for the elusive cure for a deadly disease. The resulting 
    code may be clear, straightforward to understand, and correct--all good 
    and proper things for code to be--but the amount of string copies will 
    land you in the soup. Not only does copying a large string take up memory, 
    but the actual copying can itself be slow, especially if there's a lot 
    of it. </p>
<h3>Space Efficiency</h3>

<!-- sidebar begins -->
<table width="220" border="0" cellspacing="8" cellpadding="4" align="right">
<tr>
<td width="220" valign="top" bgcolor="#efefef">
<div class="secondary">
<h4>More from this author</h4>
<p>
&bull; <a href="/pub/a/2001/11/16/perlbio2.html">Parsing Protein Domains with Perl</a><br />
&bull; <a href="/pub/a/2002/01/02/bioinf.html">Beginning Bioinformatics</a><br />
&bull; <a href="http://www.oreilly.com/news/perlbio_1001.html">Why Biologists Want to Program Computers</a>
</p>
</div>
</td></tr></table>
<!-- sidebar ends -->

<p> You may need to add a new constraint to your program design when you've 
    got a large amount of data in a running program. The constraint is <i>"Use 
    minimal memory."</i> Often, a program that barely runs at all and takes 
    many hours of clogging up the computer, can be rewritten to run in a 
    few minutes by reworking the algorithm so that it uses only a small 
    fraction of the memory. </p>
<p> It's a case of decreasing time by first decreasing space. (Astrophysicists, 
    take note.) </p>
<h3>References</h3>
<p> There's one easy way to cut down on the number of big strings in a program. 
</p>
<p> If you need a subroutine to return a large string, as in the <code>get_chromosome</code> 
    subroutine I've used as an example, you can use <i>references</i> to 
    eliminate some of this memory usage. </p>
<p> The practice of passing references to a subroutine is familiar to experienced 
    Perl programmers. In our example, we can rewrite the subroutine so that 
    the return value is placed into a string that is passed in as an argument. 
    But we don't pass a copy of the string--we pass a reference to the string, 
    which takes almost no additional space, and which still enables the 
    subroutine to provide the entire chromosome 1 DNA to the calling program. 
    Here's an example: </p>

<pre><code>load_chromosome( 1, \$chromosome1 );</code></pre>

<p> This new subroutine has two arguments. The <code>1</code> presumably will tell the 
    subroutine which human chromosome we want (we want the biggest human 
    chromosome, chromosome 1). </p>
<p> The second argument is a reference to a scalar variable. Inside the 
    subroutine, the reference is most likely used to initialize an argument 
    like this: </p>

<pre><code>my($chromnumber, $chromref) = @_;</code></pre>

<p> And then the DNA data is put into the string by calling it <code>$$chromref</code>, 
    for instance like so: </p>
	
<pre><code>$$chromref = 'ACGTGTGAACGGA';</code></pre>

<p> No return value is needed. After the subroutine call, the main program 
    will find that the contents of <code>$chromosome1</code> have changed, and now consist 
    of "ACGTGTGAACGGA." (Of course, a chromosome is much longer than this 
    little fragment.) </p>
<p> Using references is also a great way to pass a large amount of data 
    <i>into</i> a subroutine without making copies of it. In this case, 
    however, the fact that the subroutine can change the contents of the 
    referenced data is something to watch out for. Sometimes you just want 
    a subroutine to get to use the data, but you expect the variable containing 
    the data to still have the same data after the subroutine gets a look 
    at it. So you have to watch what you do when you're passing references 
    to data into a subroutine, and make sure you know what you want. </p>
<h3>Managing Memory with Buffers</h3>
<p> One of the most efficient ways to deal with very large strings is to 
    deal with them a little at a time. </p>
<p> Here's an example of a program for searching an entire chromosome for 
    a particular 12-base pattern, using very little memory. (A <i>base</i> 
    is one of the four molecules that are the principal building blocks 
    of DNA. The four bases are represented in Perl strings as the characters 
    A, C, G, and T. You'll often hear biologists talking about "megabases" 
    instead of "megabytes" in a string. If you hear that, you're probably 
    talking to a bioinformatician.) </p>
<p> When writing a program that will search for any regular expression in 
    a chromosome, it's hard to see how you could avoid putting the whole 
    chromosome in a string. But very often there's a limit to the size of 
    what you're searching for. In this program, I'm looking for the 12-base 
    pattern "ACGTACGTACGT." And I'm going to get the chromosome data from 
    a disk file. </p>
<p> My trick is going to be to just read in the chromosome data a line or 
    two at a time, search for the pattern, and then <i>reuse</i> the memory 
    to read in the next line or two of data. </p>
<p> The extra work I have to do in programming is, first, I need to 
    keep track myself of how much of the data has been read in, so I can 
    report the locations in the chromosome of successful searches. Second, 
    I need to keep aware that my pattern might start at the end of one line 
    and complete at the beginning of the next line, so I need to make sure 
    I search across line breaks as well as within lines of data from the 
    input file. </p>


<p> Here's a small program that reads in a FASTA file given as an argument 
    on the command line and searches for my pattern in any amount of DNA--a 
    whole chromosome, a whole genome, even all known genetic data, just 
    assuming that the data is in a FASTA file named in the command line. 
    I'll call my program <code>find_fragment</code>, and assuming the DNA is in 
    a FASTA file called <code>human.dna</code>, I'll call it like so: </p>

<pre><code>[tisdall@coltrane]$ perl find_fragment human.dna</code></pre>

<p> For testing purposes I made a very short FASTA DNA file, <code>human.dna</code>, 
    which contains: </p>
<pre><code>&gt; human dna--Not!  The fragment ACGTACGTACGT appears at positions 10, 40, and 98
AAAAAAAAAACGTACGTACGTCCGCGCGCGCGCGCGCGCACGTACGTACG
TGGGGGGGGGGGGGGGCCCCCCCCCCGGGGGGGGGGGGAAAAAAAAAACG
TACGTACGTTTTTTTTTTTTTTTTTTTTTTTTTTT</code></pre>
<p> Here's the code for the program <code>find_fragment</code>: </p>
<pre><code>#!/usr/bin/perl

#
# find_fragment : find 'ACGTACGTACGT' in a very large DNA FASTA file 
# using minimal memory
#
#  N.B. This example program does no checking of the input to ensure 
#       that it is DNA data in FASTA format; it just assumes that 
#       it is. This program also assumes there is just one FASTA
#       record in the input file.
#
#  Copyright (c) 2003 James Tisdall
#

use warnings;
use strict;
use Carp;

# Make sure the program is called with one argument, presumably a 
# FASTA file of DNA
my $USAGE = "perl find_fragment file.FASTA";
unless(@ARGV == 1) { croak "$USAGE:$!\n" }

# $fragment: the pattern to search for
# $fraglen:  the length of $fragment
# $buffer:   a buffer to hold the DNA from the input file
# $position: the position of the buffer in the total DNA
my($fragment, $fraglen, $buffer, $position) = ('ACGTACGTACGT', 12, '', 0);

# The first line of a FASTA file is a header and begins with '&gt;'
my $header = &lt;&gt;;

# Get the first line of DNA data, to start the ball rolling
$buffer = &lt;&gt;;
chomp $buffer;

# The remaining lines are DNA data ending with newlines
while(my $newline = &lt;&gt;) {

    # Add the new line to the buffer
    chomp $newline;
    $buffer .= $newline;

    # Search for the DNA fragment, which has a length of 12
    # (Report the character at string position 0 as being at position 1, 
    # as usual in biology)
    while($buffer =~ /$fragment/gi) {
        print "Found $fragment at position ", $position + $-[0] + 1, "\n";
    }

    # Reset the position counter (will be true after you reset the buffer, next)
    $position = $position + length($buffer) - $fraglen + 1;

    # Discard the data in the buffer, except for a portion at the end
    # so patterns that appear across line breaks are not missed
    $buffer = substr($buffer, length($buffer) - $fraglen + 1, $fraglen - 1);
}</code></pre>

<p> Here's the output of running the command <code>perl find_fragment human.dna</code>: 
</p>
<pre><code>Found ACGTACGTACGT at position 10
Found ACGTACGTACGT at position 40
Found ACGTACGTACGT at position 98</code></pre>

<h3>How the Code Works</h3>
<p> After the highly recommended <code>use strict</code> and <code>use warnings</code> are turned on, and 
    the Carp module is loaded so the program can "croak" when needed, the 
    program variables are declared and initialized. </p>
<p> The first line of the FASTA file is a header and is not needed here, 
    so it's read and not used. Then the first line of DNA data is read into 
    the buffer and its <code>newline</code> character is removed. I start with this because 
    I want to search for the fragment even if it is broken by new lines, 
    so I'll have to look at least at the first two lines; here I get the 
    first line, and in the while loop that follows I'll start by adding 
    the second line to the buffer. </p>
<p> Then the while loop, which does the main work of the program, starts 
    reading in the next line of the FASTA file named on the command line, 
    in this case the FASTA file <code>human.dna</code>. The <code>newline</code> is removed with 
    "chomp," and the new line is added to the buffer. </p>
<p> Then comes the short while loop that does the regular expression pattern 
    match of the <code>$fragment</code> in the <code>$buffer</code>. It has modifiers "g" for <i>g</i>lobal 
    search (the fragment may appear more than once in the buffer); and "i" 
    for case <i>i</i>nsensitive search, that is, either uppercase or lowercase DNA data (e.g. ACGT or acgt). </p>
<p> When the fragment is found the program simply prints out the position. 
    <code>$position</code> holds the position of the beginning of the buffer in the total 
    DNA, and is something I have to keep track of. <code>$-[0]</code> is a special variable 
    that gives the offset of the last successful pattern match in the string. 
    I also add 1, because biologists always say that the first base in a 
    sequence of DNA is at position 1, whereas Perl says that the first character 
    in a string is at position 0. So I add 1 to the Perl position to get 
    the biologist's position. </p>
<p> The last two lines of code reset the buffer by eliminating the beginning 
    part of it, and then adjust the position counter accordingly. The buffer 
    is shortened so that it just keeps the part at the very end that might 
    be part of a pattern match that crosses over the lines of the input 
    file. This would be the tail part of the buffer that is just one base 
    shorter than the length of the fragment. </p>
<p> In this way, the program keeps at most two lines' worth of DNA in <code>$buffer</code>, 
    but still manages to search the entire genome (or chromosome or whatever 
    is in the FASTA file) for the fragment. It performs very quickly, compared 
    to a program that reads in a whole genome and blows out the memory in 
    the process. </p>
<h3>When You Should Bother</h3>
<p> A space-inefficient program might well work fine on your better computers, 
    but it won't work well at all when you need to run it on another computer 
    with less main memory installed. Or, it might work fine on the fly genome, 
    but slow to a crawl on the human genome. </p>
<p> The rule of thumb is that if you know you'll be dealing with large 
    data sets, consider the amount of space your program uses as an 
    important constraint when designing and coding. Then you won't have 
    to go back and redo the entire program when a large amount of DNA gets 
    thrown at you. </p>
<p><i>Editor's note: Stay tuned for part two in this two-part series later 
    this month. In it, James will take a more in-depth look at space efficiency, 
    and include a more general version of a program that uses a buffer. 
    In particular, part two will cover running subroutines with minimal space, eliminating subroutines altogether, and sequence motifs with 
    bounded lengths.</i></p>

<hr size="1" noshade="noshade" />

<p> O'Reilly &amp; Associates will soon release (September 2003) <a href="http://www.oreilly.com/catalog/mperlbio/index.html?CMP=IL7015">Mastering 
    Perl for Bioinformatics</a>. </p>
<ul>
    <li>
        <p> <a href="http://www.oreilly.com/catalog/mperlbio/chapter/index.html?CMP=IL7015">Sample Chapter 9, Introduction to Bioperl</a>, is 
            available free online. </p>
    </li>
    <li>
        <p> You can also look at the <a href="http://www.oreilly.com/catalog/mperlbio/toc.html?CMP=IL7015">Table of Contents</a>, the 
            <a href="http://www.oreilly.com/catalog/mperlbio/inx.html?CMP=IL7015">Index</a>, and the <a href="http://www.oreilly.com/catalog/mperlbio/desc.html?CMP=IL7015">Full Description</a> 
            of the book. </p>
    </li>
    <li>
        <p> For more information, or to order the book, <a href="http://www.oreilly.com/catalog/mperlbio/index.html?CMP=IL7015">click 
            here</a>. </p>
    </li>
</ul>
        </div>



    </div>
    <div class="asset-footer"></div>
</div>


                            
                            <div id="entry-1194" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2003/09/p6pdigest/20030907.html" rel="bookmark">This week on Perl 6, week ending 2003-09-07</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author">Piers Cawley</span> on <abbr class="published" title="2003-09-07T00:00:00-08:00">September  7, 2003 12:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            
<p>Welcome to the last Perl 6 summary of my 35th year. Next week's
summary will (in theory) be written on my 36th birthday (a year of
being square, so no change there then). I'll give you fair warning
that it might be late, though it probably won't. Newcastle University
has, in its infinite wisdom decided to have its students enrolling on
that day so Gill will be off up to Newcastle to register leaving me
at home with nothing to do but keep the house tidy in case a buyer
wants to come and look at it, so sitting in one place with a laptop
writing a summary seems like a good strategy.</p>
<p>As last week's 'world turned upside down' approach of starting
with perl6-language was such a success we'll do the same again this
week.</p>
<h4><a name="the language list gets some traffic shock!">The language list gets some traffic shock!</a></h4>
<p>Jonadab the Unsightly One replied to Abhijit A. Mahabal's message
from the first of August concerning junctions and set theory.</p>
<p><a href="http://groups.google.com/groups?threadm=fzjfanij.fsf%40jonadab.homeip.net">http://groups.google.com/groups</a></p>


<h3><a name="meanwhile, on perl6internals">Meanwhile, on perl6-internals</a></h3>
<h4><a name="serialization is hard!">Serialization is Hard!</a></h4>
<p>Last week's discussion of serialization sparked off by Leopold
T&ouml;tsch's suggestion of a <code>vtable-&gt;dump</code> mode <em>really</em> got
into its stride this week. It turns out that getting this right is a
Hard Problem in the presence of threads.</p>
<p>Dan's plan for serialization involves using the GC's object graph
walker to work out what to serialize when you tell Parrot to dump a
PMC. Leo worried that this would essentially stop the garbage
collector running during serialization which could be tricky if the
serialization process tried to allocate any memory.</p>
<p>Dan and Leo ended up in a protracted, but polite, argument about
details.</p>
<p>At about 45 entries into the thread, Leo produced a summary of the
various options and issues associated with them.</p>
<p><a href="http://groups.google.com/groups?threadm=a0521060dbb7978890bf1%40%5B63.120.19.221%5D">http://groups.google.com/groups</a></p>
<p><a href="http://groups.google.com/groups?threadm=200309041031.h84AV8k12702%40thu8.leo.home">http://groups.google.com/groups</a> -- Leo's summary</p>
<h4><a name="file spec">File Spec</a></h4>
<p>Leo T&ouml;tsch commented on Vladimir Lipskiy's implementation of a
<a href="/File/Spec.html">the File::Spec manpage</a> like tool for Parrot. (File::Spec is Perl's tool for
dealing with filenames and paths in a platform independent
fashion). Michael Schwern pointed at Ken Williams' ``excellent
<a href="/Path/Class.html">the Path::Class manpage</a> module which gives you actual file and directory
objects'' which he reckons has a much better interface than
File::Spec.</p>
<p><a href="http://groups.google.com/groups?threadm=200309010757.h817v7209704%40thu8.leo.home">http://groups.google.com/groups</a></p>
<h4><a name="notifications">Notifications</a></h4>
<p>Gordon Henriksen posted a great discussion of using notifications to
implement weakrefs. Rather wonderfully he used the notification
system itself as a good example of why dying object notifications
were a good idea.</p>
<p><a href="http://groups.google.com/groups?threadm=000b01c37048%248b6febf0%24cc54e8c7%40domain.ma.iclub.com">http://groups.google.com/groups</a></p>
<h4><a name="parrot 100% gnu .net">Parrot 100% GNU .NET</a></h4>
<p>Danger. Here be Licensing Issues. I don't do Licensing issues.</p>
<p>The main thrust of the discussion was what kind of library would ship
with Parrot. Dan's answer is worth reading, if only for the ``That's a
swamp I don't have enough castles for'' line.</p>
<p><a href="http://groups.google.com/groups?threadm=3F538A99.20209%40web.de">http://groups.google.com/groups</a></p>
<p><a href="http://groups.google.com/groups?threadm=a05210611bb7b0329cc74%40%5B63.120.19.221%5D">http://groups.google.com/groups</a> -- Dan's take on the library</p>
<h4><a name="you are in a maze of keyed variants, all similar">You are in a maze of keyed variants, all similar</a></h4>
<p>This seems to have been a week in which Dan and Leo spent a good deal
of their time politely disagreeing with each other. This time they
were disagreeing about the need for all the keyed variants of
Parrot's opcodes.</p>
<p>Dan outlined the reasoning behind demanding keyed variants of every
operation in a PMC's vtable (Executive summary: A combination of
speed and space reasons). Leo still doesn't seem convinced but, for
now, Pumpking trumps Patch monster.</p>
<p><a href="http://groups.google.com/groups?threadm=a05210605bb790d0849c7%40%5B63.120.19.221%5D">http://groups.google.com/groups</a></p>
<h4><a name="parrot zmachine">Parrot Z-machine</a></h4>
<p>Amir Karger's post from last week about implementing the Z-machine
(the VM that runs Infocom and other text adventures) got de-Warnocked
this week. Nicholas Clark explained that doing the Z-machine
'properly' would require some bits of Parrot that weren't actually
there yet, specifically dynamic opcode loading and dynamic bytecode
conversion. This led to a discussion of how to get those things
implemented.</p>
<p><a href="http://groups.google.com/groups?threadm=20030828131707.8989.qmail%40web40705.mail.yahoo.com">http://groups.google.com/groups</a></p>
<h4><a name="pio questions">PIO Questions</a></h4>
<p>Benjamin Goldberg posted a long list of issues and suggestions about
handling character type and encoding on Parrot IO
objects. J&uuml;rgen B&ouml;mels said that there were indeed issues,
that he'd be dealing with them as tuits allowed and that patches are
welcome.</p>
<p><a href="http://groups.google.com/groups?threadm=3F553E05.3EF95D80%40hotpop.com">http://groups.google.com/groups</a></p>
<h4><a name="how to dynamically add a method to a class">How to dynamically add a method to a class</a></h4>
<p>Joseph Ryan had asked how to add a method to a class at runtime. Dan
explained what was supposed to happen (each class has a 'backing
namespace' associated with it which contained all the class's
methods). Leo asked for a few details about how that would look in
Parrot assembly.</p>
<p>A little later, Joseph reported what appeared to be a bug in the way
IMCC handles <code>.namespace</code>. It appears that IMCC is working as
designed, the question is whether the design is doing the Right Thing.</p>
<p><a href="http://groups.google.com/groups?threadm=3F4A99A2.1060706%40osu.edu">http://groups.google.com/groups</a></p>
<p><a href="http://groups.google.com/groups?threadm=3F5A9089.7060906%40osu.edu">http://groups.google.com/groups</a></p>
<h4><a name="proposed amendment to chartype structure">Proposed amendment to chartype structure</a></h4>
<p>Peter Gibbs is working on adding support for additional chartypes to
Parrot, along with support for dynamic loading of the same. He
outlined how he planned to do it. Dan liked the idea and Peter set
off to implement it.</p>
<p><a href="http://groups.google.com/groups?threadm=002501c3739f%247b285160%24c701010a%40peter">http://groups.google.com/groups</a></p>


<h3><a name="acknowledgements, announcements, apologies">Acknowledgements, Announcements, Apologies</a></h3>
<p>First up, a combined apology and announcement. Mitchell Charity
nudged me to remind me about Mike Scott's wonderful Getting Started
with Parrot Guide/Wiki at
<a href="http://www.vendian.org/parrot/wiki/bin/view.cgi/Main/GettingStartedWithParrotDevelopment">http://www.vendian.org/parrot/wiki/bin/view.cgi/Main/GettingStartedWithParrotDevelopment</a>
which is wonderful and should be checked out immediately. Bravo Mike,
sorry it's taken so long to get round to mentioning it in the
summary.</p>
<p>Hopefully next week I'll have some info from the Perl Foundation
about their Parrot related grants. Gav Estey gave me the details in
an AIM conversation which I foolishly didn't log.</p>
<p>Apologies to everyone for spelling 'seven years and two days' as
'seven and 2 days' last week. I would fire my proofreader, but then
there would be nobody to write the summary.</p>
<p>ObLeonBrocard: Leon didn't say anything this week. As per usual.</p>
<p>My weblog has a shiny new URL this week. No new content (yet), but
you can admire the old stuff at <a href="http://www.bofh.org.uk:8080/">http://www.bofh.org.uk:8080/</a>.</p>
<p>As ever, if you've appreciated this summary, please consider one or
more of the following options:</p>
<ul>
<li>
Send money to the Perl Foundation at
<a href="http://donate.perl-foundation.org/">http://donate.perl-foundation.org/</a> and help support the ongoing
development of Perl.</li>

<li>
Get involved in the Perl 6 process. The mailing lists are open  to
all. <a href="http://dev.perl.org/perl6/">http://dev.perl.org/perl6/</a> and <a href="http://www.parrotcode.org/">http://www.parrotcode.org/</a>
are good starting points with links to the appropriate mailing lists.</li>

<li>
Send feedback, flames, money, requests for consultancy, photographic
and writing commissions, or a lovely birthday present to
<em><a href="mailto:p6summarizer@bofh.org.uk">p6summarizer@bofh.org.uk</a></em></li>
</ul>
        </div>



    </div>
    <div class="asset-footer"></div>
</div>


                            
                            <div id="entry-1186" class="entry-asset asset hentry">
    <div class="asset-header">
        <h2 class="asset-name entry-title"><a href="/pub/2003/09/03/perlcookbook.html" rel="bookmark">Cooking with Perl, Part 2</a></h2>
        <div class="asset-meta">
            <span class="byline">
    
                By <span class="vcard author"><a class="fn url" href="http://training.perl.com/">Tom Christiansen</a></span> on <abbr class="published" title="2003-09-03T00:00:00-08:00">September  3, 2003 12:00 AM</abbr>
    
            </span>

            
            

        </div>
    </div>
    <div class="asset-content entry-content">

        <div class="asset-body">
            
<!-- sidebar begins -->
<!-- don't move sidebars -->
<!-- sidebar ends -->

<p><i>Editor's note: The new edition of <a href="http://www.oreilly.com/catalog/perlckbk2/index.html?CMP=IL7015">Perl Cookbook</a>  has released, so this week we continue to highlight recipes--new to the second edition--for your sampling pleasure. This week's excerpts include recipes from Chapter 14 ("Database Access") and Chapter 18 ("Internet Services"). And be sure to check back here next week for more new recipes on extracting table data, making simple changes to elements or text, and templating with HTML::Mason. </i></p>


<h3>Sample Recipe: Using SQL Without a Database Server</h3>

<h4>Problem</h4>

<p>You want to make complex SQL queries but don't want to maintain a 
relational database server.</p>

<h4>Solution</h4>

<p>Use the DBD::SQLite module from CPAN:</p>

<pre><code>use DBI;
&nbsp;
$dbh = DBI-&gt;connect("dbi:SQLite:dbname=/Users/gnat/salaries.sqlt", "", "",
                    { RaiseError =&gt; 1, AutoCommit =&gt; 1 });
&nbsp;
$dbh-&gt;do("UPDATE salaries SET salary = 2 * salary WHERE name = 'Nat'");
&nbsp;
$sth = $dbh-&gt;prepare("SELECT id,deductions FROM salaries WHERE name = 'Nat'");
# ...</code>
</pre>

<h4>Discussion</h4>

<p>An SQLite database lives in a single file, specified with the 
<code>dbname</code> parameter in the DBI constructor. Unlike most 
relational databases, there's no database server here--DBD::SQLite interacts 
directly with the file. Multiple processes can read from the same database file 
at the same time (with SELECTs), but only one process can make changes (and 
other processes are prevented from reading while those changes are being 
made).</p>

<csperl file="grab" domain="on" record="b/941" template="b/article_sidebar2.view">

<p>SQLite supports transactions. That is, you can make a number of 
changes to different tables, but the updates won't be written to the file until 
you commit them:</p>

<pre><code>use DBI;
$dbh = DBI-&gt;connect("dbi:SQLite:dbname=/Users/gnat/salaries.sqlt", "", "",
                    { RaiseError =&gt; 1, AutoCommit =&gt; 0 });
eval {
  $dbh-&gt;do("INSERT INTO people VALUES (29, 'Nat', 1973)");
  $dbh-&gt;do("INSERT INTO people VALUES (30, 'William', 1999)");
  $dbh-&gt;do("INSERT INTO father_of VALUES (29, 30)");
  $dbh-&gt;commit(  );
};
if ($@) {
      eval { $dbh-&gt;rollback(  ) };
      die "Couldn't roll back transaction" if $@;
}</code>
</pre>

<p>SQLite is a typeless database system. Regardless of the types 
specified when you created a table, you can put any type (strings, numbers, 
dates, blobs) into any field. Indeed, you can even create a table without 
specifying any types:</p>

<pre><code>CREATE TABLE people (id, name, birth_year);</code>
</pre>

<p>The only time that data typing comes into play is when comparisons 
occur, either through WHERE clauses or when the database has to sort values. The 
database ignores the type of the column and looks only at the type of the 
specific value being compared. Like Perl, SQLite recognizes only strings and 
numbers. Two numbers are compared as floating-point values, two strings are 
compared as strings, and a number is always less than a string when values of 
two different types are compared.</p>

<p>There is only one case when SQLite looks at the type you declare 
for a column. To get an automatically incrementing column, such as unique 
identifiers, specify a field of type "INTEGER PRIMARY KEY":</p>

<pre><code>CREATE TABLE people (id INTEGER PRIMARY KEY, name, birth_year);</code>
</pre>

<p><a href="#79318">Example 
14-6</a> shows how this is done.</p>

<p><b><a name="79318">Example 14-6:</a></b> <b>ipk </b></p>

<pre><code>  #!/usr/bin/perl -w
  # ipk - demonstrate integer primary keys
  use DBI;
  use strict;
  my $dbh = DBI-&gt;connect("dbi:SQLite:ipk.dat", "", "",
  {RaiseError =&gt; 1, AutoCommit =&gt; 1});
  # quietly drop the table if it already existed
  eval {
    local $dbh-&gt;{PrintError} = 0;
    $dbh-&gt;do("DROP TABLE names");
  };
  # (re)create it
  $dbh-&gt;do("CREATE TABLE names (id INTEGER PRIMARY KEY, name)");
  # insert values
  foreach my $person (qw(Nat Tom Guido Larry Damian Jon)) {
    $dbh-&gt;do("INSERT INTO names VALUES (NULL, '$person')");
  }
  # remove a middle value
  $dbh-&gt;do("DELETE FROM names WHERE name='Guido'");
  # add a new value
  $dbh-&gt;do("INSERT INTO names VALUES (NULL, 'Dan')");
  # display contents of the table
  my $all = $dbh-&gt;selectall_arrayref("SELECT id,name FROM names");
  foreach my $row (@$all) {
    my ($id, $word) = @$row;
    print "$word has id $id\n";
  }</code>
</pre>

<p>SQLite can hold 8-bit text data, but can't hold an ASCII NUL 
character (<code>\0</code>). The only workaround is to do your own 
encoding (for example, URL encoding or Base64) before you store and after you 
retrieve the data. This is true even of columns declared as BLOBs.</p>

<h4>See Also</h4>

<p>"Executing an SQL Command Using DBI;" the documentation for the 
CPAN module DBD::SQLite; the SQLite home page at <a 
href="http://www.hwaci.com/sw/sqlite/">http://www.hwaci.com/sw/sqlite/</a></p>













<h3>Sample Recipe: Sending Attachments in Mail</h3>

<h4>Problem</h4>

<p>You want to send mail that includes attachments; for example, you 
want to mail a PDF document.</p>

<h4>Solution</h4>

<p>Use the MIME::Lite module from CPAN. First, create a MIME::Lite 
object representing the multipart message:</p>

<pre><code>use MIME::Lite;
&nbsp;
$msg = MIME::Lite-&gt;new(From    =&gt; 'sender@example.com',
                       To      =&gt; 'recipient@example.com',
                       Subject =&gt; 'My photo for the brochure',
                       Type    =&gt; 'multipart/mixed');</code>
</pre>

<p>Then, add content through the <code>attach</code> 
method:</p>

<pre><code>$msg-&gt;attach(Type        =&gt; 'image/jpeg',
             Path        =&gt; '/Users/gnat/Photoshopped/nat.jpg',
             Filename    =&gt; 'gnat-face.jpg');
&nbsp;
$msg-&gt;attach(Type        =&gt; 'TEXT',
             Data        =&gt; 'I hope you can use this!');</code>
</pre>

<p>Finally, send the message, optionally specifying how to send 
it:</p>

<pre><code>$msg-&gt;send(  );            # default is to use sendmail(1)
# alternatively
$msg-&gt;send('smtp', 'mailserver.example.com');</code>
</pre>

<h4>Discussion</h4>

<p>The MIME::Lite module creates and sends mail with MIME-encoded 
attachments. MIME stands for Multimedia Internet Mail Extensions, and is the 
standard way of attaching files and documents. It can't, however, extract 
attachments from mail messages--for that you need to read Recipe "Extracting 
Attachments from Mail."</p>

<p>When creating and adding to a MIME::Lite object, pass parameters 
as a list of named parameter pairs. The pair conveys both mail headers (e.g., 
<code>From</code>, <code>To</code>, <code>Subject</code>) and those specific to MIME::Lite. In general, mail 
headers should be given with a trailing colon:</p>

<pre><code>$msg = MIME::Lite-&gt;new('X-Song-Playing:' =&gt; 'Natchez Trace');</code>
</pre>

<p>However, MIME::Lite accepts the headers in <a href="#20112">Table 
18-2</a> without a trailing colon. <code>*</code> indicates a 
wildcard, so <code>Content-*</code> includes <code>Content-Type</code> and <code>Content-ID</code> but 
not <code>Dis-Content</code>.</p>

<table border="1">
  <caption><b><a name="20112">Table 18-2:</a></b> <b>MIME::Lite headers </b></caption>
  
  <tbody>
  <tr>
    <td>
      <code>Approved</code></td>
    <td>
      <code>Encrypted</code></td>
    <td>
      <code>Received</code></td>
    <td>
      <code>Sender</code></td></tr>
  <tr>
    <td>
      <code>Bcc</code></td>
    <td>
      <code>From</code></td>
    <td>
      <code>References</code></td>
    <td>
      <code>Subject</code></td></tr>
  <tr>
    <td>
      <code>Cc</code></td>
    <td>
      <code>Keywords</code></td>
    <td>
      <code>Reply-To</code></td>
    <td>
      <code>To</code></td></tr>
  <tr>
    <td>
      <code>Comments</code></td>
    <td>
      <code>Message-ID</code></td>
    <td>
      <code>Resent-*</code></td>
    <td>
      <code>X-*</code></td></tr>
  <tr>
    <td>
      <code>Content-*</code></td>
    <td>
      <code>MIME-Version</code></td>
    <td>
      <code>Return-Path</code></td>
    <td>
      &nbsp;</td></tr>
  <tr>
    <td>
      <code>Date</code></td>
    <td>
      <code>Organization</code></td>
    <td>
      &nbsp;</td>
    <td>
      &nbsp;</td></tr></tbody></table>
	  
<p>The full list of MIME::Lite options is given in <a href="#21965">Table 
18-3</a>.</p>

<table border="1">
  <caption><b><a name="21965">Table 18-3:</a></b> <b>MIME::Lite options </b></caption>
  
  <tbody>
  <tr>
    <td>
      <code>Data</code></td>
    <td>
      <code>FH</code></td>
    <td>
      <code>ReadNow</code></td></tr>
  <tr>
    <td>
      <code>Datestamp</code></td>
    <td>
      <code>Filename</code></td>
    <td>
      <code>Top</code></td></tr>
  <tr>
    <td>
      <code>Disposition</code></td>
    <td>
      <code>Id</code></td>
    <td>
      <code>Type</code></td></tr>
  <tr>
    <td>
      <code>Encoding</code></td>
    <td>
      <code>Length</code></td>
    <td>
      &nbsp;</td></tr>
  <tr>
    <td>
      <code>Filename</code></td>
    <td>
      <code>Path</code></td>
    <td>
      &nbsp;</td></tr></tbody></table>
	  
<p>The MIME::Lite options and their values govern what is attached 
(the data) and how:</p>

<dl>
  <dt><code>Path</code> 
  </dt>
<dd>The file containing the data to attach. </dd>
  
  <dt><code>Filename</code> 
  </dt>
<dd>The default filename for the reader of the message to 
  save the file as. By default this is the filename from the <code>Path</code> option (if <code>Path</code> was 
  specified). </dd>
  
  <dt><code>Data</code> 
  </dt>
<dd>The data to attach. </dd>
  
  <dt><code>Type</code> 
  </dt>
<dd>The <code>Content-Type</code> of the data 
  to attach. </dd>
  
  <dt><code>Disposition</code> 
  </dt>
<dd>Either <code>inline</code> or <code>attachment</code>. The former indicates that the reader should 
  display the data as part of the message, not as an attachment. The latter 
  indicates that the reader should display an option to decode and save the 
  data. This is, at best, a hint. </dd>
  
  <dt><code>FH</code> 
  </dt>
<dd>An open filehandle from which to read the attachment 
  data. 
  </dd></dl>
  
<p>There are several useful content types: <code>TEXT</code> means <code>text/plain</code>, which is 
the default; <code>BINARY</code> similarly is short for <code>application/octet-stream</code>; <code>multipart/mixed</code> is used for a message that has attachments; 
<code>application/msword</code> for Microsoft Word files; <code>application/vnd.ms-excel</code> for Microsoft Excel files; <code>application/pdf</code> for PDF files; <code>image/gif</code>, <code>image/jpeg</code>, and <code>image/png</code> for GIF, JPEG, and PNG files, respectively; <code>audio/mpeg</code> for MP3 files; <code>video/mpeg</code> for MPEG movies; <code>video/quicktime</code> for Quicktime (<em>.mov</em>) files.</p>

<p>The only two ways to send the message are using <em>sendmail</em>(1) or using Net::SMTP. Indicate Net::SMTP by 
calling <code>send</code> with a first argument of <code>"smtp"</code>. Remaining arguments are parameters to the Net::SMTP 
constructor:</p>

<pre><code># timeout of 30 seconds
$msg-&gt;send("smtp", "mail.example.com", Timeout =&gt; 30);</code>
</pre>

<p>If you plan to make more than one MIME::Lite object, be aware that 
invoking <code>send</code> as a class method changes the default 
way to send messages:</p>

<pre><code>MIME::Lite-&gt;send("smtp", "mail.example.com");
$msg = MIME::Lite-&gt;new(%opts);
# ...
$msg-&gt;send(  );                   # sends using SMTP</code>
</pre>

<p>If you're going to process multiple messages, also look into the 
<code>ReadNow</code> parameter. This specifies that the data for 
the attachment should be read from the file or filehandle immediately, rather 
than when the message is sent, written, or converted to a string.</p>

<p>Sending the message isn't the only thing you can do with it. You 
can get the final message as a string:</p>

<pre><code>$text = $msg-&gt;as_string;</code>
</pre>

<p>The <code>print</code> method writes the string form 
of the message to a filehandle:</p>

<pre><code>$msg-&gt;print($SOME_FILEHANDLE);</code>
</pre>

<p><a href="#85143">Example 
18-3</a> is a program that mails filenames given on the command line as 
attachments.</p>

<p><b><a name="85143">Example 18-3:</a></b> <b>mail-attachment </b></p>

<pre><code>#!/usr/bin/perl -w
# mail-attachment - send files as attachments
&nbsp;
use MIME::Lite;
use Getopt::Std;
&nbsp;
my $SMTP_SERVER = 'smtp.example.com';           # CHANGE ME
my $DEFAULT_SENDER = 'sender@example.com';      # CHANGE ME
my $DEFAULT_RECIPIENT = 'recipient@example.com';# CHANGE ME  
&nbsp;
MIME::Lite-&gt;send('smtp', $SMTP_SERVER, Timeout=&gt;60);
&nbsp;
my (%o, $msg);
&nbsp;
# process options
&nbsp;
getopts('hf:t:s:', \%o);
&nbsp;
$o{f} ||= $DEFAULT_SENDER;
$o{t} ||= $DEFAULT_RECIPIENT;
$o{s} ||= 'Your binary file, sir';
&nbsp;
if ($o{h} or !@ARGV) {
    die "usage:\n\t$0 [-h] [-f from] [-t to] [-s subject] file ...\n";
}
&nbsp;
# construct and send email
&nbsp;
$msg = new MIME::Lite(
    From =&gt; $o{f},
    To   =&gt; $o{t},
    Subject =&gt; $o{s},
    Data =&gt; "Hi",
    Type =&gt; "multipart/mixed",
);
&nbsp;
while (@ARGV) {
  $msg-&gt;attach('Type' =&gt; 'application/octet-stream',
               'Encoding' =&gt; 'base64',
               'Path' =&gt; shift @ARGV);
}
&nbsp;
$msg-&gt;send(  );</code>
</pre>

<h4>See Also</h4>

<p>The documentation for MIME::Lite</p>


<hr noshade="noshade" />

<p>O'Reilly &amp; Associates recently released (August 2003) <a href="http://www.oreilly.com/catalog/perlckbk2/index.html?CMP=IL7015">Perl Cookbook, 2nd Edition.</a></p>

<ul>
    <li><a href="http://www.oreilly.com/catalog/perlckbk2/chapter/index.html?CMP=IL7015">Sample Chapter 1, Strings</a> is available free online.</li>
    <li>You can also look at the <a href="http://www.oreilly.com/catalog/perlckbk2/toc.html?CMP=IL7015">Table of Contents</a>, the <a href="http://www.oreilly.com/catalog/perlckbk2/inx.html?CMP=IL7015">Index</a>, and the <a href="http://www.oreilly.com/catalog/perlckbk2/desc.html?CMP=IL7015">full description</a> of the book.</li>
    <li>For more information, or to order the book, <a href="http://www.oreilly.com/catalog/perlckbk2/index.html?CMP=IL7015">click here</a>.</li>
</ul>

        </div>



    </div>
    <div class="asset-footer"></div>
</div>




                            <div class="content-nav">
                                <a href="/pub/2003/08/">&laquo; August 2003</a> |
                                <a href="/pub/">Main Index</a> |
                                <a href="/pub/archives.html">Archives</a>
                                | <a href="/pub/2003/10/">October 2003 &raquo;</a>
                            </div>


                        </div>
                    </div>


                    <div id="beta">
    <div id="beta-inner">


    
    <div class="widget-what-is-perl widget">
    <div class="widget-content widget-content-what-is-perl">
       Visit the home of the  Perl programming language: <a href="http://www.perl.org/">Perl.org</a
    </div>
</div>
<div class="widget-find-out-more widget-archives widget">
    <div class="widget-content">
        <ul>
            <li><a href="http://www.perl.org/get.html">Download</a></li>
            <li><a href="http://perldoc.perl.org/">Documentation</a></li>
            <li><a href="http://blogs.perl.org/">Perl Bloggers</a></li>
            <li><a href="http://news.perlfoundation.org/">Foundation News</a></li>
        </ul>
    </div>
</div><div class="widget-tcpc widget">
<h3 class="widget-header">Sponsored by</h3>
    <div class="widget-content">
        <a href="http://training.perl.com/" alt="Perl Training" target="_blank"><img src="/i/tcpc.png" width="150" height="50"></a>
    </div>
</div>

<div class="widget-syndication widget">
    <div class="widget-content">
        <ul>
            <li><img src="/mt-static/images/status_icons/feed.gif" alt="Subscribe to feed" width="9" height="9" /> <a href="/pub/atom.xml">Subscribe to this website's feed</a></li>

        </ul>
    </div>
</div>
<div class="widget-archive-monthly widget-archive widget">
    <h3 class="widget-header">Monthly <a href="/pub/archives.html">Archives</a></h3>
    <div class="widget-content">
        <ul>
        
            <li><a href="/pub/2014/02/">February 2014 (1)</a></li>
        
    
        
            <li><a href="/pub/2014/01/">January 2014 (1)</a></li>
        
    
        
            <li><a href="/pub/2013/10/">October 2013 (1)</a></li>
        
    
        
            <li><a href="/pub/2013/01/">January 2013 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/12/">December 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/11/">November 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/10/">October 2012 (2)</a></li>
        
    
        
            <li><a href="/pub/2012/08/">August 2012 (2)</a></li>
        
    
        
            <li><a href="/pub/2012/06/">June 2012 (11)</a></li>
        
    
        
            <li><a href="/pub/2012/05/">May 2012 (18)</a></li>
        
    
        
            <li><a href="/pub/2012/04/">April 2012 (17)</a></li>
        
    
        
            <li><a href="/pub/2012/02/">February 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/12/">December 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/09/">September 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/08/">August 2011 (2)</a></li>
        
    
        
            <li><a href="/pub/2011/06/">June 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/05/">May 2011 (3)</a></li>
        
    
        
            <li><a href="/pub/2011/04/">April 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/03/">March 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/02/">February 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/01/">January 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/11/">November 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/10/">October 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/09/">September 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/08/">August 2010 (3)</a></li>
        
    
        
            <li><a href="/pub/2010/07/">July 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/04/">April 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/03/">March 2010 (4)</a></li>
        
    
        
            <li><a href="/pub/2008/05/">May 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/04/">April 2008 (2)</a></li>
        
    
        
            <li><a href="/pub/2008/03/">March 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/02/">February 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/01/">January 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/12/">December 2007 (2)</a></li>
        
    
        
            <li><a href="/pub/2007/09/">September 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/08/">August 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/07/">July 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/06/">June 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/05/">May 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/04/">April 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/03/">March 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/02/">February 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/01/">January 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/12/">December 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/11/">November 2006 (2)</a></li>
        
    
        
            <li><a href="/pub/2006/10/">October 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/09/">September 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/08/">August 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/07/">July 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/06/">June 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/05/">May 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/04/">April 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/03/">March 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/02/">February 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2006/01/">January 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/12/">December 2005 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/11/">November 2005 (3)</a></li>
        
    
        
            <li><a href="/pub/2005/10/">October 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/09/">September 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/08/">August 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/07/">July 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/06/">June 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/05/">May 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/04/">April 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/03/">March 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2005/02/">February 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/01/">January 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/12/">December 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/11/">November 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/10/">October 2004 (5)</a></li>
        
    
        
            <li><a href="/pub/2004/09/">September 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/08/">August 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/07/">July 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/06/">June 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/05/">May 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2004/04/">April 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/03/">March 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/02/">February 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/01/">January 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/12/">December 2003 (4)</a></li>
        
    
        
            <li><a href="/pub/2003/11/">November 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/10/">October 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/09/">September 2003 (6)</a></li>
        
    
        
            <li><a href="/pub/2003/08/">August 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/07/">July 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/06/">June 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/05/">May 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/04/">April 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/03/">March 2003 (10)</a></li>
        
    
        
            <li><a href="/pub/2003/02/">February 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/01/">January 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/12/">December 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/11/">November 2002 (9)</a></li>
        
    
        
            <li><a href="/pub/2002/10/">October 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/09/">September 2002 (11)</a></li>
        
    
        
            <li><a href="/pub/2002/08/">August 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/07/">July 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/06/">June 2002 (4)</a></li>
        
    
        
            <li><a href="/pub/2002/05/">May 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/04/">April 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/03/">March 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/02/">February 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/01/">January 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/12/">December 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/11/">November 2001 (5)</a></li>
        
    
        
            <li><a href="/pub/2001/10/">October 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/09/">September 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/08/">August 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/07/">July 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/06/">June 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/05/">May 2001 (11)</a></li>
        
    
        
            <li><a href="/pub/2001/04/">April 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/03/">March 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/02/">February 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/01/">January 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2000/12/">December 2000 (6)</a></li>
        
    
        
            <li><a href="/pub/2000/11/">November 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/10/">October 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/09/">September 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/08/">August 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/07/">July 2000 (5)</a></li>
        
    
        
            <li><a href="/pub/2000/06/">June 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/05/">May 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/04/">April 2000 (3)</a></li>
        
    
        
            <li><a href="/pub/2000/03/">March 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/02/">February 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/01/">January 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/12/">December 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/11/">November 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/10/">October 1999 (5)</a></li>
        
    
        
            <li><a href="/pub/1999/09/">September 1999 (4)</a></li>
        
    
        
            <li><a href="/pub/1999/08/">August 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/07/">July 1999 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/06/">June 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/04/">April 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/03/">March 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/01/">January 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/12/">December 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/11/">November 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/07/">July 1998 (2)</a></li>
        
    
        
            <li><a href="/pub/1998/06/">June 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/03/">March 1998 (1)</a></li>
        
        </ul>
    </div>
</div>
        
    

<div class="widget-powered widget">
    <div class="widget-content">
        <a href="http://www.movabletype.com/"><img src="/mt-static/images/bug-pbmt-white.png" alt="Powered by Movable Type 5.13-en" width="120" height="75" /></a>
    </div>
</div>



    </div>
</div>






                </div>
            </div>


            <div id="footer">
    <div id="footer-inner">
        <div id="footer-content">
            <div class="widget-powered widget">
                <div class="widget-content">
                    Powered by <a href="http://www.movabletype.com/" rel="generator">Movable Type Pro</a>
                </div>
            </div>

            <div class="widget-creative-commons widget">
                <div class="widget-content">
                    This blog is licensed under a <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/">Creative Commons License</a>.
                </div>
            </div>

        </div>
    </div>
</div>



        </div>
    </div>
</body>
</html>
