<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" id="sixapart-standard">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="generator" content="Movable Type Pro 5.13-en" />
<link rel="stylesheet" href="/pub/styles.css" type="text/css" />
<link rel="start" href="/pub/" title="Home" />
<link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/pub/atom.xml" />
<script type="text/javascript" src="/pub/mt.js"></script>
<!--
<rdf:RDF xmlns="http://web.resource.org/cc/"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<Work rdf:about="/pub/2000/02/spamfilter.html">
<dc:title>My Life With Spam</dc:title>
<dc:description>My Life with Spam -&gt; or How I Caught the Spam and What I Did With It When I Caught it -&gt; I wrote Part 1 of this series back in October 1999 for the LinuxPlanet web site, but the...</dc:description>
<dc:creator>Mark-Jason Dominus</dc:creator>
<dc:date>2000-02-09T00:00:00-08:00</dc:date>
<license rdf:resource="http://creativecommons.org/licenses/by-nc-nd/3.0/" />
</Work>
<License rdf:about="http://creativecommons.org/licenses/by-nc-nd/3.0/">
</License>
</rdf:RDF>
-->

<script type="text/javascript">

 var _gaq = _gaq || [];
 _gaq.push(['_setAccount', 'UA-50555-22']);
 _gaq.push(['_trackPageview']);

 (function() {
   var ga = document.createElement('script'); ga.type =
   'text/javascript'; ga.async = true;
   ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
   'http://www') + '.google-analytics.com/ga.js';
   var s = document.getElementsByTagName('script')[0];
   s.parentNode.insertBefore(ga, s);
 })();

</script>
<script type='text/javascript' src='http://partner.googleadservices.com/gampad/google_service.js'></script>
<script type='text/javascript'>
GS_googleAddAdSenseService("ca-pub-4136420132070439");
GS_googleEnableAllServices();
</script>
<script type='text/javascript'>
GA_googleAddSlot("ca-pub-4136420132070439", "Perl_728x90");
</script>
<script type='text/javascript'>GA_googleFetchAds();</script>
    
    <link rel="prev bookmark" href="/pub/2000/01/rss.html" title="RSS and You" />
    <link rel="next bookmark" href="/pub/2000/01/10PerlMyths.html" title="Ten Perl Myths" />
    
    
    <title>My Life With Spam - Perl.com</title>
</head>
<body id="perl-com" class="mt-entry-archive layout-wt">
    <div id="container">
        <div id="container-inner">


            <div id="header">
    <div id="header-inner">
        <div id="header-content">
        <span id="top_advert"> 
<!-- Put any landscape advert in here -->
<!-- Perl_728x90 -->
<script type='text/javascript'>
GA_googleFillSlot("Perl_728x90");
</script>
        </span> 



            <div id="header-name"><a href="/pub/" accesskey="1">Perl.com</a></div>
            <div id="header-description">news and views of the Perl programming language</div>




        </div>
    </div>
</div>



            <div id="content">
                <div id="content-inner">


                    <div id="alpha">
                        <div id="alpha-inner">


                            <div id="entry-1658" class="entry-asset asset hentry">
                                <div class="asset-header">
                                    <h1 id="page-title" class="asset-name entry-title">My Life With Spam</h1>
                                    <div class="asset-meta">
                                        <span class="byline">

                                            By <span class="vcard author">Mark-Jason Dominus</span> on <abbr class="published" title="2000-02-09T00:00:00-08:00">February  9, 2000 12:00 AM</abbr>

                                        </span>


                                    </div>
                                </div>
                                <div class="asset-content entry-content">

                                    <div class="asset-body">
                                        <!-- <a NAME="My_Life_with_Spam">My Life with Spam</a> -->
<p>
or

<!-- <a NAME="How_I_Caught_the_Spam_and_What_I">How I Caught the Spam and What I Did With It When I Caught it</a> -->


<br />
<p>I wrote Part 1 of this series back in October 1999 for the LinuxPlanet web site, 
  but the editors decided not to publish the rest of the series. Since then, many 
  people have asked for the continuation. This article is Part 2.</p>

<p>Part 1 of the series discussed my early experiences with the spam problem, first 
  on Usenet and then in my e-mail box. I talked about how to set up a mail filter 
  program and how to have it parse incoming messages. I discussed splitting up 
  the header into logical lines and why this is necessary. For the details and 
  the Perl code, you can read <a href="http://www.plover.com/~mjd/perl/lp/Spam.html">the original article</a>.</p>


<p>I also talked about my filtering philosophy, which is to blacklist the domains 
  that send me a lot of spam, and reject mail from those domains.</p>


<p>
<h1><a NAME="Domain_Pattern_Matching">Domain Pattern Matching</a></h1>
<p> One way to handle domains might have been to take the <code>To:</code> address 
  in the message and strip off the host name. However, this is impossible because 
  a host name <em>is</em> a domain. <code>perl.com</code> is both a host name 
  and a domain; <code>www.perl.com</code> is both a host name and a domain, and 
  so is <code>chocolaty-goodness.www.perl.com</code>. In practice, though, it's 
  easy to use a simple heuristic: 
<ol>
<li>
   Split the host name into components. 
  <li>
If the last component is <code>com</code>, <code>edu</code>, <code>gov</code>,
<code>net</code>, or <code>org</code>, then the domain name is the last two components.

<li>
<p>
Otherwise, the domain name is the last three components

</ol>
<p> The theory is that if the final component is not a generic top-level domain 
  like <code>com</code>, it is probably a two-letter country code. Most countries 
  imitate the generic space at the second level of their domain. For example, 
  the United Kingdom has <code>ac.uk</code>, <code>co.uk</code>, and <code>org.uk</code> 
  corresponding to <code>edu</code>, <code>com</code>, and <code>org</code>, so 
  when I get mail from <code>someone@thelonious.new.ox.ac.uk</code>, I want to 
  recognize the domain as <code>ox.ac.uk</code> (Oxford University), not <code>ac.uk</code>. 
<p> Of course, this is a heuristic, which is a fancy way of saying that it doesn't 
  work. Many top-level domains aren't divided up at the third level the way I 
  assumed. For example, the <code>to</code> domain has no organization at all, 
  the same as the <code>com</code> domain. If I get mail from <code>hot.spama.to</code>, 
  my program will blacklist that domain only, not realizing that it's part of 
  the larger <code>spama.to</code> domain owned by the same people. So far, however, 
  this has never come up. 
<p> And I didn't include <code>mil</code> in my list of exceptions. However, I've 
  never gotten spam from a <code>mil</code>. 
<p> Eventually the domain registration folks will introduce a batch of new generic 
  top-level domains, such as <code>.firm</code> and <code>.web</code>. But they've 
  been getting ready for it since 1996; they're still working up to it; and I 
  might grow old and die waiting for it to happen. (See <a
HREF="http://www.gtld-mou.org/">http://www.gtld-mou.org/</a> for more information.) 
<p> For all its problems, this method has worked just fine for a long time because 
  hardly any of the problems ever actually come up. There's a moral here: The 
  world is full of terrifically over-engineered software. Sometimes you can waste 
  a lot of time trying to find the perfect solution to a problem that only needs 
  to be partially solved. Or as my friends at MIT used to say, ``Good enough for 
  government work!'' 
<p>
Here's the code for extracting the domain:

<p>
<pre> 1    my ($user, $site) = $s =~ /(.*)@(.*)/;
 2    next unless $site;
 3    my @components =  split(/\./, $site);
 4    my $n_comp = ($components[-1] =~ /^edu|com|net|org|gov$/) ? 2 : 3;
 5    my $domain = lc(join '.', @components[-$n_comp .. -1]);
 6    $domain =~ s/^\.//;  # Remove leading . if there is one.
</pre>
<p> The sender's address is in <code>$s</code>. I extract the site name from the 
  address with a simple pattern match, which is also a wonderful example of the 
  &quot;good enough&quot; principle. Messages appear in the <code>comp.lang.perl.misc</code> 
  newsgroup every week asking for a pattern that matches an e-mail address. The 
  senders get a lot of very long complicated answers, or are told that it can't 
  be done. And yet there it is. Sure, it doesn't work. Of course, if you get mail 
  addressed to ``@''@plover.com, it's going to barf. Of course, if you get source-routed 
  mail with an address like <a
HREF="mailto:@send.here.first:joe@send.here.afterwards,">@send.here.first:joe@send.here.afterwards,</a> 
  it isn't going to work. 
<p>But guess what? Those things never happen. A production mail server has to 
  deal with these sorts of fussy details, but if my program fails to reject some 
  message as spam because it made an overly simple assumption about the format 
  of the mail addresses, there's no harm done. 
<p> On line 2, we skip immediately to the next address if there's no site name, 
  since it now appears that this wasn't an address at all. Line 3 breaks the site 
  name up into components; <code>thelonious.new.ox.ac.uk</code> is broken into 
  <code>thelonious</code>, <code>new</code>, <code>ox</code>, <code>ac</code>, 
  and <code>uk</code>. 
<p> Line 4 is the nasty heuristic: It peeks at the last component, in this case 
  <code>uk</code>, and if it's one of the magic five (<code>edu</code>, <code>com</code>, 
  <code>net</code>, <code>org</code>, or <code>gov</code>), it sets <code>$n_comp</code> 
  to 2; otherwise to 3. <code>$n_comp</code> is going to be the number of components 
  that are part of the domain, so the domain of <code>saul.cis.upenn.edu</code> 
  is <code>upenn.edu</code>, and the domain of <code>thelonious.new.ox.ac.uk</code> 
  is <code>ox.ac.uk</code>. 
<p> To get the last component, we subscript the component array <code>@components</code> 
  with <code>-1</code>. <code>-1</code> as an array subscript means to get the 
  last element of the array. Similarly, -2 means to get the next-to-last element. 
  In this case, the last component is <code>uk</code>, which doesn't match the 
  pattern, so <code>$n_comp</code> is 3. 
<p> On line 5, <code>-$n_comp .. -1</code> is really <code>-3 .. -1</code>, which 
  is the list <code>-3, -2, -1</code>. We use a Perl feature called a "list 
  slice" to extract just the elements -3, -2, and -1 from the <code>@components</code> 
  array. The syntax 
<p>
<pre>        @components[(some list)]
</pre>
<p>
invokes this feature. The list is taken to be a list of subscripts, and the
elements of <code>@components</code> with those subscripts are extracted, in order. This is why you
can write

<p>
<pre>        ($year, $month, $day) = (localtime)[5,4,3];
</pre>
<p> to extract the year, month, and day from <code>localtime</code>, in that order--it's 
  almost the same feature. Here we're extracting elements -3 (the third-to-last), 
  -2 (the second-to-last), and -1 (the last) and joining them together again. 
  If <code>$n_comp</code> had been 2, we would have gotten elements -2 and -1 
  only. 
<p> Finally, line 6 takes care of a common case in which the heuristic doesn't 
  work. If we get mail from <code>alcatel.at</code>, and try to select the last 
  three components, we'll get one undefined component--because there were really 
  only two there--and the result of the join will be <code>.alcatel.at</code>, 
  with a bogus null component on the front. Line 6 looks to see if there's an 
  extra period on the front of the domain, and if so, it chops it off. 
<p>
<hr size="1" noshade>
<h1><a NAME="Now_That_You_Have_it_What_Do_Yo">Now That You Have it, What Do You Do
With it?</a></h1>
<p>
I've extracted the domain name. The obvious thing to do is to have a big
hash with every bad domain in it, and to look this domain up in the hash to
see if it's there. Looking things up in a hash is very fast.  

<p> However, that's not what I decided to do. Instead, I have a huge file with 
  a <em>regex</em> in it for every bad domain, and I take the domain in question 
  and match it against all the patterns in the file. That's a lot slower. A <em>lot</em> 
  slower. Instead of looking up the domain instantaneously, it takes 0.24 seconds 
  to match the patterns. 
<p> Some people might see that and complain that it was taking a thousand times 
  as long as it should. And maybe that's true. But the patterns are more flexible, 
  and what's a quarter of a second more or less? The mail filter handled 2,211 
  messages in the month of January. At 0.24 seconds each, the pattern matching 
  is costing me less than 9 minutes per month. 
<p>
So much for the downside. What's the upside? I get to use patterns. That's
a big upside.

<p> I have a pattern in my pattern file that rejects any mail from anyone who 
  claims that their domain is all digits, such as 12345.com. That would have been 
  impossible with a hash. I have a pattern that rejects mail from anyone with 
  &quot;casino&quot; in their domain. That took care of spam from Planetrockcasino.com 
  and Romancasino.com before I had ever heard of those places. Remember that I 
  only do the pattern matching on the domain, so if someone sent me mail from 
  <code>casino.ox.ac.uk</code>, it would get through. 
<p> The regexes actually do have a potential problem: The patterns are in the 
  file, one pattern per line. Suppose I'm adding patterns to the file and I leave 
  a blank line by mistake. Then some mail arrives. The filter extracts the domain 
  name of the sender and starts working through the pattern file. 0.24 seconds 
  later, it gets to the blank line. 
<p>What happens when you match a string against the empty pattern? It matches, 
  that's what. Every string matches the empty pattern. Since the patterns are 
  assumed to describe mail that I <em>don't</em> want to receive, the letter is 
  rejected. So is the next letter. So is every letter. Whoops. 
<p> It's tempting to say that I should just check for blank patterns and skip 
  them if they're there, but that won't protect me against a line that has only 
  a period and nothing else--that will also match any string. 
<p>
Instead, here's what I've done:

<p>
<pre>        $MATCHLESS = &quot;qjdhqhd1!&amp;@^#^*&amp;!@#&quot;;
</pre>
<p>
<pre>        if ($MATCHLESS =~ /$badsite_pat/i) {
          &amp;defer(&quot;The bad site pattern matched `$MATCHLESS', 
                  so I assume it would match anything.  Deferring...\n&quot;);
        }
</pre>
<p> Since the patterns are designed to identify bad domain names, none of them 
  should match <code>qjdhqhd1!&amp;@^#^*&amp;!@#</code>. If a pattern <em>does</em> 
  match that string, it probably also matches a whole lot of other stuff that 
  it shouldn't. In that case, the program assumes that the pattern file is corrupt, 
  and defers the delivery. This means that it tells <code>qmail</code> that it 
  isn't prepared to deliver the mail at the present time, and that <code>qmail</code> 
  should try again later on. <code>qmail</code> will keep trying until it gets 
  through or until five days have elapsed, at which point it gives up and bounces 
  the message back to the sender. Chances are that I'll notice that I'm not getting 
  any mail sometime before five days have elapsed, look in the filter log file, 
  and fix the pattern file. As <code>qmail</code> retries delivery, the deferred 
  messages will eventually arrive. 
<p> Deferring a message is easy when your mailer is <code>qmail</code>. Here's 
  the <code>defer</code> subroutine in its entirety: 
<p>
<pre>        sub defer {
          my $msg = shift;
          carp $msg;
          exit 111;
        }
</pre>
<p> When <code>qmail</code> sees the 111 exit status from the filter program, 
  it interprets it as a request to defer delivery. (Similarly, 100 tells <code>qmail</code> 
  that there was a permanent failure and it should bounce the message back to 
  the sender immediately. The normal status of 0 means that delivery was successful.) 
<p>
I would still be in trouble if I installed <code>com</code> as a pattern in the pattern file, because it
matches more domains than it
should, but the
<code>MATCHLESS</code> test doesn't catch it. But unlike the blank line problem, it's never come
up, so I've decided to deal with it when it arises.

<p>
<hr size="1" noshade>
<h1><a NAME="C_Received_Lines">'Received:' Lines</a></h1>
<p> In addition to filtering the <code>From:</code>, <code>Reply-To:</code>, and 
  envelope sender addresses, I also look through the list of forwarding hosts 
  for bad domains. The <code>From:</code> and <code>Reply-To:</code> headers are 
  easy to forge: The sender can put whatever they want in those fields and spammers 
  usually do. But the <code>Received:</code> fields are a little different. When 
  computer A sends a message to computer B, the <em>receiving</em> computer B 
  adds a <code>Received:</code> header to the message, recording who it is, when 
  it received the message, and from whom. If the message travels through several 
  computers, there will be several received lines, with the earliest one at the 
  bottom of the header and the later ones added above it. Here's a typical set 
  of <code>Received:</code> lines: 
<p>
<pre>
1   Received: (qmail 7131 invoked by uid 119); 22 Feb 1999 22:01:59 -0000<br />
2   Received: (qmail 7124 invoked by uid 119); 22 Feb 1999 22:01:58 -0000<br />
3   Received: (qmail 7119 invoked from network); 22 Feb 1999 22:01:53 -0000<br />
4   Received: from renoir.op.net (root@209.152.193.4)<br />
5   by plover.com with SMTP; 22 Feb 1999 22:01:53 -0000<br />
6   Received: from pisarro.op.net (root@pisarro.op.net [209.152.193.22]) 
    by renoir.op.net (o1/$Revision:1.18 $) with ESMTP id RAA24909 
	for &lt;mjd@mail.op.net&gt;; Mon, 22 Feb 1999 17:01:48 -0500 (EST)<br />
7   Received: from linc.cis.upenn.edu (LINC.CIS.UPENN.EDU [158.130.12.3])
    by pisarro.op.net 
   (o2/$Revision: 1.1 $) with ESMTP id RAA12310 for 
   &lt;mjd@op.net&gt;; Mon, 22 Feb 1999 17:01:45 -0500(EST)<br />
8   Received: from saul.cis.upenn.edu (SAUL.CIS.UPENN.EDU [158.130.12.4])<br />
9   by linc.cis.upenn.edu (8.8.5/8.8.5) with ESMTP id QAA15020<br />
10  for &lt;mjd@op.net&gt;; Mon, 22 Feb 1999 16:56:20 -0500 (EST)<br />
11  Received: from mail.cucs.org (root@cucs-a252.cucs.org [207.25.43.252])<br />
12  by saul.cis.upenn.edu (8.8.5/8.8.5) with ESMTP id QAA09203
13  for &lt;mjd@saul.cis.upenn.edu&gt;; Mon, 22 Feb 1999 16:56:19 -0500 (EST)<br />
14  Received: from localhost.cucs.org ([192.168.1.223])<br />
15  by mail.cucs.org (8.8.5/8.8.5) with SMTP id QAA06332<br />
16  for &lt;mjd@saul.cis.upenn.edu&gt;; Mon, 22 Feb 1999 16:54:11 -0500
</pre>
<p> This is from a message that someone sent to <code>mjd@saul.cis.upenn.edu</code>, 
  an old address of mine. Apparently the sender's mail client, in <code>localhost.cucs.org</code>, 
  initially passed the message to the organization's mail server, <code>mail.cucs.org</code>. 
  The mail server then added the lines 14-16 to the message header. 
<p> The mail server then delivered the message to <code>saul.cis.upenn.edu</code> 
  over the Internet. <code>saul</code> added lines 11-13. Notice that the time 
  on line 13 is 128 seconds after the time on line 13. This might mean that the 
  message sat on <code>mail.cucs.org</code> for 128 seconds before it was delivered 
  to <code>saul</code>, or it might mean that the two computers' clocks are not 
  properly synchronized. 
<p> When the mail arrived on <code>saul</code>, the mailer there discovered that 
  I have a <code>.forward</code> file there directing delivery to <code>mjd@op.net</code>. 
  <code>saul</code> needed to forward the message to <code>mjd@op.net</code>. 
  However, most machines in the University of Pennsylvania CIS department do not 
  deliver Internet mail themselves. Instead, they forward all mail to a departmental 
  mail hub, <code>linc</code>, which takes care of delivering all the mail outside 
  the organization. Lines 8-10 were added by <code>linc</code> when the mail was 
  delivered to it by <code>saul</code>. 
<p>
<code>linc</code> looked up <code>op.net</code> in the domain name service and discovered
that the machine <code>pisarro.op.net</code> was receiving mail for the
<code>op.net</code> domain. Line 7 was added by <code>pisarro</code> when it received the
mail from <code>linc</code>.

<p> I don't know why <code>pisarro</code> then delivered the message to <code>renoir</code>, 
  but we know that it did, because line 6 says so. 
<p> <code>qmail</code> on <code>plover.com</code> added lines 4-5 when the mail 
  was delivered from <code>renoir</code>. Then the final three lines, 1-3, were 
  added by <code>qmail</code> for various local deliveries to <code>mjd</code>, 
  then <code>mjd-filter</code> (which runs my spam filter), and finally, <code>mjd-filter-deliver</code>, 
  which is the address that actually leads to my mailbox. 
<p> What can we learn from all this? The <code>Received:</code> lines have a record 
  of every computer that the message passed through on its way to being delivered. 
  And unlike the <code>From:</code> and <code>Reply-To:</code> lines, it really 
  does record where the message has been. 
<p>Suppose the original sender, at <code>localhost.cucs.org</code> had wanted 
  to disguise the message's origin. Let's call him Bob. Bob cannot prevent <code>cucs.org</code> 
  from being mentioned in the message header. Why? Because there it is in line 
  11. Line 11 was put there by <code>saul.cis.upenn.edu</code>, not by Bob, who 
  has no control over computers in the <code>upenn.edu</code> domain. 
<p>
Bob can try to confuse the issue by <em>adding</em> spurious <code>Received:</code>
lines, but he can't prevent the other computers from adding the correct
ones.

<p> Now, when spammers send spam, they often forge the <code>From:</code> and 
  the <code>Reply-To:</code> lines so that people don't know who they are and 
  can't come and kill them. But they can't forge the <code>Received:</code> lines 
  because it's another computer that puts those in. So when we're searching for 
  domains to check against the list of bad domain patterns, we should look through 
  the <code>Received:</code> lines too. 
<p> The difficulty with that is that there's no standard for what a <code>Received:</code> 
  line should look like or what should be in it, and every different mailer does 
  its own thing. You can see this in the example above. We need a way to go over 
  the <code>Received:</code> lines and look for things that might be domains. 
  This is just the sort of thing that Perl regexes were designed for. 
<p>
<code>  
1  sub forwarders {<br />
2    return @forwarders if @forwarders;<br />
3   <br />
4     @forwarders = <br />
5  grep { /[A-Za-z]/ } ($H{'Received'} =~ m/(?:[\w-]+\.)+[\w-]+/g);<br />
6 <br />
7   @forwarders = grep 
    { !/(\bplover\.com|\bcis\.upenn\.edu|\bpobox\.com|\bop\.net)$/i }
    @forwarders;<br />
8 <br />
9   foreach $r (@forwarders) {<br />
10    $r{lc $r} = 1;<br />
11     }<br />
12 <br />
13   @forwarders = keys %r;<br />
14 <br />
15   return @forwarders;<br />
16     }<br />
</code>
<p> The message header has already been parsed and placed into the <code>%H</code> 
  hash. <code>$H{Received}</code> contains the concatenation of all the <code>Received</code> 
  lines in the whole message. The purpose of the <code>forwarders()</code> function 
  is to examine <code>$H{Received}</code>, extract all the domain names it can 
  find, and place them in the array <code>@forwarders</code>. 
<p> Lines 4-5 are the heart of this process. Let's look a little more closely. 
<p>
<pre>        $H{'Received'} =~ m/(?:[\w-]+\.)+[\w-]+/g
</pre>
<p> This does a pattern match in the <code>Received:</code> lines. <code>[\w-]</code> 
  looks for a single letter, digit, underscore, or hyphen, while <code>[\w-]+</code> 
  looks for a sequence of such characters, such as <code>saul</code> or <code>apple-gunkies</code>. 
  This is a domain component. <code>[\w-]+\.</code> looks for a domain component 
  followed by a period, like <code>saul.</code> or <code>apple-gunkies.</code>. 
<p> Ignore the <code>?:</code> for the time being. Without it, the pattern is 
  <code>([\w-]+\.)+[\w-]+</code>, which means a domain component followed by a 
  period, then another domain component followed by another period, and so on, 
  and ending with a domain component and no period. So this is a pattern that 
  will match something that looks like a domain. 
<p>
The <code>/g</code> modifier on the match instructs Perl to find <em>all</em> matching substrings
and to return a list of them. Perl will look through
the
<code>Received:</code> headers, pulling out all the things that look like domains, making them
into a list, and returning the list of domains.

<p>
Another example of this feature:

<p>
<pre>
$s = &quot;Timmy is 7 years old and he lives at 350 Beacon St. 
Boston, MA 02134&quot; @numbers = ($s =~ m/\d+/g);
</pre>
<p>
Now <code>@numbers</code> contains (7, 350, 02134).

<p>
I still haven't explained that <code>?:</code>. I have to confess to a lie. Perl only returns the list of
matching
substrings if the pattern contains no parentheses. If the pattern contains
parentheses, the parentheses cause part of the string to be captured into
the special
<code>$1</code> variable, and the match returns a list of the <code>$1</code>s instead of a list of
the entire matching substrings. If I'd done

<p>
<pre>
&quot;saul.cis.upenn.edu plover.com&quot; =~ m/([\w-]+\.)+[\w-]+/g
</pre>
<p> instead, I would have gotten the list <code>(&quot;saul.cis.upenn.&quot;, 
  &quot;plover.&quot;)</code>, which are the <code>$1</code>'s, because the <code>com</code> 
  parts match the final <code>[\w-]+</code>, which is not in parentheses. The 
  <code>?:</code> in the real pattern is nothing more than a switch to tell Perl 
  not to use <code>$1</code>; . Since <code>$1</code> isn't being used, we get 
  the default behavior, and the match returns a list of everything that matched. 
<p>
<pre> 
  4   @forwarders = 
  5   grep { /[A-Za-z]/ } ($H{'Received'} =~ m/(?:[\w-]+\.)+[\w-]+/g);
</pre>
<p>
The pattern match generates a list of things that might be domains. The
list initially looks like:

<p>
<pre>
  renoir.op.net 209.152.193.4
  plover.com
  pisarro.op.net pisarro.op.net 209.152.193.22 renoir.op.net 1.18 mail.op.net
  linc.cis.upenn.edu LINC.CIS.UPENN.EDU 158.130.12.3 pisarro.op.net 1.1 op.net
  saul.cis.upenn.edu SAUL.CIS.UPENN.EDU 158.130.12.4
  linc.cis.upenn.edu 8.8.5 8.8.5
  op.net
  mail.cucs.org cucs-a252.cucs.org 207.25.43.252
  saul.cis.upenn.edu 8.8.5 8.8.5
  saul.cis.upenn.edu
  localhost.cucs.org 192.168.1.223
  mail.cucs.org 8.8.5 8.8.5
  saul.cis.upenn.edu
</pre>
<p> As you can see, it contains a lot of junk. Most notably, it contains several 
  occurrences of <code>8.8.5</code>, because the <code>upenn.edu</code> mailer 
  was Sendmail version 8.8.5. There are also some IP addresses that we won't be 
  able to filter, and some other things that look like version numbers. The <code>grep</code> 
  filters this list of items and passes through only those that contain at least 
  one letter, discarding the entirely numeric ones. 
<p>
<code>@forwarders</code> is now

<p>
<pre>       
  renoir.op.net
  plover.com
  pisarro.op.net pisarro.op.net renoir.op.net mail.op.net
  linc.cis.upenn.edu LINC.CIS.UPENN.EDU pisarro.op.net op.net
  saul.cis.upenn.edu SAUL.CIS.UPENN.EDU
  linc.cis.upenn.edu
  op.net
  mail.cucs.org cucs-a252.cucs.org
  saul.cis.upenn.edu
  saul.cis.upenn.edu
  localhost.cucs.org
  mail.cucs.org
  saul.cis.upenn.edu
</pre>
<p>
The rest of the function is just a little bit of cleanup. Line 7 discards
several domain names that aren't worth looking at because they appear so
often: 

<p>
<code>
<pre>
7  @forwarders = grep { !/(\bplover\.com|\bcis\.upenn\.edu|\bpobox\.com|\bop\.net)$/i }
   @forwarders;
</pre>
</code>
<p> Plover.com is my domain, and it's going to appear in all my mail, so there's 
  no point in checking it. I worked at the University of Pennsylvania for four 
  and a half years, and I get a lot of mail forwarded from there, so there's no 
  point in checking <code>cis.upenn.edu</code> domains either. Similarly, I subscribe 
  to the Pobox.com lifetime e-mail forwarding service, and I get a lot of mail 
  forwarded through there. <code>op.net</code> is my ISP domain name, which handles 
  mail for me when Plover is down. Line 7 discards all these domains from the 
  <code>@forwarders</code> list, leaving only the following: 
<p>
<pre> 
       mail.cucs.org cucs-a252.cucs.org
       localhost.cucs.org
       mail.cucs.org
</pre>
<p> Lines 9-13 now discard duplicate items, using a common Perl idiom: 
<p>
<pre>  
 9     foreach $r (@forwarders) {
 10       $r{lc $r} = 1;
 11     }
 12
 13     @forwarders = keys %r;
</pre>
<p> We use the remaining items as keys in a hash. Since a hash can't have the 
  same key twice, the duplicate <code>mail.cucs.org</code> has no effect on the 
  hash, which ends up with the keys, <code>mail.cucs.org</code>, <code>cucs-a252.cucs.org</code> 
  and <code>localhost.cucs.org</code>. The values associated with these keys are 
  each &quot;1,&quot; which doesn't matter. When we ask Perl for a list of keys 
  on line 13, we get each key exactly once. 
<p> Finally, line 15 returns the list of forwarders to whomever needed it. 
<p>
There's one little thing I didn't discuss:  

<p>
<pre>  2       return @forwarders if @forwarders;
</pre>
<p> The first thing the function does is check to see if it's already processed 
  the <code>Received:</code> lines and the computer <code>@forwarders</code>. 
  If so, it returns the list without computing it over again. That way I can just 
  call <code>forwarders()</code> anywhere in my program that I need a list of 
  forwarders, without worrying that I might be doing the same work more than once; 
  the <code>forwarders()</code> function guarantees to return immediately after 
  the first time I call it. 
<p>
<hr size="1" noshade>
<h1><a NAME="More_to_Come">More to Come</a></h1>
<p>
Because of the long delay, I'll repeat the quiz from the first article:
What's wrong with this header line?

<p>
<pre>
Received: from login_2961.sayme2.net (mail.sayme2.net[103.12.210.92])
by sayme2.net (8.8.5/8.7.3) with SMTP id XAA02040
for creditc@aoI.net;  Thu, 28 August 1997 15:51:23 -0700 (EDT)
</pre>
<p> The story's not over. In the next article, I'll talk about some other rules 
  I used to filter the spam; one of them would have thrown out messages when it 
  saw a line like the one above. Another one throws out mail when there's no <code>To:</code> 
  line in the message--a likely sign of bulk mail. 
<p>
I'll also tell a cautionary tale of how I might have lost a lot of money
because my system worked too well, and how I found out that sometimes, you <em>want</em> to get
unsolicited bulk mail.
                                    </div>


                                </div>
                                <div class="asset-footer">


                                    <div class="entry-tags">
                                        <h4>Tags<span class="delimiter">:</span></h4>
                                        <ul>
                                            <li><a href="javascript:void(0)" onclick="location.href='http://www.perl.com/mt-search.cgi?IncludeBlogs=2&amp;tag=spam&amp;limit=20';return false;" rel="tag">spam</a></li>
                                        </ul>
                                    </div>

                                </div>
                            </div>


                    
                    


                        </div>
                    </div>


                    <div id="beta">
    <div id="beta-inner">


    
    <div class="widget-what-is-perl widget">
    <div class="widget-content widget-content-what-is-perl">
       Visit the home of the  Perl programming language: <a href="http://www.perl.org/">Perl.org</a
    </div>
</div>
<div class="widget-find-out-more widget-archives widget">
    <div class="widget-content">
        <ul>
            <li><a href="http://www.perl.org/get.html">Download</a></li>
            <li><a href="http://perldoc.perl.org/">Documentation</a></li>
            <li><a href="http://blogs.perl.org/">Perl Bloggers</a></li>
            <li><a href="http://news.perlfoundation.org/">Foundation News</a></li>
        </ul>
    </div>
</div><div class="widget-tcpc widget">
<h3 class="widget-header">Sponsored by</h3>
    <div class="widget-content">
        <a href="http://training.perl.com/" alt="Perl Training" target="_blank"><img src="/i/tcpc.png" width="150" height="50"></a>
    </div>
</div>

<div class="widget-syndication widget">
    <div class="widget-content">
        <ul>
            <li><img src="/mt-static/images/status_icons/feed.gif" alt="Subscribe to feed" width="9" height="9" /> <a href="/pub/atom.xml">Subscribe to this website's feed</a></li>

        </ul>
    </div>
</div>
<div class="widget-archive-monthly widget-archive widget">
    <h3 class="widget-header">Monthly <a href="/pub/archives.html">Archives</a></h3>
    <div class="widget-content">
        <ul>
        
            <li><a href="/pub/2014/02/">February 2014 (1)</a></li>
        
    
        
            <li><a href="/pub/2014/01/">January 2014 (1)</a></li>
        
    
        
            <li><a href="/pub/2013/10/">October 2013 (1)</a></li>
        
    
        
            <li><a href="/pub/2013/01/">January 2013 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/12/">December 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/11/">November 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2012/10/">October 2012 (2)</a></li>
        
    
        
            <li><a href="/pub/2012/08/">August 2012 (2)</a></li>
        
    
        
            <li><a href="/pub/2012/06/">June 2012 (11)</a></li>
        
    
        
            <li><a href="/pub/2012/05/">May 2012 (18)</a></li>
        
    
        
            <li><a href="/pub/2012/04/">April 2012 (17)</a></li>
        
    
        
            <li><a href="/pub/2012/02/">February 2012 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/12/">December 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/09/">September 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/08/">August 2011 (2)</a></li>
        
    
        
            <li><a href="/pub/2011/06/">June 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/05/">May 2011 (3)</a></li>
        
    
        
            <li><a href="/pub/2011/04/">April 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/03/">March 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/02/">February 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2011/01/">January 2011 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/11/">November 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/10/">October 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/09/">September 2010 (1)</a></li>
        
    
        
            <li><a href="/pub/2010/08/">August 2010 (3)</a></li>
        
    
        
            <li><a href="/pub/2010/07/">July 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/04/">April 2010 (2)</a></li>
        
    
        
            <li><a href="/pub/2010/03/">March 2010 (4)</a></li>
        
    
        
            <li><a href="/pub/2008/05/">May 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/04/">April 2008 (2)</a></li>
        
    
        
            <li><a href="/pub/2008/03/">March 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/02/">February 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2008/01/">January 2008 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/12/">December 2007 (2)</a></li>
        
    
        
            <li><a href="/pub/2007/09/">September 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/08/">August 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/07/">July 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/06/">June 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/05/">May 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/04/">April 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/03/">March 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/02/">February 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2007/01/">January 2007 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/12/">December 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/11/">November 2006 (2)</a></li>
        
    
        
            <li><a href="/pub/2006/10/">October 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/09/">September 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/08/">August 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/07/">July 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/06/">June 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/05/">May 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/04/">April 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/03/">March 2006 (1)</a></li>
        
    
        
            <li><a href="/pub/2006/02/">February 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2006/01/">January 2006 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/12/">December 2005 (4)</a></li>
        
    
        
            <li><a href="/pub/2005/11/">November 2005 (3)</a></li>
        
    
        
            <li><a href="/pub/2005/10/">October 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/09/">September 2005 (2)</a></li>
        
    
        
            <li><a href="/pub/2005/08/">August 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/07/">July 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/06/">June 2005 (9)</a></li>
        
    
        
            <li><a href="/pub/2005/05/">May 2005 (8)</a></li>
        
    
        
            <li><a href="/pub/2005/04/">April 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/03/">March 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2005/02/">February 2005 (7)</a></li>
        
    
        
            <li><a href="/pub/2005/01/">January 2005 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/12/">December 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/11/">November 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/10/">October 2004 (5)</a></li>
        
    
        
            <li><a href="/pub/2004/09/">September 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/08/">August 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/07/">July 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/06/">June 2004 (6)</a></li>
        
    
        
            <li><a href="/pub/2004/05/">May 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2004/04/">April 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/03/">March 2004 (8)</a></li>
        
    
        
            <li><a href="/pub/2004/02/">February 2004 (9)</a></li>
        
    
        
            <li><a href="/pub/2004/01/">January 2004 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/12/">December 2003 (4)</a></li>
        
    
        
            <li><a href="/pub/2003/11/">November 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/10/">October 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/09/">September 2003 (6)</a></li>
        
    
        
            <li><a href="/pub/2003/08/">August 2003 (7)</a></li>
        
    
        
            <li><a href="/pub/2003/07/">July 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/06/">June 2003 (9)</a></li>
        
    
        
            <li><a href="/pub/2003/05/">May 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/04/">April 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/03/">March 2003 (10)</a></li>
        
    
        
            <li><a href="/pub/2003/02/">February 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2003/01/">January 2003 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/12/">December 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/11/">November 2002 (9)</a></li>
        
    
        
            <li><a href="/pub/2002/10/">October 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/09/">September 2002 (11)</a></li>
        
    
        
            <li><a href="/pub/2002/08/">August 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/07/">July 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2002/06/">June 2002 (4)</a></li>
        
    
        
            <li><a href="/pub/2002/05/">May 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/04/">April 2002 (6)</a></li>
        
    
        
            <li><a href="/pub/2002/03/">March 2002 (7)</a></li>
        
    
        
            <li><a href="/pub/2002/02/">February 2002 (5)</a></li>
        
    
        
            <li><a href="/pub/2002/01/">January 2002 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/12/">December 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/11/">November 2001 (5)</a></li>
        
    
        
            <li><a href="/pub/2001/10/">October 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/09/">September 2001 (7)</a></li>
        
    
        
            <li><a href="/pub/2001/08/">August 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/07/">July 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/06/">June 2001 (13)</a></li>
        
    
        
            <li><a href="/pub/2001/05/">May 2001 (11)</a></li>
        
    
        
            <li><a href="/pub/2001/04/">April 2001 (9)</a></li>
        
    
        
            <li><a href="/pub/2001/03/">March 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/02/">February 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2001/01/">January 2001 (8)</a></li>
        
    
        
            <li><a href="/pub/2000/12/">December 2000 (6)</a></li>
        
    
        
            <li><a href="/pub/2000/11/">November 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/10/">October 2000 (10)</a></li>
        
    
        
            <li><a href="/pub/2000/09/">September 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/08/">August 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/07/">July 2000 (5)</a></li>
        
    
        
            <li><a href="/pub/2000/06/">June 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/05/">May 2000 (7)</a></li>
        
    
        
            <li><a href="/pub/2000/04/">April 2000 (3)</a></li>
        
    
        
            <li><a href="/pub/2000/03/">March 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/02/">February 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/2000/01/">January 2000 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/12/">December 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/11/">November 1999 (6)</a></li>
        
    
        
            <li><a href="/pub/1999/10/">October 1999 (5)</a></li>
        
    
        
            <li><a href="/pub/1999/09/">September 1999 (4)</a></li>
        
    
        
            <li><a href="/pub/1999/08/">August 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/07/">July 1999 (2)</a></li>
        
    
        
            <li><a href="/pub/1999/06/">June 1999 (3)</a></li>
        
    
        
            <li><a href="/pub/1999/04/">April 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/03/">March 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1999/01/">January 1999 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/12/">December 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/11/">November 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/07/">July 1998 (2)</a></li>
        
    
        
            <li><a href="/pub/1998/06/">June 1998 (1)</a></li>
        
    
        
            <li><a href="/pub/1998/03/">March 1998 (1)</a></li>
        
        </ul>
    </div>
</div>
        
    

<div class="widget-powered widget">
    <div class="widget-content">
        <a href="http://www.movabletype.com/"><img src="/mt-static/images/bug-pbmt-white.png" alt="Powered by Movable Type 5.13-en" width="120" height="75" /></a>
    </div>
</div>



    </div>
</div>






                </div>
            </div>


            <div id="footer">
    <div id="footer-inner">
        <div id="footer-content">
            <div class="widget-powered widget">
                <div class="widget-content">
                    Powered by <a href="http://www.movabletype.com/" rel="generator">Movable Type Pro</a>
                </div>
            </div>

            <div class="widget-creative-commons widget">
                <div class="widget-content">
                    This blog is licensed under a <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/">Creative Commons License</a>.
                </div>
            </div>

        </div>
    </div>
</div>



        </div>
    </div>
</body>
</html>
